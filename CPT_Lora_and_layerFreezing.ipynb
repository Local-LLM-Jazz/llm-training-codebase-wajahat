{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1b3686d",
   "metadata": {},
   "source": [
    "## CPT Using Layer Freezing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2303cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/content/'\n",
      "/home/ai-research-lab/MCSProjectbyWajahatalibasharat5Percent\n",
      "Cloning into 'LLaMA-Factory'...\n",
      "remote: Enumerating objects: 360, done.\u001b[K\n",
      "remote: Counting objects: 100% (360/360), done.\u001b[K\n",
      "remote: Compressing objects: 100% (279/279), done.\u001b[K\n",
      "remote: Total 360 (delta 79), reused 275 (delta 66), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (360/360), 9.94 MiB | 1.76 MiB/s, done.\n",
      "Resolving deltas: 100% (79/79), done.\n",
      "/home/ai-research-lab/MCSProjectbyWajahatalibasharat5Percent/LLaMA-Factory\n",
      "\u001b[0m\u001b[01;34massets\u001b[0m/       \u001b[01;34mevaluation\u001b[0m/  MANIFEST.in     requirements.txt  \u001b[01;34mtests\u001b[0m/\n",
      "CITATION.cff  \u001b[01;34mexamples\u001b[0m/    pyproject.toml  \u001b[01;34mscripts\u001b[0m/\n",
      "\u001b[01;34mdata\u001b[0m/         LICENSE      README.md       setup.py\n",
      "\u001b[01;34mdocker\u001b[0m/       Makefile     README_zh.md    \u001b[01;34msrc\u001b[0m/\n",
      "Obtaining file:///home/ai-research-lab/MCSProjectbyWajahatalibasharat5Percent/LLaMA-Factory\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: transformers!=4.46.*,!=4.47.*,!=4.48.0,!=4.52.0,<=4.52.4,>=4.45.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from llamafactory==0.9.4.dev0) (4.52.4)\n",
      "Requirement already satisfied: datasets<=3.6.0,>=2.16.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from llamafactory==0.9.4.dev0) (3.6.0)\n",
      "Requirement already satisfied: accelerate<=1.7.0,>=0.34.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from llamafactory==0.9.4.dev0) (1.7.0)\n",
      "Requirement already satisfied: peft<=0.15.2,>=0.14.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from llamafactory==0.9.4.dev0) (0.15.2)\n",
      "Requirement already satisfied: trl<=0.9.6,>=0.8.6 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from llamafactory==0.9.4.dev0) (0.9.6)\n",
      "Requirement already satisfied: tokenizers<=0.21.1,>=0.19.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from llamafactory==0.9.4.dev0) (0.21.1)\n",
      "Requirement already satisfied: gradio<=5.31.0,>=4.38.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from llamafactory==0.9.4.dev0) (5.31.0)\n",
      "Requirement already satisfied: scipy in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from llamafactory==0.9.4.dev0) (1.15.3)\n",
      "Requirement already satisfied: einops in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from llamafactory==0.9.4.dev0) (0.8.1)\n",
      "Requirement already satisfied: sentencepiece in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from llamafactory==0.9.4.dev0) (0.2.0)\n",
      "Requirement already satisfied: tiktoken in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from llamafactory==0.9.4.dev0) (0.9.0)\n",
      "Requirement already satisfied: protobuf in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from llamafactory==0.9.4.dev0) (6.31.1)\n",
      "Requirement already satisfied: uvicorn in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from llamafactory==0.9.4.dev0) (0.34.3)\n",
      "Requirement already satisfied: fastapi in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from llamafactory==0.9.4.dev0) (0.115.13)\n",
      "Requirement already satisfied: sse-starlette in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from llamafactory==0.9.4.dev0) (2.3.6)\n",
      "Requirement already satisfied: matplotlib>=3.7.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from llamafactory==0.9.4.dev0) (3.10.3)\n",
      "Requirement already satisfied: fire in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from llamafactory==0.9.4.dev0) (0.7.0)\n",
      "Requirement already satisfied: omegaconf in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from llamafactory==0.9.4.dev0) (2.3.0)\n",
      "Requirement already satisfied: packaging in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from llamafactory==0.9.4.dev0) (25.0)\n",
      "Requirement already satisfied: pyyaml in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from llamafactory==0.9.4.dev0) (6.0.2)\n",
      "Requirement already satisfied: numpy<2.0.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from llamafactory==0.9.4.dev0) (1.26.4)\n",
      "Requirement already satisfied: pydantic<=2.10.6 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from llamafactory==0.9.4.dev0) (2.10.6)\n",
      "Requirement already satisfied: pandas>=2.0.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from llamafactory==0.9.4.dev0) (2.3.0)\n",
      "Requirement already satisfied: av in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from llamafactory==0.9.4.dev0) (14.4.0)\n",
      "Requirement already satisfied: librosa in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from llamafactory==0.9.4.dev0) (0.11.0)\n",
      "Requirement already satisfied: tyro<0.9.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from llamafactory==0.9.4.dev0) (0.8.14)\n",
      "Requirement already satisfied: torch>=2.0.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from llamafactory==0.9.4.dev0) (2.7.1+cu128)\n",
      "Requirement already satisfied: torchvision>=0.15.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from llamafactory==0.9.4.dev0) (0.22.1+cu128)\n",
      "Requirement already satisfied: bitsandbytes>=0.39.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from llamafactory==0.9.4.dev0) (0.46.0)\n",
      "Requirement already satisfied: psutil in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from accelerate<=1.7.0,>=0.34.0->llamafactory==0.9.4.dev0) (5.9.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from accelerate<=1.7.0,>=0.34.0->llamafactory==0.9.4.dev0) (0.33.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from accelerate<=1.7.0,>=0.34.0->llamafactory==0.9.4.dev0) (0.5.3)\n",
      "Requirement already satisfied: filelock in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (0.3.8)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (3.12.13)\n",
      "Requirement already satisfied: aiofiles<25.0,>=22.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (24.1.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (4.9.0)\n",
      "Requirement already satisfied: ffmpy in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.6.0)\n",
      "Requirement already satisfied: gradio-client==1.10.1 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (1.10.1)\n",
      "Requirement already satisfied: groovy~=0.1 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.1.2)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.28.1)\n",
      "Requirement already satisfied: jinja2<4.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (3.1.4)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (2.1.5)\n",
      "Requirement already satisfied: orjson~=3.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (3.10.18)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (11.0.0)\n",
      "Requirement already satisfied: pydub in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.0.20)\n",
      "Requirement already satisfied: ruff>=0.9.3 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.12.0)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.1.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.46.2)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.13.3)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (4.12.2)\n",
      "Requirement already satisfied: websockets<16.0,>=10.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from gradio-client==1.10.1->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (15.0.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from pandas>=2.0.0->llamafactory==0.9.4.dev0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from pandas>=2.0.0->llamafactory==0.9.4.dev0) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from pandas>=2.0.0->llamafactory==0.9.4.dev0) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from pydantic<=2.10.6->llamafactory==0.9.4.dev0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from pydantic<=2.10.6->llamafactory==0.9.4.dev0) (2.27.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate<=1.7.0,>=0.34.0->llamafactory==0.9.4.dev0) (1.1.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from transformers!=4.46.*,!=4.47.*,!=4.48.0,!=4.52.0,<=4.52.4,>=4.45.0->llamafactory==0.9.4.dev0) (2024.11.6)\n",
      "Requirement already satisfied: click>=8.0.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (14.0.0)\n",
      "Requirement already satisfied: docstring-parser>=0.16 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from tyro<0.9.0->llamafactory==0.9.4.dev0) (0.16)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from tyro<0.9.0->llamafactory==0.9.4.dev0) (1.7.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (6.5.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (1.20.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from torch>=2.0.0->llamafactory==0.9.4.dev0) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from torch>=2.0.0->llamafactory==0.9.4.dev0) (3.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.61 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from torch>=2.0.0->llamafactory==0.9.4.dev0) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.57 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from torch>=2.0.0->llamafactory==0.9.4.dev0) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.57 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from torch>=2.0.0->llamafactory==0.9.4.dev0) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.7.1.26 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from torch>=2.0.0->llamafactory==0.9.4.dev0) (9.7.1.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.3.14 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from torch>=2.0.0->llamafactory==0.9.4.dev0) (12.8.3.14)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.41 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from torch>=2.0.0->llamafactory==0.9.4.dev0) (11.3.3.41)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.55 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from torch>=2.0.0->llamafactory==0.9.4.dev0) (10.3.9.55)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.2.55 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from torch>=2.0.0->llamafactory==0.9.4.dev0) (11.7.2.55)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.7.53 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from torch>=2.0.0->llamafactory==0.9.4.dev0) (12.5.7.53)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from torch>=2.0.0->llamafactory==0.9.4.dev0) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from torch>=2.0.0->llamafactory==0.9.4.dev0) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.55 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from torch>=2.0.0->llamafactory==0.9.4.dev0) (12.8.55)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.61 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from torch>=2.0.0->llamafactory==0.9.4.dev0) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.0.11 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from torch>=2.0.0->llamafactory==0.9.4.dev0) (1.13.0.11)\n",
      "Requirement already satisfied: triton==3.3.1 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from torch>=2.0.0->llamafactory==0.9.4.dev0) (3.3.1)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from triton==3.3.1->torch>=2.0.0->llamafactory==0.9.4.dev0) (78.1.1)\n",
      "Requirement already satisfied: certifi in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from httpx>=0.24.1->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from httpx>=0.24.1->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.16.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from matplotlib>=3.7.0->llamafactory==0.9.4.dev0) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from matplotlib>=3.7.0->llamafactory==0.9.4.dev0) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from matplotlib>=3.7.0->llamafactory==0.9.4.dev0) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from matplotlib>=3.7.0->llamafactory==0.9.4.dev0) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from matplotlib>=3.7.0->llamafactory==0.9.4.dev0) (3.2.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->llamafactory==0.9.4.dev0) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from requests>=2.32.2->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from requests>=2.32.2->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (2.5.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.1.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=2.0.0->llamafactory==0.9.4.dev0) (1.3.0)\n",
      "Requirement already satisfied: termcolor in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from fire->llamafactory==0.9.4.dev0) (3.1.0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from librosa->llamafactory==0.9.4.dev0) (3.0.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from librosa->llamafactory==0.9.4.dev0) (0.61.2)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from librosa->llamafactory==0.9.4.dev0) (1.7.0)\n",
      "Requirement already satisfied: joblib>=1.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from librosa->llamafactory==0.9.4.dev0) (1.5.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from librosa->llamafactory==0.9.4.dev0) (5.2.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from librosa->llamafactory==0.9.4.dev0) (0.13.1)\n",
      "Requirement already satisfied: pooch>=1.1 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from librosa->llamafactory==0.9.4.dev0) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from librosa->llamafactory==0.9.4.dev0) (0.5.0.post1)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from librosa->llamafactory==0.9.4.dev0) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from librosa->llamafactory==0.9.4.dev0) (1.1.1)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from numba>=0.51.0->librosa->llamafactory==0.9.4.dev0) (0.44.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from pooch>=1.1->librosa->llamafactory==0.9.4.dev0) (4.3.8)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from scikit-learn>=1.1.0->librosa->llamafactory==0.9.4.dev0) (3.6.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from soundfile>=0.12.1->librosa->llamafactory==0.9.4.dev0) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa->llamafactory==0.9.4.dev0) (2.22)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from omegaconf->llamafactory==0.9.4.dev0) (4.9.3)\n",
      "Building wheels for collected packages: llamafactory\n",
      "  Building editable for llamafactory (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for llamafactory: filename=llamafactory-0.9.4.dev0-0.editable-py3-none-any.whl size=27651 sha256=7ed75f233bfe2ab33e5958a6f85c240c8630c8cc1a7460631a109bcf639310fe\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-jd_wi6v6/wheels/c5/0a/c2/28b4705dbb3d685eb19293f68ed95a6ac31ae294f37787de36\n",
      "Successfully built llamafactory\n",
      "Installing collected packages: llamafactory\n",
      "  Attempting uninstall: llamafactory\n",
      "    Found existing installation: llamafactory 0.9.4.dev0\n",
      "    Uninstalling llamafactory-0.9.4.dev0:\n",
      "      Successfully uninstalled llamafactory-0.9.4.dev0\n",
      "Successfully installed llamafactory-0.9.4.dev0\n"
     ]
    }
   ],
   "source": [
    "%cd /content/\n",
    "%rm -rf LLaMA-Factory\n",
    "!git clone --depth 1 https://github.com/hiyouga/LLaMA-Factory.git\n",
    "%cd LLaMA-Factory\n",
    "%ls\n",
    "!pip install -e .[torch,bitsandbytes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98bd18cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA version: 12.8\n",
      "CUDA available: True\n",
      "Device name: NVIDIA GeForce RTX 4090\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"CUDA version:\", torch.version.cuda)           # e.g. '12.1'\n",
    "print(\"CUDA available:\", torch.cuda.is_available())  # should be True\n",
    "print(\"Device name:\", torch.cuda.get_device_name(0)) # e.g. 'NVIDIA GeForce RTX 4090'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a83c58d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7bcae4fa48e44b3bf23fd68c3f13ab4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##login-info\n",
    "# !pip3 install ipywidgets\n",
    "from huggingface_hub import login, notebook_login\n",
    "notebook_login()\n",
    "# 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\n",
    "# wiki_demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23613ae9",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e9f2045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd1fa7a752fe4e72871755f63199a0f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples written: 320390\n",
      "\n",
      "First 200 characters of the first sample:\n",
      "Anarchism is a political philosophy and movement that is skeptical of all justifications for authority and seeks to abolish the institutions it claims maintain unnecessary coercion and hierarchy, typi\n",
      "\n",
      "✅ Correct: Raw text only.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Define the absolute path to the 'data' directory\n",
    "data_dir = '/home/ai-research-lab/MCSProjectbyWajahatalibasharat5Percent/LLaMA-Factory/data'\n",
    "# Ensure the 'data' directory exists\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "# Define the output file path within the 'data' directory\n",
    "# output_path = os.path.join(data_dir, 'wiki_1percent.json')\n",
    "output_path = os.path.join(data_dir, 'wiki_5percent.json')\n",
    "# Load the dataset with streaming\n",
    "dataset = load_dataset(\n",
    "    'wikimedia/wikipedia',\n",
    "    '20231101.en',\n",
    "    split='train',\n",
    "    streaming=True\n",
    ")\n",
    "\n",
    "# Estimate total size and compute 1%\n",
    "total_samples = dataset.info.splits['train'].num_examples\n",
    "# sample_size = int(0.01 * total_samples)\n",
    "sample_size = int(0.05 * total_samples)\n",
    "# Collect raw text samples\n",
    "text_samples = []\n",
    "for i, example in enumerate(dataset):\n",
    "    if i >= sample_size:\n",
    "        break\n",
    "    text_samples.append(example['text'])\n",
    "\n",
    "# Format as a list of {\"text\": ...}\n",
    "formatted_data = [{'text': t} for t in text_samples]\n",
    "\n",
    "# Save to JSON with UTF-8 encoding\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(formatted_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# Verification\n",
    "with open(output_path, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "    print(f'Total samples written: {len(data)}\\n')\n",
    "    first = data[0]['text'][:200]\n",
    "    print('First 200 characters of the first sample:')\n",
    "    print(first)\n",
    "    if '### Title:' in first or 'Wikipedia Article' in first:\n",
    "        print('\\n⚠️ WARNING: Detected Wikipedia formatting—expected raw text only.')\n",
    "    else:\n",
    "        print('\\n✅ Correct: Raw text only.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ced0467e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning Markdown files in: /home/ai-research-lab/MCSProjectbyWajahatalibasharat5Percent/LLaMA-Factory/data/Markdown/\n",
      "Collected 37 markdown documents and saved to /home/ai-research-lab/MCSProjectbyWajahatalibasharat5Percent/LLaMA-Factory/data/markdown_docs.jsonl\n",
      "\n",
      "First 3 lines of markdown_docs.jsonl:\n",
      "{\"text\": \"## [AS PASSED BY THE MAJLIS-E-SHOORA (PARLIAMENT)]\\n\\n## BILL\\n\\nto provide for setting up of the Pakistan International Airlines Corporation into a public limited company .\\n\\nWHEREAS it for   conversion of the Pakistan International Airlines   Corporation   into a 1984 (XLVII of 1984) and to deal with ancillary matters;\\n\\nIt is hereby enacted as follows:\\n\\n- 1 Short title, extent and commencement.- (l) This Act may be called the Pakistan International Airlines Corporation (Conversion) Act. 2016.\\n- It extends to the whole of Pakistan\\n- It shall come into force at once.\\n- 2 Definitions.- In this Act.  unless there is anything repugnant in the subject or context.\\n- (a) \\\"arrangement\\\" means an arrangement in writing between the Company and any relevant entity setting forth the terms. conditions and manner of transfer of o' Or more assets of the Company to 2 relevant entity along with the consideration for the same, which transfer is subject to be provisions of section 4;\\n- (b) \\\"assets includes all properties. rights and entitlements of every description and nature whatsoever. whether present or future. actual or contingent. and tangible or intangible, in Pakistan or elsewhere and includes but not limited to property held on trust. both movable and immovable. benefits. claims.   receivables, cash balances; documents, investments, privileges and powers;\\n- \\\"Company' mcans Pakistan International Airlines Corporation Limited incorporated under the Companies Ordinance:\\n- \\\"Companies Ordinance\\\" means the   Companies   Ordinance. 1984 (XLVII of 1984);\\n- \\\"Company request\\\" mneans a to the Federal Government to issue an order pursuant to section 4 to effect transfer to a relevant entity of specified assets in terms of the relevant arrangenment, provided nevertheless; such request may only be made once the Company has to that extent complied with the provisions of sub-section (3) of section 196 of the Companies Ordinance and the applicable code of corporate governance;\\n- \\\"conversion with all its cognate expressions means, in accordance with the provisions of this Act. the conversion of the Corporation into a Company:\\n- \\\"commencing date\\\" means the date of promulgation of this Act;\\n- h \\\"Corporation means the Pakistan International Airlines Corporation established under the Pakistan International Airlines Corporation Act. 1956 (XIX of 1956):\\n- \\\"liabilities includes all borrowings; duties. obligations; loans encumbrances of every   description and nature whatsoever in Pakistan elsewhere; whether present or future. actual or contingent, and disclosed or undisclosed; O\\n- \\\"order' means any order issued by the Federal  Government  pursuant to subsection (1 ) of section \\\"orders' shall be construed accordingly;\\n- \\\"PIAC Act\\\" means the Pakistan   International (XIX of 1956):\\n- proceedings includes any  suit. arbitration Or   administrative proceedings applications. appeals. awards, reviews or revisions filed or pending;\\n- m relevant entity' means any body corporate or company owned or controlled by the Federal Government or the Federal Government itself:\\n- (n) \\\"specified assets' means the assets specified in the relevant arrangements;\\n- 'undertakings ' include all projects; ventures and operations undertaken by the Corporation; individually or collectively . in collaboration with some other person; and\\n- \\\"validity period\\\" means   the period   starting   from the  commencing date   and ending on the second anniversary of the commencing date.. or on such earlier date as may be notified by the Federal Government in the official Gazette.\\n- 3 Conversion of Corporation into a Company - (i) The Corporation shall be deemed to have been converted into a company limited by shares with effect from the commencing date public\\n- 2) As and from the commending date,\\n- (a) the Company shall be deemed to hold and own all assets and liabilities of the Corporation  without any conveyance; alienation assignment  and withou. any further act. deed or registration and without   discharging Or invalidating any contract; and\\n- (b without prejudice to the generality of the foregoing clause; the Company shall;\\n- be entitled [0 the benefit of all notitications. licenses.   permissions, sanctions;   authorizations.  concessions;   decrees, orders and benefits whatsoever issued or granted in favour of the Corporation as on the commencing date, including but not limited to the permission connected with the of the securities of the Corporation on the relevant stock exchanges; and listing\\n- (ii) be deemed to have taken over and shall be entitled to enforce, all rights, licenses; and concessions and to have assumed all liabilities of the Corporation and shall be liable to pay and discharge all liabilities of every description and nature whatsoever of the Corporation. grants\\n- (3 The shareholders of the Company shall be deemed without any fresh issuance of shares   to own and hold the same number of fully shares   with such rights   and privileges (including as to class; kind and face value) as owned and Company shall be deemed to be equivalent to the authorized of the Corporation as on the commencing date and no fee or charges shall be payable in this regard. paid they capital\\n- All   proceedings of every description and nature   whatsoever by Or against  or relating to the Corporation pending on the commencing date in any court; tribunal, or other authority shall be continued, defended, prosecuted and enforced by or against or relating to the Corporation; and the same shall not abate, be discontinued, prejudiced or otherwise affected by the provisions of this Act.\\n- (5 The Company shall be deemed to be the successor-in-interest of the Corporation; and the name of the Company shall be deemed to have been substituted for the name of the   Corporation of attorney , consents;   undertakings; leases, grants, concessions, records of Central or documents of every description and nature   whatsoever relating to the Corporation and no objection shall be entertained by any court; tribunal or authority in regard to such substitution or on the ground that any such contract; agreement or document as aforesaid was, or with; the name of the Corporation and not the Company.\\n- (6) All  employees of the Corporation   shall be deemed to be employees of the Company on the same remuneration and other conditions of service, rights and privileges including but not  limited to the provisions as to their pension; provident   fund and gratuity; as the case may and other matters as were applicable to them before the conversion; including all existing retirement benefits of the employees whether funded or non-funded: be,\\n\\n## Provided that\\n\\n- Notwithstanding anything contained in this Act or nay other law; Or any decision of any court or tribunal, the employees of the Company shall continue to be govemed by non-statutory contractual terms, conditions, rules   and regulations which shall not   acquire;, Or be deemed to have acquired or be treated as having acquired, statutory status;\\n- No person deemed to be employed by the Company under this section shall be entitled to any compensation or benefit as a consequence of the conversion of the Corporation into a Company;\\n- (iii) The salaries; emoluments and all other terms of service of employees; whether permanent or contractual, shall not be changed to their disadvantage; and\\n- (iv) Pensions and other of the Corporation to   retired employees shall not be changed to their disadvantage.\\n- Notwithstanding the provisions of section 146 of the Companies Ordinance, the Company shall, upon conversion; continue all business and   undertakings of the Corporation as were carried on immediately to the commencing date. being prior\\n- 4 Power to pass orders for the transfer of assets.- (1) During the validity period and subject to a transfer of specified assets to a relevant entity substantially on the terms set forth in the relevant arrangement. prior\\n- (2) The orders shall binding on the Company; the relevant and any other person having any right; claim or liability in relation to the Company or any relevant entity . entity\\n- (3) As and from the date specified in the order, the specified assets shall, by virtue and to the extent provided in the relevant order, stand transferred and vest in, the relevant without nay conveyance; alienation or assignment and without any further act, deed Or registration and without discharging or invalidating any contract, and be subject to the terms of the relevant order in all cases. to, entity ,\\n- Representation on the Board of Directors and all other rights and privileges of shareholders of the Company; or any of its subsidiary companies carrying on air-transport business; shall be proportionate to their share-holding.\\n- Explanation: - Management control of the Company and any of its subsidiary companies in the above circumstances shall continue to vest in the majority shareholder; which shall be the Federal Government and whose share shall not be less than one percent. fifty\\n- 5 The Federal Government shall carry out or cause to be carried out valuation of the assets of the Company, and its subsidiary companies carrying on air-transport business, by a recognized valuator before transferring any shares of these companies to a third party .\\n- The Public Procurement Regulatory Authority Ordinance; 2002 (Ordinance XXII of 2002) and rules framed thereunder; as presently applicable, shall continue to apply to all transactions under this Act.\\n- 5 Guarantees to remain in force Notwithstanding the repeal of the PIAC Act; all guarantees   given by the Federal Government to any   person;   including   foreign or local institutions; to secure any of the liabilities of the Corporation shall remain in full force and affect as though they were given on behalf of the Company.\\n- 6 The Federal Government may, by notification in the Official Gazette, waive any duty, fee or any other charge that may be under any Federal law for the time in force. payable tax, being\\n- 7 Name and Headquarters of Company - (1) The name of the Company shall not be changed without the consent; in writing; of the Federal Government.\\n- (2) The Headquarters of the Company and any of its subsidiary companies carrying on air-transport business shall be at Karachi.\\n- 8 No or Neither the conversion nor the transfer of any asset of the Company through an order shall given rise to any or loss under the Income Tax Ordinance; 2001 (XLXof 2001) loss gain gain\\n- 9 Act to override - The provisions of this Act and the orders issued hereunder shall have effect notwithstanding anything to the contrary contained in any other law for the time in force. being\\n- 10. difficulty arises during the validity in giving effect to any provision of this Act; the Federal Government may, be notification in the official Gazette; make such provisions as may appear to it to be necessary for the purpose of removing the difficulty . period\\n- 11 Repeal - (1) The PIAC Act is hereby repealed.\\n- On repeal of PIAC Act under sub-section (l), nothing contained in the said Act shall be applicable to the Company; its shareholders Or any other person that may have had interest in the Corporation immediately to the conversion. prior\"}\n",
      "{\"text\": \"<!-- image -->\\n\\nTerminal-1 JIAP , Karachi-75200 Tel: (92-21) 9924-2033 Fax: (92-21) 9924-2032\\n\\n## HEADQUARTERS PAKISTAN CIVIL AVIATION AUTHORITY\\n\\ndairtransport@caapakistan com pk\\n\\nAuqust 30 2021\\n\\n## IMPLEMENTATION OF STANDARD OPERATING PROCEDURES PRIVATEAIRCRAFFLGHTS\\n\\nReference our letter of even number dated August 13, 2021 containing Categorized   Country Lists and   guidelines   concerning inbound travel to Pakistan.\\n\\n- 2. The instructions contained in the above-mentioned letter are hereby extended till September 30, 2021. Consequenlly; all Pakistanis whose return to Pakistan from Category C Countries is scheduled till September 30, 2021, may travel to Pakistan without grant of a special exemption and while in possession of valid negative PCR Test Result conducted within the 72 hours to commencement of travel to Pakistan; subject to conformance with all other applicable rules regulations . Inbound travel to Pakistan from Category € Countries for all other passengers will continue to remain banned. prior\\n- 3. or all passengers arriving in Pakistan will, however, be subjected to and Quarantine stipulations as per procedure in-vogue. Any Testing\\n- 4 All concerned are directed to ensure strict compliance.\\n\\n<!-- image -->\\n\\n(IRFANSABIR)\\n\\nAirCommodore (Retd)\\n\\nDirector AT &amp; ER\\n\\nAll Scheduled and Charter Airline Operators All Ground Handling Agents All Private Operators All Authorized Flight Permission Agents\\n\\n## Copyto:\\n\\n- Additional Deputy DGCAA (Reg) HQCAA; Karachi\\n- Joint Secretary II, Aviation Division; Islamabad\\n- Director Airport Services, HQCAA; Karachi\\n- All Chief Operating OfficerslAirport Managers\\n- PSO to DGCAA, HQCAA, Karachi\\n- Director Operations; Airports Security Force, ASF HQ; Karachi\"}\n",
      "{\"text\": \"<!-- image -->\\n\\n## HEADQUARTERS PAKISTAN CIVIL AVIATION AUTHORITY\\n\\nTerminal-1 JIAP , Karachi-75200\\n\\nTel: (92-21) 9924-2033\\n\\nFax: (92-21) 9924-2032\\n\\ndairtransport @caapakistan compk\\n\\nJuly 27 2021\\n\\n## PRIVATE AIRCRAFT FLIGHTS\\n\\nReference is made to our letters of even number dated June 12 and July 12, 2021 providing guidelines on inbound travel to Pakistan from Categorized Country Lists .\\n\\n- 2 The instructions and guidelines coriained in our above-referred letters are hereby extended upto August 31, 2021\\\\_ Consequently, all Pakistanis whose return to Pakistan from Category C Countries is scheduled till August 38, 2021 may travel to Pakistan without grant of a special exemption and while in possession of a valid negative PCR Test Result conducted within the 72 hours to commencement of travel to Pakistan; subject to conformance with all other applicable rules / regulations. Inbound travel to Pakistan from Category C Countries for all other passengers will continue to remain banned. prior\\n- 3 or all passengers arriving in Pakistan will, however; be subjected to Testing and Quarantine stipulations as per procedure in-vogue. Any\\n- 4 All concerned are directed t0 ensure strict compliance.\\n\\n(IRFAN SABIR)\\n\\nAir Comhodore (Retd.)\\n\\nDirector AT &amp; ER\\n\\n<!-- image -->\\n\\nAll Scheduled and Charter Air Carriers All Private Operators All Authorized Flight Permission Agents All Ground Handling Agents\\n\\n## Copy to:\\n\\n- Joint Secretary II, Aviation Division; Islamabad\\n- PSO to DG CAA; HQCAA, Karachi\\n- Additional Deputy DGCAA, HQCAA, Karachi\\n- All Chief Operating Officers/Airport Managers\\n- Director Operations, ASF, ASF HQ; Karachi\\n\\n<!-- image -->\\n\\n## HEADQUARTERS PAKISTAN CIVIL AVIATION AUTHORITY\\n\\nTerminal-1 JIAP , Karachi-75200\\n\\nTel: (92-21) 9924-2033\\n\\nFax: (92-21) 9924-2032\\n\\ndairtransport @caapakistan compk\\n\\nRef: HQCAA10895O1AINR\\n\\nJuly 12 2021\\n\\n## IMPLEMENIATION OF STANDARD OPERATING PROCEDURES PRIVATE AIRCRAFT FLIGHTS\\n\\nReference is made to our letter of even number dated June 12 and 29, 2021  providing  guidelines on inbound travel to Pakistan from Categorized Country Lists.\\n\\n- 2 The instructions and guidelines coriained in our above-referred letters are hereby extended upto July 31, 2021. Consequently; all Pakistanis whose return to Pakistan from Category C Countries is scheduled till July 31, 2021 may travel to Pakistan wilhout grant of a special   exemption and while in possession of a valid negative PCR Test Result conducted within the 72 hours to commencement of travel to Pakistan, subject to conformance with all other applicable rules / regulations. 'bound travel to Pakistan from Category € Countries for all other passengers will continue to remain banned. prior\\n- 3 or all passengers arriving in Pakistan will, however; be subjected t0 Testing and Quarantine stipulations as per procedure in-vogue. Any\\n- 4 All concerned are directed t0 ensure strict compliance\\n\\nAir Copimodore\\n\\n(IRFAN SABIR) (Retd:)\\n\\nDirector AT &amp; ER\\n\\n<!-- image -->\\n\\nAll Scheduled and Charter Air Carriers\\n\\nAll Private Operators All Authorized Flight Permission Agents All Ground Handling Agents\\n\\n## Copy\\n\\n- Joint Secretary II, Aviation Division; Islamabad\\n- PSO to DG CAA; HQCAA; Karachi\\n- Additional Deputy DGCAA, HQCAA, Karachi\\n- All Chief Operating Officers/Airport Managers\\n- Director Operations; ASF, ASF HQ, Karachi\\n\\n<!-- image -->\\n\\n## HEADQUARTERS PAKISTAN CIVIL AVIATION AUTHORITY\\n\\nTerminal-1 JIAP , Karachi-75200\\n\\nTel: (92-21) 9924-2033\\n\\nFax: (92-21) 9924-2032\\n\\ndairtransport@caapakistan com pk\\n\\nJune 29 2021\\n\\n## IMPLEMENTATION OF STANDARD OPERATING PROCEDURES PRIVATE AIRCRAFTFLIGHIS\\n\\nReference our letter of even number dated June 12, 2021 containing Categorized   Country Lists and guidelines   concerning inbound travel to Pakistan.\\n\\n- 2 The instructions and guidelines contained in our above-referred letter are hereby extended upto July 15, 2021. Consequently; all Pakistanis may return to Pakistan from Category C Countries upto July 15, 2021 while in possession of valid negative PCR Test Result conducted within the 72 hours to commencement of travel to Pakistan; subject to conformance with all other applicable rules regulations. Inbound travel t0 Pakistan from Category € Countries for all other passengers will continue to remain banned. prior\\n- 3 or all passengers arriving in Pakistan will, however; be subjected to Testing and Quarantine stipulations as per procedure in-vogue. Any\\n- 4 All concerned are directed to ensure strict compliance.\\n\\n<!-- image -->\\n\\nAll Scheduled and Charter Airline Operators All Ground Handling Agents All Private Operators All Authorized Flight Permission Agents\\n\\n- Joint Secretary II, Aviation Division; Islamabad\\n- Director Security, HQCAA, Karachi\\n- Additional Deputy DGCAA (Reg), HQCAA; Karachi\\n- PSO to DGCAA, HQCAA, Karachi\\n- All Chief Operating OfficerslAirport Managers\\n\\n<!-- image -->\\n\\n## HEADQUARTERS PAKISTAN CIVIL AVIATION AUTHORITY\\n\\nTerminal-1 JIAP , Karachi-75200\\n\\nTel: (92-21) 9924-2033\\n\\nFax: (92-21) 9924-2032\\n\\ndairtransport@caapakistan com pk\\n\\nJune 12 2021\\n\\n## IMPLEMENTATION OF STANDARD OPERATING PROCEDURES PRIVATE AIRCRAFTFLIGHIS\\n\\nReference our   letter of even number  dated 22 and 23, 2021 containing Categorized Country Lists and guidelines concerning inbound travel to Pakistan. May\\n\\n- 2 Revised Category C Country List duly approved by the Competent Authority is enclosed herewith and will become effective immediately. Accordingly; travel to Pakistan from Category C Countries will   continue to remain banned and only allowed subject to grant of special exemption from the NCOC Exemptions Committee. being\\n- 3. Notwithstanding the foregoing; all Pakistanis who have scheduled return to Pakistan from Category C Countries in the month of June; 2021 will be allowed to travel to Pakistan and will be exempted from the inbound travel ban placed on Category C Countries. Such passengers will; however be subjected to Testing and Quarantine stipulations upon arrival in Pakistan as per procedure in-vogue.\\n- 4 . All concerned are directed to ensure strict compliance.\\n\\n<!-- image -->\\n\\nAll Scheduled and Charter Airline Operators All Ground Handling Agents All Private Operators All Authorized Flight Permission Agents\\n\\n## Copy\\n\\n- Additional Deputy DGCAA (Reg) HQCAA, Karachi\\n- Joint Secretary II, Aviation Division; Islamabad\\n- Director Security; HQCAA, Karachi\\n- All Chief Operating OfficerslAirport Managers\\n- PSO t0 DGCAA, HQCAA, Karachi\\n- Director Operations, Airports Security Force; ASF HQ; Karachi\\n\\n## UPDATED LISI JUNE 12 2021 VALID WITH IMMEDIATEEFFECI\\n\\nINTERNATIONAL TRAVELLERS FROM ANY COUNTRY ARE REQUIRED TO POSSESS VALID NEGATIVE PCR TEST CERTIFICATION CONDUCTED WITHIN THE 72 HOURS PRIOR TO COMMENCEMENT OF TRAVEL TO PAKISTAN\\n\\n## CATEGORYC\\n\\nINTERNATIONAL TRAVEL TO PAKISTAN FROM CATEGORY c COUNTRIES MENTIONED BELOW IS BANNED AND ONLY ALLOWED SUBJECT TO EXEMPTION BY COMMITTEE AS PER PROCEDURE IN VOGUE\\n\\n|   Sr . | Country            |\\n|--------|--------------------|\\n|     01 | Arqentina          |\\n|     02 | Bangladesh         |\\n|     03 | Bhutan             |\\n|     04 | Bolivia            |\\n|     05 | Brazil             |\\n|     06 | Chile              |\\n|     07 | Colombia           |\\n|     08 | Costa Rica         |\\n|     09 | Dominican Republic |\\n|     10 | Ecuador            |\\n|     11 | India              |\\n|     12 | Indonesia          |\\n|     13 | Iran               |\\n|     14 | Iraq               |\\n|     15 | Maldives           |\\n|     16 | Mexico             |\\n|     17 | Namibia            |\\n|     18 | Nepal              |\\n|     19 | Paraquay           |\\n|     20 | Peru               |\\n|     21 | Philippines        |\\n|     22 | South Africa       |\\n|     23 | Sri Lanka          |\\n|     24 | Trinidadand Tobago |\\n|     25 | Tunisia            |\\n|     26 | Uruquay            |\\n\\nNote: Pakistani whose return from Category C countries is scheduled in June 2021 have been excluded from exemption process. However, will undergo already emplaced inbound testing / Quarantine protocols. they\"}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Define the directory containing your Markdown files\n",
    "# --- MAKE SURE THIS PATH IS EXACTLY CORRECT ---\n",
    "markdown_dir = '/home/ai-research-lab/MCSProjectbyWajahatalibasharat5Percent/LLaMA-Factory/data/Markdown/'\n",
    "\n",
    "# Define the output JSONL file path within the 'data' directory\n",
    "# (It's good practice to keep processed data directly in 'data' or a 'processed_data' subfolder)\n",
    "output_jsonl_path = '/home/ai-research-lab/MCSProjectbyWajahatalibasharat5Percent/LLaMA-Factory/data/markdown_docs.jsonl'\n",
    "\n",
    "# Ensure the parent directory for output_jsonl_path exists\n",
    "os.makedirs(os.path.dirname(output_jsonl_path), exist_ok=True)\n",
    "\n",
    "\n",
    "# Collect text from Markdown files\n",
    "markdown_samples = []\n",
    "# Check if the markdown_dir exists\n",
    "if not os.path.exists(markdown_dir):\n",
    "    print(f\"Error: Markdown directory not found at {markdown_dir}\")\n",
    "else:\n",
    "    print(f\"Scanning Markdown files in: {markdown_dir}\")\n",
    "    for filename in os.listdir(markdown_dir):\n",
    "        if filename.endswith(\".md\"):\n",
    "            filepath = os.path.join(markdown_dir, filename)\n",
    "            try:\n",
    "                with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                    content = f.read()\n",
    "                    if content.strip(): # Only add non-empty files after stripping whitespace\n",
    "                        markdown_samples.append({'text': content})\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {filepath}: {e}\")\n",
    "\n",
    "# Save to JSONL\n",
    "if markdown_samples:\n",
    "    with open(output_jsonl_path, 'w', encoding='utf-8') as f:\n",
    "        for sample in markdown_samples:\n",
    "            f.write(json.dumps(sample, ensure_ascii=False) + '\\n')\n",
    "    print(f\"Collected {len(markdown_samples)} markdown documents and saved to {output_jsonl_path}\")\n",
    "\n",
    "    # Optional: Verify first few lines\n",
    "    print(\"\\nFirst 3 lines of markdown_docs.jsonl:\")\n",
    "    with open(output_jsonl_path, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i >= 3:\n",
    "                break\n",
    "            print(line.strip())\n",
    "else:\n",
    "    print(f\"No Markdown files found or processed in {markdown_dir}. Check the directory and file extensions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "085eda19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing /home/ai-research-lab/MCSProjectbyWajahatalibasharat5Percent/LLaMA-Factory/data/dataset_info.json successfully.\n",
      "\n",
      "Successfully updated /home/ai-research-lab/MCSProjectbyWajahatalibasharat5Percent/LLaMA-Factory/data/dataset_info.json with 'wiki_5percent' and 'markdown_docs' entries.\n",
      "\n",
      "--- Current content of dataset_info.json ---\n",
      "{\n",
      "  \"identity\": {\n",
      "    \"file_name\": \"identity.json\"\n",
      "  },\n",
      "  \"alpaca_en_demo\": {\n",
      "    \"file_name\": \"alpaca_en_demo.json\"\n",
      "  },\n",
      "  \"alpaca_zh_demo\": {\n",
      "    \"file_name\": \"alpaca_zh_demo.json\"\n",
      "  },\n",
      "  \"glaive_toolcall_en_demo\": {\n",
      "    \"file_name\": \"glaive_toolcall_en_demo.json\",\n",
      "    \"formatting\": \"sharegpt\",\n",
      "    \"columns\": {\n",
      "      \"messages\": \"conversations\",\n",
      "      \"tools\": \"tools\"\n",
      "    }\n",
      "  },\n",
      "  \"glaive_toolcall_zh_demo\": {\n",
      "    \"file_name\": \"glaive_toolcall_zh_demo.json\",\n",
      "    \"formatting\": \"sharegpt\",\n",
      "    \"columns\": {\n",
      "      \"messages\": \"conversations\",\n",
      "      \"tools\": \"tools\"\n",
      "    }\n",
      "  },\n",
      "  \"mllm_demo\": {\n",
      "    \"file_name\": \"mllm_demo.json\",\n",
      "    \"formatting\": \"sharegpt\",\n",
      "    \"columns\": {\n",
      "      \"messages\": \"messages\",\n",
      "      \"images\": \"images\"\n",
      "    },\n",
      "    \"tags\": {\n",
      "      \"role_tag\": \"role\",\n",
      "      \"content_tag\": \"content\",\n",
      "      \"user_tag\": \"user\",\n",
      "      \"assistant_tag\": \"assistant\"\n",
      "    }\n",
      "  },\n",
      "  \"mllm_audio_demo\": {\n",
      "    \"file_name\": \"mllm_audio_demo.json\",\n",
      "    \"formatting\": \"sharegpt\",\n",
      "    \"columns\": {\n",
      "      \"messages\": \"messages\",\n",
      "      \"audios\": \"audios\"\n",
      "    },\n",
      "    \"tags\": {\n",
      "      \"role_tag\": \"role\",\n",
      "      \"content_tag\": \"content\",\n",
      "      \"user_tag\": \"user\",\n",
      "      \"assistant_tag\": \"assistant\"\n",
      "    }\n",
      "  },\n",
      "  \"mllm_video_demo\": {\n",
      "    \"file_name\": \"mllm_video_demo.json\",\n",
      "    \"formatting\": \"sharegpt\",\n",
      "    \"columns\": {\n",
      "      \"messages\": \"messages\",\n",
      "      \"videos\": \"videos\"\n",
      "    },\n",
      "    \"tags\": {\n",
      "      \"role_tag\": \"role\",\n",
      "      \"content_tag\": \"content\",\n",
      "      \"user_tag\": \"user\",\n",
      "      \"assistant_tag\": \"assistant\"\n",
      "    }\n",
      "  },\n",
      "  \"mllm_video_audio_demo\": {\n",
      "    \"file_name\": \"mllm_video_audio_demo.json\",\n",
      "    \"formatting\": \"sharegpt\",\n",
      "    \"columns\": {\n",
      "      \"messages\": \"messages\",\n",
      "      \"videos\": \"videos\",\n",
      "      \"audios\": \"audios\"\n",
      "    },\n",
      "    \"tags\": {\n",
      "      \"role_tag\": \"role\",\n",
      "      \"content_tag\": \"content\",\n",
      "      \"user_tag\": \"user\",\n",
      "      \"assistant_tag\": \"assistant\"\n",
      "    }\n",
      "  },\n",
      "  \"alpaca_en\": {\n",
      "    \"hf_hub_url\": \"llamafactory/alpaca_en\",\n",
      "    \"ms_hub_url\": \"llamafactory/alpaca_en\",\n",
      "    \"om_hub_url\": \"HaM/alpaca_en\"\n",
      "  },\n",
      "  \"alpaca_zh\": {\n",
      "    \"hf_hub_url\": \"llamafactory/alpaca_zh\",\n",
      "    \"ms_hub_url\": \"llamafactory/alpaca_zh\"\n",
      "  },\n",
      "  \"alpaca_gpt4_en\": {\n",
      "    \"hf_hub_url\": \"llamafactory/alpaca_gpt4_en\",\n",
      "    \"ms_hub_url\": \"llamafactory/alpaca_gpt4_en\"\n",
      "  },\n",
      "  \"alpaca_gpt4_zh\": {\n",
      "    \"hf_hub_url\": \"llamafactory/alpaca_gpt4_zh\",\n",
      "    \"ms_hub_url\": \"llamafactory/alpaca_gpt4_zh\",\n",
      "    \"om_hub_url\": \"State_Cloud/alpaca-gpt4-data-zh\"\n",
      "  },\n",
      "  \"glaive_toolcall_en\": {\n",
      "    \"hf_hub_url\": \"llamafactory/glaive_toolcall_en\",\n",
      "    \"formatting\": \"sharegpt\",\n",
      "    \"columns\": {\n",
      "      \"messages\": \"conversations\",\n",
      "      \"tools\": \"tools\"\n",
      "    }\n",
      "  },\n",
      "  \"glaive_toolcall_zh\": {\n",
      "    \"hf_hub_url\": \"llamafactory/glaive_toolcall_zh\",\n",
      "    \"formatting\": \"sharegpt\",\n",
      "    \"columns\": {\n",
      "      \"messages\": \"conversations\",\n",
      "      \"tools\": \"tools\"\n",
      "    }\n",
      "  },\n",
      "  \"lima\": {\n",
      "    \"hf_hub_url\": \"llamafactory/lima\",\n",
      "    \"formatting\": \"sharegpt\"\n",
      "  },\n",
      "  \"guanaco\": {\n",
      "    \"hf_hub_url\": \"JosephusCheung/GuanacoDataset\",\n",
      "    \"ms_hub_url\": \"AI-ModelScope/GuanacoDataset\"\n",
      "  },\n",
      "  \"belle_2m\": {\n",
      "    \"hf_hub_url\": \"BelleGroup/train_2M_CN\",\n",
      "    \"ms_hub_url\": \"AI-ModelScope/train_2M_CN\"\n",
      "  },\n",
      "  \"belle_1m\": {\n",
      "    \"hf_hub_url\": \"BelleGroup/train_1M_CN\",\n",
      "    \"ms_hub_url\": \"AI-ModelScope/train_1M_CN\"\n",
      "  },\n",
      "  \"belle_0.5m\": {\n",
      "    \"hf_hub_url\": \"BelleGroup/train_0.5M_CN\",\n",
      "    \"ms_hub_url\": \"AI-ModelScope/train_0.5M_CN\"\n",
      "  },\n",
      "  \"belle_dialog\": {\n",
      "    \"hf_hub_url\": \"BelleGroup/generated_chat_0.4M\",\n",
      "    \"ms_hub_url\": \"AI-ModelScope/generated_chat_0.4M\"\n",
      "  },\n",
      "  \"belle_math\": {\n",
      "    \"hf_hub_url\": \"BelleGroup/school_math_0.25M\",\n",
      "    \"ms_hub_url\": \"AI-ModelScope/school_math_0.25M\"\n",
      "  },\n",
      "  \"belle_multiturn\": {\n",
      "    \"script_url\": \"belle_multiturn\",\n",
      "    \"formatting\": \"sharegpt\"\n",
      "  },\n",
      "  \"ultra_chat\": {\n",
      "    \"script_url\": \"ultra_chat\",\n",
      "    \"formatting\": \"sharegpt\"\n",
      "  },\n",
      "  \"open_platypus\": {\n",
      "    \"hf_hub_url\": \"garage-bAInd/Open-Platypus\",\n",
      "    \"ms_hub_url\": \"AI-ModelScope/Open-Platypus\"\n",
      "  },\n",
      "  \"codealpaca\": {\n",
      "    \"hf_hub_url\": \"sahil2801/CodeAlpaca-20k\",\n",
      "    \"ms_hub_url\": \"AI-ModelScope/CodeAlpaca-20k\"\n",
      "  },\n",
      "  \"alpaca_cot\": {\n",
      "    \"hf_hub_url\": \"QingyiSi/Alpaca-CoT\",\n",
      "    \"ms_hub_url\": \"AI-ModelScope/Alpaca-CoT\"\n",
      "  },\n",
      "  \"openorca\": {\n",
      "    \"hf_hub_url\": \"Open-Orca/OpenOrca\",\n",
      "    \"ms_hub_url\": \"AI-ModelScope/OpenOrca\",\n",
      "    \"columns\": {\n",
      "      \"prompt\": \"question\",\n",
      "      \"response\": \"response\",\n",
      "      \"system\": \"system_prompt\"\n",
      "    }\n",
      "  },\n",
      "  \"slimorca\": {\n",
      "    \"hf_hub_url\": \"Open-Orca/SlimOrca\",\n",
      "    \"formatting\": \"sharegpt\"\n",
      "  },\n",
      "  \"mathinstruct\": {\n",
      "    \"hf_hub_url\": \"TIGER-Lab/MathInstruct\",\n",
      "    \"ms_hub_url\": \"AI-ModelScope/MathInstruct\",\n",
      "    \"columns\": {\n",
      "      \"prompt\": \"instruction\",\n",
      "      \"response\": \"output\"\n",
      "    }\n",
      "  },\n",
      "  \"firefly\": {\n",
      "    \"hf_hub_url\": \"YeungNLP/firefly-train-1.1M\",\n",
      "    \"columns\": {\n",
      "      \"prompt\": \"input\",\n",
      "      \"response\": \"target\"\n",
      "    }\n",
      "  },\n",
      "  \"wikiqa\": {\n",
      "    \"hf_hub_url\": \"wiki_qa\",\n",
      "    \"columns\": {\n",
      "      \"prompt\": \"question\",\n",
      "      \"response\": \"answer\"\n",
      "    }\n",
      "  },\n",
      "  \"webqa\": {\n",
      "    \"hf_hub_url\": \"suolyer/webqa\",\n",
      "    \"ms_hub_url\": \"AI-ModelScope/webqa\",\n",
      "    \"columns\": {\n",
      "      \"prompt\": \"input\",\n",
      "      \"response\": \"output\"\n",
      "    }\n",
      "  },\n",
      "  \"webnovel\": {\n",
      "    \"hf_hub_url\": \"zxbsmk/webnovel_cn\",\n",
      "    \"ms_hub_url\": \"AI-ModelScope/webnovel_cn\"\n",
      "  },\n",
      "  \"nectar_sft\": {\n",
      "    \"hf_hub_url\": \"AstraMindAI/SFT-Nectar\",\n",
      "    \"ms_hub_url\": \"AI-ModelScope/SFT-Nectar\"\n",
      "  },\n",
      "  \"deepctrl\": {\n",
      "    \"ms_hub_url\": \"deepctrl/deepctrl-sft-data\"\n",
      "  },\n",
      "  \"adgen_train\": {\n",
      "    \"hf_hub_url\": \"HasturOfficial/adgen\",\n",
      "    \"ms_hub_url\": \"AI-ModelScope/adgen\",\n",
      "    \"split\": \"train\",\n",
      "    \"columns\": {\n",
      "      \"prompt\": \"content\",\n",
      "      \"response\": \"summary\"\n",
      "    }\n",
      "  },\n",
      "  \"adgen_eval\": {\n",
      "    \"hf_hub_url\": \"HasturOfficial/adgen\",\n",
      "    \"ms_hub_url\": \"AI-ModelScope/adgen\",\n",
      "    \"split\": \"validation\",\n",
      "    \"columns\": {\n",
      "      \"prompt\": \"content\",\n",
      "      \"response\": \"summary\"\n",
      "    }\n",
      "  },\n",
      "  \"sharegpt_hyper\": {\n",
      "    \"hf_hub_url\": \"totally-not-an-llm/sharegpt-hyperfiltered-3k\",\n",
      "    \"formatting\": \"sharegpt\"\n",
      "  },\n",
      "  \"sharegpt4\": {\n",
      "    \"hf_hub_url\": \"shibing624/sharegpt_gpt4\",\n",
      "    \"ms_hub_url\": \"AI-ModelScope/sharegpt_gpt4\",\n",
      "    \"formatting\": \"sharegpt\"\n",
      "  },\n",
      "  \"ultrachat_200k\": {\n",
      "    \"hf_hub_url\": \"HuggingFaceH4/ultrachat_200k\",\n",
      "    \"ms_hub_url\": \"AI-ModelScope/ultrachat_200k\",\n",
      "    \"split\": \"train_sft\",\n",
      "    \"formatting\": \"sharegpt\",\n",
      "    \"columns\": {\n",
      "      \"messages\": \"messages\"\n",
      "    },\n",
      "    \"tags\": {\n",
      "      \"role_tag\": \"role\",\n",
      "      \"content_tag\": \"content\",\n",
      "      \"user_tag\": \"user\",\n",
      "      \"assistant_tag\": \"assistant\"\n",
      "    }\n",
      "  },\n",
      "  \"agent_instruct\": {\n",
      "    \"hf_hub_url\": \"THUDM/AgentInstruct\",\n",
      "    \"ms_hub_url\": \"ZhipuAI/AgentInstruct\",\n",
      "    \"formatting\": \"sharegpt\"\n",
      "  },\n",
      "  \"lmsys_chat\": {\n",
      "    \"hf_hub_url\": \"lmsys/lmsys-chat-1m\",\n",
      "    \"ms_hub_url\": \"AI-ModelScope/lmsys-chat-1m\",\n",
      "    \"formatting\": \"sharegpt\",\n",
      "    \"columns\": {\n",
      "      \"messages\": \"conversation\"\n",
      "    },\n",
      "    \"tags\": {\n",
      "      \"role_tag\": \"role\",\n",
      "      \"content_tag\": \"content\",\n",
      "      \"user_tag\": \"user\",\n",
      "      \"assistant_tag\": \"assistant\"\n",
      "    }\n",
      "  },\n",
      "  \"evol_instruct\": {\n",
      "    \"hf_hub_url\": \"WizardLM/WizardLM_evol_instruct_V2_196k\",\n",
      "    \"ms_hub_url\": \"AI-ModelScope/WizardLM_evol_instruct_V2_196k\",\n",
      "    \"formatting\": \"sharegpt\"\n",
      "  },\n",
      "  \"glaive_toolcall_100k\": {\n",
      "    \"hf_hub_url\": \"hiyouga/glaive-function-calling-v2-sharegpt\",\n",
      "    \"formatting\": \"sharegpt\",\n",
      "    \"columns\": {\n",
      "      \"messages\": \"conversations\",\n",
      "      \"tools\": \"tools\"\n",
      "    }\n",
      "  },\n",
      "  \"cosmopedia\": {\n",
      "    \"hf_hub_url\": \"HuggingFaceTB/cosmopedia\",\n",
      "    \"columns\": {\n",
      "      \"prompt\": \"prompt\",\n",
      "      \"response\": \"text\"\n",
      "    }\n",
      "  },\n",
      "  \"stem_zh\": {\n",
      "    \"hf_hub_url\": \"hfl/stem_zh_instruction\"\n",
      "  },\n",
      "  \"ruozhiba_gpt4\": {\n",
      "    \"hf_hub_url\": \"hfl/ruozhiba_gpt4_turbo\"\n",
      "  },\n",
      "  \"neo_sft\": {\n",
      "    \"hf_hub_url\": \"m-a-p/neo_sft_phase2\",\n",
      "    \"formatting\": \"sharegpt\"\n",
      "  },\n",
      "  \"magpie_pro_300k\": {\n",
      "    \"hf_hub_url\": \"Magpie-Align/Magpie-Pro-300K-Filtered\",\n",
      "    \"formatting\": \"sharegpt\"\n",
      "  },\n",
      "  \"magpie_ultra\": {\n",
      "    \"hf_hub_url\": \"argilla/magpie-ultra-v0.1\",\n",
      "    \"columns\": {\n",
      "      \"prompt\": \"instruction\",\n",
      "      \"response\": \"response\"\n",
      "    }\n",
      "  },\n",
      "  \"web_instruct\": {\n",
      "    \"hf_hub_url\": \"TIGER-Lab/WebInstructSub\",\n",
      "    \"columns\": {\n",
      "      \"prompt\": \"question\",\n",
      "      \"response\": \"answer\"\n",
      "    }\n",
      "  },\n",
      "  \"openo1_sft\": {\n",
      "    \"hf_hub_url\": \"llamafactory/OpenO1-SFT\",\n",
      "    \"ms_hub_url\": \"llamafactory/OpenO1-SFT\",\n",
      "    \"columns\": {\n",
      "      \"prompt\": \"prompt\",\n",
      "      \"response\": \"response\"\n",
      "    }\n",
      "  },\n",
      "  \"open_thoughts\": {\n",
      "    \"hf_hub_url\": \"llamafactory/OpenThoughts-114k\",\n",
      "    \"formatting\": \"sharegpt\",\n",
      "    \"columns\": {\n",
      "      \"messages\": \"messages\"\n",
      "    },\n",
      "    \"tags\": {\n",
      "      \"role_tag\": \"role\",\n",
      "      \"content_tag\": \"content\",\n",
      "      \"user_tag\": \"user\",\n",
      "      \"assistant_tag\": \"assistant\",\n",
      "      \"system_tag\": \"system\"\n",
      "    }\n",
      "  },\n",
      "  \"open_r1_math\": {\n",
      "    \"hf_hub_url\": \"llamafactory/OpenR1-Math-94k\",\n",
      "    \"formatting\": \"sharegpt\",\n",
      "    \"columns\": {\n",
      "      \"messages\": \"messages\"\n",
      "    },\n",
      "    \"tags\": {\n",
      "      \"role_tag\": \"role\",\n",
      "      \"content_tag\": \"content\",\n",
      "      \"user_tag\": \"user\",\n",
      "      \"assistant_tag\": \"assistant\",\n",
      "      \"system_tag\": \"system\"\n",
      "    }\n",
      "  },\n",
      "  \"chinese_r1_distill\": {\n",
      "    \"hf_hub_url\": \"Congliu/Chinese-DeepSeek-R1-Distill-data-110k-SFT\",\n",
      "    \"ms_hub_url\": \"liucong/Chinese-DeepSeek-R1-Distill-data-110k-SFT\"\n",
      "  },\n",
      "  \"llava_1k_en\": {\n",
      "    \"hf_hub_url\": \"BUAADreamer/llava-en-zh-2k\",\n",
      "    \"subset\": \"en\",\n",
      "    \"formatting\": \"sharegpt\",\n",
      "    \"columns\": {\n",
      "      \"messages\": \"messages\",\n",
      "      \"images\": \"images\"\n",
      "    },\n",
      "    \"tags\": {\n",
      "      \"role_tag\": \"role\",\n",
      "      \"content_tag\": \"content\",\n",
      "      \"user_tag\": \"user\",\n",
      "      \"assistant_tag\": \"assistant\"\n",
      "    }\n",
      "  },\n",
      "  \"llava_1k_zh\": {\n",
      "    \"hf_hub_url\": \"BUAADreamer/llava-en-zh-2k\",\n",
      "    \"subset\": \"zh\",\n",
      "    \"formatting\": \"sharegpt\",\n",
      "    \"columns\": {\n",
      "      \"messages\": \"messages\",\n",
      "      \"images\": \"images\"\n",
      "    },\n",
      "    \"tags\": {\n",
      "      \"role_tag\": \"role\",\n",
      "      \"content_tag\": \"content\",\n",
      "      \"user_tag\": \"user\",\n",
      "      \"assistant_tag\": \"assistant\"\n",
      "    }\n",
      "  },\n",
      "  \"llava_150k_en\": {\n",
      "    \"hf_hub_url\": \"BUAADreamer/llava-en-zh-300k\",\n",
      "    \"subset\": \"en\",\n",
      "    \"formatting\": \"sharegpt\",\n",
      "    \"columns\": {\n",
      "      \"messages\": \"messages\",\n",
      "      \"images\": \"images\"\n",
      "    },\n",
      "    \"tags\": {\n",
      "      \"role_tag\": \"role\",\n",
      "      \"content_tag\": \"content\",\n",
      "      \"user_tag\": \"user\",\n",
      "      \"assistant_tag\": \"assistant\"\n",
      "    }\n",
      "  },\n",
      "  \"llava_150k_zh\": {\n",
      "    \"hf_hub_url\": \"BUAADreamer/llava-en-zh-300k\",\n",
      "    \"subset\": \"zh\",\n",
      "    \"formatting\": \"sharegpt\",\n",
      "    \"columns\": {\n",
      "      \"messages\": \"messages\",\n",
      "      \"images\": \"images\"\n",
      "    },\n",
      "    \"tags\": {\n",
      "      \"role_tag\": \"role\",\n",
      "      \"content_tag\": \"content\",\n",
      "      \"user_tag\": \"user\",\n",
      "      \"assistant_tag\": \"assistant\"\n",
      "    }\n",
      "  },\n",
      "  \"pokemon_cap\": {\n",
      "    \"hf_hub_url\": \"llamafactory/pokemon-gpt4o-captions\",\n",
      "    \"formatting\": \"sharegpt\",\n",
      "    \"columns\": {\n",
      "      \"messages\": \"conversations\",\n",
      "      \"images\": \"images\"\n",
      "    }\n",
      "  },\n",
      "  \"mllm_pt_demo\": {\n",
      "    \"hf_hub_url\": \"BUAADreamer/mllm_pt_demo\",\n",
      "    \"formatting\": \"sharegpt\",\n",
      "    \"columns\": {\n",
      "      \"messages\": \"messages\",\n",
      "      \"images\": \"images\"\n",
      "    },\n",
      "    \"tags\": {\n",
      "      \"role_tag\": \"role\",\n",
      "      \"content_tag\": \"content\",\n",
      "      \"user_tag\": \"user\",\n",
      "      \"assistant_tag\": \"assistant\"\n",
      "    }\n",
      "  },\n",
      "  \"oasst_de\": {\n",
      "    \"hf_hub_url\": \"mayflowergmbh/oasst_de\"\n",
      "  },\n",
      "  \"dolly_15k_de\": {\n",
      "    \"hf_hub_url\": \"mayflowergmbh/dolly-15k_de\"\n",
      "  },\n",
      "  \"alpaca-gpt4_de\": {\n",
      "    \"hf_hub_url\": \"mayflowergmbh/alpaca-gpt4_de\"\n",
      "  },\n",
      "  \"openschnabeltier_de\": {\n",
      "    \"hf_hub_url\": \"mayflowergmbh/openschnabeltier_de\"\n",
      "  },\n",
      "  \"evol_instruct_de\": {\n",
      "    \"hf_hub_url\": \"mayflowergmbh/evol-instruct_de\"\n",
      "  },\n",
      "  \"dolphin_de\": {\n",
      "    \"hf_hub_url\": \"mayflowergmbh/dolphin_de\"\n",
      "  },\n",
      "  \"booksum_de\": {\n",
      "    \"hf_hub_url\": \"mayflowergmbh/booksum_de\"\n",
      "  },\n",
      "  \"airoboros_de\": {\n",
      "    \"hf_hub_url\": \"mayflowergmbh/airoboros-3.0_de\"\n",
      "  },\n",
      "  \"ultrachat_de\": {\n",
      "    \"hf_hub_url\": \"mayflowergmbh/ultra-chat_de\"\n",
      "  },\n",
      "  \"dpo_en_demo\": {\n",
      "    \"file_name\": \"dpo_en_demo.json\",\n",
      "    \"ranking\": true,\n",
      "    \"formatting\": \"sharegpt\",\n",
      "    \"columns\": {\n",
      "      \"messages\": \"conversations\",\n",
      "      \"chosen\": \"chosen\",\n",
      "      \"rejected\": \"rejected\"\n",
      "    }\n",
      "  },\n",
      "  \"dpo_zh_demo\": {\n",
      "    \"file_name\": \"dpo_zh_demo.json\",\n",
      "    \"ranking\": true,\n",
      "    \"formatting\": \"sharegpt\",\n",
      "    \"columns\": {\n",
      "      \"messages\": \"conversations\",\n",
      "      \"chosen\": \"chosen\",\n",
      "      \"rejected\": \"rejected\"\n",
      "    }\n",
      "  },\n",
      "  \"dpo_mix_en\": {\n",
      "    \"hf_hub_url\": \"llamafactory/DPO-En-Zh-20k\",\n",
      "    \"subset\": \"en\",\n",
      "    \"ranking\": true,\n",
      "    \"formatting\": \"sharegpt\",\n",
      "    \"columns\": {\n",
      "      \"messages\": \"conversations\",\n",
      "      \"chosen\": \"chosen\",\n",
      "      \"rejected\": \"rejected\"\n",
      "    }\n",
      "  },\n",
      "  \"dpo_mix_zh\": {\n",
      "    \"hf_hub_url\": \"llamafactory/DPO-En-Zh-20k\",\n",
      "    \"subset\": \"zh\",\n",
      "    \"ranking\": true,\n",
      "    \"formatting\": \"sharegpt\",\n",
      "    \"columns\": {\n",
      "      \"messages\": \"conversations\",\n",
      "      \"chosen\": \"chosen\",\n",
      "      \"rejected\": \"rejected\"\n",
      "    }\n",
      "  },\n",
      "  \"ultrafeedback\": {\n",
      "    \"hf_hub_url\": \"llamafactory/ultrafeedback_binarized\",\n",
      "    \"ms_hub_url\": \"llamafactory/ultrafeedback_binarized\",\n",
      "    \"ranking\": true,\n",
      "    \"columns\": {\n",
      "      \"prompt\": \"instruction\",\n",
      "      \"chosen\": \"chosen\",\n",
      "      \"rejected\": \"rejected\"\n",
      "    }\n",
      "  },\n",
      "  \"coig_p\": {\n",
      "    \"hf_hub_url\": \"m-a-p/COIG-P\",\n",
      "    \"ranking\": true,\n",
      "    \"formatting\": \"sharegpt\",\n",
      "    \"columns\": {\n",
      "      \"messages\": \"conversations\",\n",
      "      \"chosen\": \"chosen\",\n",
      "      \"rejected\": \"rejected\"\n",
      "    }\n",
      "  },\n",
      "  \"rlhf_v\": {\n",
      "    \"hf_hub_url\": \"llamafactory/RLHF-V\",\n",
      "    \"ranking\": true,\n",
      "    \"formatting\": \"sharegpt\",\n",
      "    \"columns\": {\n",
      "      \"messages\": \"conversations\",\n",
      "      \"chosen\": \"chosen\",\n",
      "      \"rejected\": \"rejected\",\n",
      "      \"images\": \"images\"\n",
      "    }\n",
      "  },\n",
      "  \"vlfeedback\": {\n",
      "    \"hf_hub_url\": \"Zhihui/VLFeedback\",\n",
      "    \"ranking\": true,\n",
      "    \"formatting\": \"sharegpt\",\n",
      "    \"columns\": {\n",
      "      \"messages\": \"conversations\",\n",
      "      \"chosen\": \"chosen\",\n",
      "      \"rejected\": \"rejected\",\n",
      "      \"images\": \"images\"\n",
      "    }\n",
      "  },\n",
      "  \"rlaif_v\": {\n",
      "    \"hf_hub_url\": \"openbmb/RLAIF-V-Dataset\",\n",
      "    \"ranking\": true,\n",
      "    \"columns\": {\n",
      "      \"prompt\": \"question\",\n",
      "      \"chosen\": \"chosen\",\n",
      "      \"rejected\": \"rejected\",\n",
      "      \"images\": \"image\"\n",
      "    }\n",
      "  },\n",
      "  \"orca_pairs\": {\n",
      "    \"hf_hub_url\": \"Intel/orca_dpo_pairs\",\n",
      "    \"ranking\": true,\n",
      "    \"columns\": {\n",
      "      \"prompt\": \"question\",\n",
      "      \"chosen\": \"chosen\",\n",
      "      \"rejected\": \"rejected\",\n",
      "      \"system\": \"system\"\n",
      "    }\n",
      "  },\n",
      "  \"hh_rlhf_en\": {\n",
      "    \"script_url\": \"hh_rlhf_en\",\n",
      "    \"ranking\": true,\n",
      "    \"columns\": {\n",
      "      \"prompt\": \"instruction\",\n",
      "      \"chosen\": \"chosen\",\n",
      "      \"rejected\": \"rejected\",\n",
      "      \"history\": \"history\"\n",
      "    }\n",
      "  },\n",
      "  \"nectar_rm\": {\n",
      "    \"hf_hub_url\": \"AstraMindAI/RLAIF-Nectar\",\n",
      "    \"ms_hub_url\": \"AI-ModelScope/RLAIF-Nectar\",\n",
      "    \"ranking\": true\n",
      "  },\n",
      "  \"orca_dpo_de\": {\n",
      "    \"hf_hub_url\": \"mayflowergmbh/intel_orca_dpo_pairs_de\",\n",
      "    \"ranking\": true\n",
      "  },\n",
      "  \"kto_en_demo\": {\n",
      "    \"file_name\": \"kto_en_demo.json\",\n",
      "    \"formatting\": \"sharegpt\",\n",
      "    \"columns\": {\n",
      "      \"messages\": \"messages\",\n",
      "      \"kto_tag\": \"label\"\n",
      "    },\n",
      "    \"tags\": {\n",
      "      \"role_tag\": \"role\",\n",
      "      \"content_tag\": \"content\",\n",
      "      \"user_tag\": \"user\",\n",
      "      \"assistant_tag\": \"assistant\"\n",
      "    }\n",
      "  },\n",
      "  \"kto_mix_en\": {\n",
      "    \"hf_hub_url\": \"argilla/kto-mix-15k\",\n",
      "    \"formatting\": \"sharegpt\",\n",
      "    \"columns\": {\n",
      "      \"messages\": \"completion\",\n",
      "      \"kto_tag\": \"label\"\n",
      "    },\n",
      "    \"tags\": {\n",
      "      \"role_tag\": \"role\",\n",
      "      \"content_tag\": \"content\",\n",
      "      \"user_tag\": \"user\",\n",
      "      \"assistant_tag\": \"assistant\"\n",
      "    }\n",
      "  },\n",
      "  \"ultrafeedback_kto\": {\n",
      "    \"hf_hub_url\": \"argilla/ultrafeedback-binarized-preferences-cleaned-kto\",\n",
      "    \"ms_hub_url\": \"AI-ModelScope/ultrafeedback-binarized-preferences-cleaned-kto\",\n",
      "    \"columns\": {\n",
      "      \"prompt\": \"prompt\",\n",
      "      \"response\": \"completion\",\n",
      "      \"kto_tag\": \"label\"\n",
      "    }\n",
      "  },\n",
      "  \"wiki_demo\": {\n",
      "    \"file_name\": \"wiki_demo.txt\",\n",
      "    \"columns\": {\n",
      "      \"prompt\": \"text\"\n",
      "    }\n",
      "  },\n",
      "  \"c4_demo\": {\n",
      "    \"file_name\": \"c4_demo.jsonl\",\n",
      "    \"columns\": {\n",
      "      \"prompt\": \"text\"\n",
      "    }\n",
      "  },\n",
      "  \"refinedweb\": {\n",
      "    \"hf_hub_url\": \"tiiuae/falcon-refinedweb\",\n",
      "    \"columns\": {\n",
      "      \"prompt\": \"content\"\n",
      "    }\n",
      "  },\n",
      "  \"redpajama_v2\": {\n",
      "    \"hf_hub_url\": \"togethercomputer/RedPajama-Data-V2\",\n",
      "    \"columns\": {\n",
      "      \"prompt\": \"raw_content\"\n",
      "    },\n",
      "    \"subset\": \"default\"\n",
      "  },\n",
      "  \"wikipedia_en\": {\n",
      "    \"hf_hub_url\": \"olm/olm-wikipedia-20221220\",\n",
      "    \"ms_hub_url\": \"AI-ModelScope/olm-wikipedia-20221220\",\n",
      "    \"columns\": {\n",
      "      \"prompt\": \"text\"\n",
      "    }\n",
      "  },\n",
      "  \"wikipedia_zh\": {\n",
      "    \"hf_hub_url\": \"pleisto/wikipedia-cn-20230720-filtered\",\n",
      "    \"ms_hub_url\": \"AI-ModelScope/wikipedia-cn-20230720-filtered\",\n",
      "    \"columns\": {\n",
      "      \"prompt\": \"completion\"\n",
      "    }\n",
      "  },\n",
      "  \"pile\": {\n",
      "    \"hf_hub_url\": \"monology/pile-uncopyrighted\",\n",
      "    \"ms_hub_url\": \"AI-ModelScope/pile\",\n",
      "    \"columns\": {\n",
      "      \"prompt\": \"text\"\n",
      "    }\n",
      "  },\n",
      "  \"skypile\": {\n",
      "    \"hf_hub_url\": \"Skywork/SkyPile-150B\",\n",
      "    \"ms_hub_url\": \"AI-ModelScope/SkyPile-150B\",\n",
      "    \"columns\": {\n",
      "      \"prompt\": \"text\"\n",
      "    }\n",
      "  },\n",
      "  \"fineweb\": {\n",
      "    \"hf_hub_url\": \"HuggingFaceFW/fineweb\",\n",
      "    \"columns\": {\n",
      "      \"prompt\": \"text\"\n",
      "    }\n",
      "  },\n",
      "  \"fineweb_edu\": {\n",
      "    \"hf_hub_url\": \"HuggingFaceFW/fineweb-edu\",\n",
      "    \"columns\": {\n",
      "      \"prompt\": \"text\"\n",
      "    }\n",
      "  },\n",
      "  \"the_stack\": {\n",
      "    \"hf_hub_url\": \"bigcode/the-stack\",\n",
      "    \"ms_hub_url\": \"AI-ModelScope/the-stack\",\n",
      "    \"columns\": {\n",
      "      \"prompt\": \"content\"\n",
      "    }\n",
      "  },\n",
      "  \"starcoder_python\": {\n",
      "    \"hf_hub_url\": \"bigcode/starcoderdata\",\n",
      "    \"ms_hub_url\": \"AI-ModelScope/starcoderdata\",\n",
      "    \"columns\": {\n",
      "      \"prompt\": \"content\"\n",
      "    },\n",
      "    \"folder\": \"python\"\n",
      "  },\n",
      "  \"wiki_5percent\": {\n",
      "    \"file_name\": \"wiki_5percent.json\",\n",
      "    \"columns\": {\n",
      "      \"prompt\": \"text\"\n",
      "    }\n",
      "  },\n",
      "  \"markdown_docs\": {\n",
      "    \"file_name\": \"markdown_docs.jsonl\",\n",
      "    \"columns\": {\n",
      "      \"prompt\": \"text\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Define the base directory of your LLaMA-Factory installation\n",
    "llama_factory_base_dir = '/home/ai-research-lab/MCSProjectbyWajahatalibasharat5Percent/LLaMA-Factory'\n",
    "data_dir = os.path.join(llama_factory_base_dir, 'data')\n",
    "dataset_info_path = os.path.join(data_dir, 'dataset_info.json')\n",
    "\n",
    "# Define the new entry for your markdown data\n",
    "# This assumes you ran Step 1 and created markdown_docs.jsonl in the 'data' directory\n",
    "new_markdown_entry = {\n",
    "    \"file_name\": \"markdown_docs.jsonl\",\n",
    "    \"columns\": {\n",
    "        \"prompt\": \"text\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Define the updated entry for wiki_1percent\n",
    "# This ensures it has the correct 'columns' and 'formatting' for pre-training\n",
    "updated_wiki_entry = {\n",
    "    \"file_name\": \"wiki_5percent.json\",\n",
    "    \"columns\": {\n",
    "        \"prompt\": \"text\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Load existing dataset_info.json\n",
    "existing_data = {}\n",
    "if os.path.exists(dataset_info_path):\n",
    "    try:\n",
    "        with open(dataset_info_path, 'r', encoding='utf-8') as f:\n",
    "            existing_data = json.load(f)\n",
    "        print(f\"Loaded existing {dataset_info_path} successfully.\")\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Warning: Could not decode existing {dataset_info_path} ({e}). \"\n",
    "              \"Starting with an empty configuration, any previous entries might be lost if not valid JSON.\")\n",
    "        existing_data = {}\n",
    "else:\n",
    "    print(f\"No existing {dataset_info_path} found. Creating a new one.\")\n",
    "    # Ensure the 'data' directory exists if it's not there for some reason\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "# Add or update the entries\n",
    "existing_data[\"wiki_5percent\"] = updated_wiki_entry\n",
    "existing_data[\"markdown_docs\"] = new_markdown_entry\n",
    "\n",
    "# Save the combined content back to the file\n",
    "with open(dataset_info_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(existing_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\nSuccessfully updated {dataset_info_path} with 'wiki_5percent' and 'markdown_docs' entries.\")\n",
    "print(\"\\n--- Current content of dataset_info.json ---\")\n",
    "with open(dataset_info_path, 'r', encoding='utf-8') as f:\n",
    "    print(f.read())\n",
    "print(\"---------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a27bc086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changed\n",
    "import json\n",
    "args = dict(\n",
    "    # model settings\n",
    "    model_name_or_path=\"meta-llama/LLaMA-3.2-3B-Instruct\",\n",
    "    trust_remote_code=True,\n",
    "\n",
    "    # training stage\n",
    "    stage=\"pt\",\n",
    "    do_train=True,\n",
    "    finetuning_type=\"freeze\",\n",
    "    freeze_trainable_layers=4,\n",
    "    freeze_trainable_modules=\"all\",\n",
    "\n",
    "    # dataset settings\n",
    "    dataset=\"wiki_5percent,markdown_docs\",\n",
    "    # dataset=\"wiki_2percent\",\n",
    "    # max_samples=1000,\n",
    "    cutoff_len=2048,\n",
    "    overwrite_cache=True,\n",
    "    preprocessing_num_workers=16,\n",
    "    dataloader_num_workers=4,\n",
    "\n",
    "    # output and checkpointing\n",
    "    output_dir=\"llama3-3b_freeze_5per\",\n",
    "    # output_dir=\"llama3-3b_freeze_1per_8layers\",\n",
    "    logging_steps=10,\n",
    "    overwrite_output_dir=True,\n",
    "    plot_loss=True,\n",
    "    report_to=\"none\",\n",
    "\n",
    "    # optimizer and schedule\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=8,\n",
    "    learning_rate=0.0001,\n",
    "    num_train_epochs=1.0,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_ratio=0.1,\n",
    "\n",
    "    # precision and device\n",
    "    bf16=True,\n",
    "\n",
    "    # distributed training timeout\n",
    "    ddp_timeout=18000,\n",
    "    # deepspeed=\"ds_config.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f0c8f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(args, open(\"CPT_LayerFreezing_5per.json\", \"w\", encoding=\"utf-8\"), indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f6e39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|2025-06-23 09:39:27] llamafactory.cli:143 >> Initializing 2 distributed tasks at: 127.0.0.1:43657\n",
      "W0623 09:39:27.583000 8367 site-packages/torch/distributed/run.py:766] \n",
      "W0623 09:39:27.583000 8367 site-packages/torch/distributed/run.py:766] *****************************************\n",
      "W0623 09:39:27.583000 8367 site-packages/torch/distributed/run.py:766] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0623 09:39:27.583000 8367 site-packages/torch/distributed/run.py:766] *****************************************\n",
      "[INFO|2025-06-23 09:39:29] llamafactory.hparams.parser:406 >> Process rank: 0, world size: 2, device: cuda:0, distributed training: True, compute dtype: torch.bfloat16\n",
      "[INFO|2025-06-23 09:39:30] llamafactory.hparams.parser:406 >> Process rank: 1, world size: 2, device: cuda:1, distributed training: True, compute dtype: torch.bfloat16\n",
      "[INFO|tokenization_utils_base.py:2023] 2025-06-23 09:39:31,447 >> loading file tokenizer.json from cache at /home/ai-research-lab/.cache/huggingface/hub/models--meta-llama--LLaMA-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2023] 2025-06-23 09:39:31,447 >> loading file tokenizer.model from cache at None\n",
      "[INFO|tokenization_utils_base.py:2023] 2025-06-23 09:39:31,447 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2023] 2025-06-23 09:39:31,447 >> loading file special_tokens_map.json from cache at /home/ai-research-lab/.cache/huggingface/hub/models--meta-llama--LLaMA-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2023] 2025-06-23 09:39:31,447 >> loading file tokenizer_config.json from cache at /home/ai-research-lab/.cache/huggingface/hub/models--meta-llama--LLaMA-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2023] 2025-06-23 09:39:31,447 >> loading file chat_template.jinja from cache at None\n",
      "[INFO|tokenization_utils_base.py:2299] 2025-06-23 09:39:31,662 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "[INFO|configuration_utils.py:698] 2025-06-23 09:39:35,510 >> loading configuration file config.json from cache at /home/ai-research-lab/.cache/huggingface/hub/models--meta-llama--LLaMA-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95/config.json\n",
      "[INFO|configuration_utils.py:770] 2025-06-23 09:39:35,511 >> Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128008,\n",
      "    128009\n",
      "  ],\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 131072,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 24,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": {\n",
      "    \"factor\": 32.0,\n",
      "    \"high_freq_factor\": 4.0,\n",
      "    \"low_freq_factor\": 1.0,\n",
      "    \"original_max_position_embeddings\": 8192,\n",
      "    \"rope_type\": \"llama3\"\n",
      "  },\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2023] 2025-06-23 09:39:36,517 >> loading file tokenizer.json from cache at /home/ai-research-lab/.cache/huggingface/hub/models--meta-llama--LLaMA-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2023] 2025-06-23 09:39:36,517 >> loading file tokenizer.model from cache at None\n",
      "[INFO|tokenization_utils_base.py:2023] 2025-06-23 09:39:36,517 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2023] 2025-06-23 09:39:36,517 >> loading file special_tokens_map.json from cache at /home/ai-research-lab/.cache/huggingface/hub/models--meta-llama--LLaMA-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2023] 2025-06-23 09:39:36,517 >> loading file tokenizer_config.json from cache at /home/ai-research-lab/.cache/huggingface/hub/models--meta-llama--LLaMA-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2023] 2025-06-23 09:39:36,517 >> loading file chat_template.jinja from cache at None\n",
      "/home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "  warnings.warn(  # warn only once\n",
      "[rank1]:[W623 09:39:36.162881359 ProcessGroupNCCL.cpp:4718] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.\n",
      "[INFO|tokenization_utils_base.py:2299] 2025-06-23 09:39:36,723 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "[WARNING|2025-06-23 09:39:36] llamafactory.data.template:148 >> `template` was not specified, try parsing the chat template from the tokenizer.\n",
      "[INFO|2025-06-23 09:39:36] llamafactory.data.template:143 >> Add pad token: <|eot_id|>\n",
      "[INFO|2025-06-23 09:39:36] llamafactory.data.loader:143 >> Loading dataset wiki_5percent.json...\n",
      "Converting format of dataset (num_proc=16): 100%|█| 320390/320390 [00:01<00:00, \n",
      "[INFO|2025-06-23 09:39:38] llamafactory.data.loader:143 >> Loading dataset markdown_docs.jsonl...\n",
      "Setting num_proc from 16 back to 1 for the train split to disable multiprocessing as it only contains one shard.\n",
      "Generating train split: 37 examples [00:00, 15357.67 examples/s]\n",
      "Converting format of dataset (num_proc=16): 100%|█| 37/37 [00:00<00:00, 378.01 e\n",
      "/home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "  warnings.warn(  # warn only once\n",
      "[rank0]:[W623 09:39:39.922536747 ProcessGroupNCCL.cpp:4718] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.\n",
      "Running tokenizer on dataset (num_proc=16): 100%|█| 320427/320427 [00:40<00:00, \n",
      "training example:\n",
      "input_ids:\n",
      "[2127, 1132, 2191, 374, 264, 5054, 19675, 323, 7351, 430, 374, 44929, 315, 682, 1120, 7174, 369, 11447, 323, 26737, 311, 90376, 279, 14673, 433, 8349, 10519, 26225, 78242, 323, 30022, 11, 11383, 2737, 7140, 90160, 11, 323, 32682, 13, 1556, 1132, 2191, 28424, 369, 279, 14039, 315, 279, 1614, 449, 1614, 1752, 34775, 323, 37079, 1949, 30257, 13, 1666, 264, 35901, 2163, 29480, 7351, 11, 420, 5403, 315, 44565, 2191, 374, 9277, 389, 279, 3117, 61943, 2163, 315, 279, 5054, 20326, 11, 6118, 7633, 439, 279, 57125, 20611, 315, 279, 41289, 7351, 320, 2808, 531, 8997, 51618, 3677, 95668, 617, 12439, 304, 34775, 2085, 16287, 12694, 1132, 552, 1317, 1603, 279, 21967, 315, 5415, 11, 77563, 11, 477, 991, 19505, 13, 3161, 279, 10205, 315, 39433, 70994, 13162, 11, 67451, 42914, 9017, 11447, 1101, 16392, 13, 10541, 35483, 315, 78431, 6848, 527, 1766, 682, 6957, 3925, 11, 6617, 44565, 2191, 22763, 505, 279, 92931, 13, 12220, 279, 15629, 4376, 315, 279, 220, 777, 339, 323, 279, 1176, 11026, 315, 279, 220, 508, 339, 9478, 11, 279, 78431, 7351, 20415, 3384, 304, 1455, 5596, 315, 279, 1917, 323, 1047, 264, 5199, 3560, 304, 7487, 6, 28970, 369, 91225, 49686, 13, 40741, 78431, 8853, 315, 3463, 14454, 2391, 420, 4261, 13, 1556, 1132, 1705, 617, 4529, 961, 304, 3892, 93574, 11, 1455, 35146, 304, 279, 12366, 6947, 2957, 11, 279, 8690, 16803, 5111, 323, 279, 15506, 16803, 5111, 11, 6832, 842, 13160, 279, 842, 315, 279, 29924, 11639, 315, 44565, 2191, 13, 763, 279, 1566, 11026, 315, 279, 220, 508, 339, 323, 1139, 279, 220, 1691, 267, 9478, 11, 279, 78431, 7351, 706, 1027, 594, 86153, 3131, 810, 11, 7982, 304, 23354, 323, 10383, 2949, 7294, 98231, 380, 11, 7294, 48260, 323, 7294, 74419, 8082, 19567, 382, 2127, 1132, 1705, 3539, 17226, 20414, 11, 902, 1253, 387, 8965, 18255, 1139, 30191, 323, 41993, 15174, 26, 1070, 374, 5199, 28347, 1990, 279, 1403, 13, 38321, 661, 5528, 1456, 311, 38553, 1148, 459, 78431, 8396, 2643, 387, 1093, 11, 719, 30191, 26411, 11, 902, 617, 35901, 4529, 264, 16806, 2543, 11, 9395, 311, 63331, 11447, 323, 279, 1614, 13, 9176, 62814, 315, 3823, 36017, 617, 1027, 28160, 555, 78431, 10334, 11, 43665, 11, 323, 550, 7332, 382, 32960, 99174, 11, 57726, 11, 323, 7419, 4815, 791, 1880, 1631, 5848, 6371, 315, 44565, 2191, 374, 505, 279, 38050, 18341, 459, 847, 71, 689, 11, 7438, 330, 30096, 264, 49080, 498, 24306, 315, 279, 9436, 459, 12, 3573, 30096, 909, 323, 279, 3492, 802, 31764, 437, 3573, 38491, 1, 477, 330, 81, 8646, 1865, 578, 21166, 482, 2191, 72214, 279, 42933, 1510, 430, 9428, 2530, 459, 15630, 13, 1556, 1132, 2191, 8111, 304, 6498, 505, 220, 10513, 17, 439, 44565, 44618, 323, 459, 15630, 505, 220, 9800, 24, 26, 4216, 6498, 603, 1154, 20654, 4147, 264, 5647, 315, 19823, 13, 40741, 48752, 2949, 279, 8753, 22910, 61336, 872, 19949, 439, 93134, 11, 8051, 2478, 1778, 13487, 6222, 1690, 6325, 449, 3010, 93134, 13, 9176, 14110, 5548, 315, 279, 220, 777, 339, 9478, 1778, 439, 12656, 4359, 7678, 320, 10005, 21, 4235, 10750, 21, 8, 323, 93537, 1226, 275, 2785, 320, 5245, 23, 4235, 9674, 16, 8, 1053, 17210, 311, 279, 78431, 83258, 315, 279, 1828, 9659, 719, 1550, 539, 1005, 78431, 477, 44565, 2191, 304, 23524, 5694, 477, 872, 21463, 382, 791, 1176, 5054, 55475, 311, 1650, 5678, 459, 78431, 1754, 574, 38077, 12278, 974, 764, 393, 583, 31721, 263, 320, 5245, 24, 4235, 9714, 20, 705, 36024, 279, 16287, 7342, 315, 44565, 2191, 304, 279, 5209, 12, 777, 339, 9478, 13, 8876, 279, 220, 9378, 15, 82, 323, 7314, 304, 9822, 11, 57125, 2191, 706, 3629, 1027, 1511, 439, 264, 74450, 369, 44565, 2191, 323, 1202, 1005, 439, 264, 74450, 374, 2103, 4279, 4994, 279, 3723, 4273, 13, 4427, 603, 1154, 315, 57125, 2191, 8464, 311, 3927, 4633, 1949, 48831, 19675, 1193, 11, 323, 1949, 48831, 44565, 2191, 304, 4040, 374, 61937, 57125, 44565, 2191, 382, 8142, 279, 4751, 57125, 706, 1027, 14090, 69593, 449, 44565, 2191, 11, 1202, 7438, 706, 810, 6051, 1027, 80703, 555, 22622, 25375, 505, 2679, 30450, 85129, 5315, 11, 2737, 2225, 279, 1561, 14043, 323, 57125, 28187, 1705, 11, 889, 656, 539, 22712, 5694, 449, 59021, 3674, 1705, 477, 264, 348, 53290, 4717, 11, 323, 14560, 13042, 45750, 11, 889, 527, 15871, 11920, 449, 8431, 58455, 13, 23212, 11, 1063, 93134, 1005, 57125, 41289, 311, 5766, 44565, 2191, 596, 8389, 390, 14632, 323, 20654, 1082, 1202, 13537, 449, 51618, 13, 1556, 1132, 2191, 374, 44029, 1511, 311, 7664, 279, 7294, 43802, 20631, 20611, 315, 279, 41289, 7351, 13, 1556, 1132, 2191, 374, 13168, 291, 311, 41289, 7739, 902, 527, 1614, 36185, 477, 505, 3485, 13, 99394, 315, 44565, 2191, 8965, 11415, 44565, 2191, 596, 41289, 16792, 323, 9940, 1082, 13865, 520, 6968, 29953, 354, 316, 552, 1990, 279, 1403, 13, 4427, 31839, 7664, 44565, 2191, 439, 3515, 1690, 34453, 505, 84581, 11, 323, 1694, 2225, 18250, 323, 41289, 719, 810, 779, 13, 9176, 31839, 8007, 459, 277, 971, 98231, 2191, 439, 264, 70847, 315, 78431, 16565, 382, 8142, 14076, 311, 279, 1614, 374, 8792, 311, 78431, 3463, 11, 27409, 44565, 2191, 374, 539, 459, 4228, 3465, 369, 31839, 11, 439, 1070, 374, 264, 2763, 315, 10430, 4315, 31839, 323, 93134, 389, 279, 5030, 11, 323, 5370, 60701, 45493, 44565, 2191, 10284, 22009, 13, 17559, 36222, 3079, 5540, 2997, 279, 690, 369, 264, 2536, 23283, 3035, 535, 8396, 11, 279, 38001, 315, 279, 1614, 41705, 11, 279, 16801, 430, 3823, 7138, 6276, 12966, 311, 3073, 304, 477, 5208, 9017, 1778, 264, 2536, 23283, 3035, 535, 8396, 11, 323, 264, 24710, 389, 1268, 311, 1180, 311, 23564, 279, 10728, 315, 459, 15630, 382, 13730, 271, 4808, 17515, 944, 11639, 4815, 10438, 279, 9886, 315, 25861, 323, 9919, 11, 9749, 11447, 1550, 539, 3073, 13, 1102, 574, 1306, 279, 15244, 315, 11447, 430, 44565, 4633, 6848, 1051, 16948, 37588, 439, 264, 13010, 13, 578, 1455, 28289, 5956, 34291, 311, 44565, 2191, 304, 279, 14154, 1917, 1051, 304, 5734, 323, 25431, 13, 763, 5734, 11, 41903, 44565, 2191, 320, 1820, 10430, 389, 279, 57008, 315, 279, 1614, 8, 574, 91784, 660, 555, 60608, 380, 61787, 68844, 526, 67927, 323, 445, 3524, 8510, 13, 32944, 3002, 71883, 42914, 11, 60608, 2191, 706, 1027, 1071, 311, 617, 1047, 330, 91645, 16961, 811, 1, 315, 44565, 2191, 382, 2127, 1132, 292, 33726, 1051, 1101, 83280, 555, 28375, 5493, 323, 61787, 304, 25431, 13, 362, 60478, 4010, 355, 323, 34940, 511, 645, 1511, 279, 21849, 315, 6898, 343, 606, 311, 41468, 279, 12324, 1990, 7016, 27070, 555, 279, 1614, 323, 4443, 51360, 13, 328, 78046, 29440, 59652, 1122, 11527, 15320, 323, 29676, 389, 279, 1314, 315, 3927, 11542, 315, 42563, 13, 356, 1910, 1233, 27292, 3823, 2383, 320, 17101, 437, 8, 323, 5938, 11527, 1418, 4560, 311, 3974, 4184, 311, 7138, 320, 764, 4548, 570, 71883, 1233, 1051, 33445, 315, 264, 8396, 3196, 389, 57751, 323, 11919, 4398, 4315, 1202, 10495, 2085, 279, 9546, 315, 264, 1614, 382, 644, 42108, 4606, 11, 1070, 574, 912, 44565, 4633, 5820, 3734, 1063, 14943, 5411, 10597, 19567, 13, 4314, 11, 323, 1023, 10451, 19567, 11, 3010, 6688, 7342, 311, 10597, 44565, 2191, 13, 763, 279, 328, 46488, 1122, 21080, 11, 40091, 67, 587, 2663, 369, 459, 77271, 20631, 8396, 323, 279, 76445, 315, 87149, 11, 1193, 311, 387, 5246, 16070, 555, 35414, 735, 38155, 358, 382, 644, 15004, 969, 11, 10597, 31237, 82, 89194, 2403, 279, 1614, 13, 763, 4606, 11, 5370, 31237, 82, 8040, 7294, 21395, 323, 57125, 61555, 13, 50086, 291, 2802, 304, 61386, 488, 2391, 279, 55383, 323, 304, 879, 19971, 2391, 279, 1050, 1659, 28101, 5540, 315, 7294, 43802, 20631, 37019, 2191, 11, 8104, 304, 9822, 13, 92931, 11774, 311, 20207, 11447, 320, 5132, 1299, 323, 10597, 8, 323, 279, 93574, 315, 279, 220, 11128, 15, 82, 323, 220, 10336, 23, 682, 85747, 279, 42933, 4500, 315, 1148, 6244, 279, 11639, 315, 29924, 44565, 2191, 382, 49552, 11639, 720, 16397, 279, 8753, 22910, 11, 49638, 5315, 1778, 439, 279, 2998, 4193, 5512, 323, 279, 220, 5602, 264, 13353, 1486, 304, 279, 74454, 315, 7294, 21395, 323, 6918, 380, 58214, 13, 578, 1176, 78431, 60701, 8040, 6957, 279, 220, 972, 339, 9478, 439, 12656, 4359, 7678, 16948, 37588, 41903, 44565, 2191, 304, 9635, 11, 57323, 20445, 275, 318, 3876, 279, 1614, 11, 7639, 65292, 1215, 596, 7422, 63675, 279, 1648, 311, 3927, 2191, 323, 38077, 12278, 974, 764, 393, 583, 31721, 263, 596, 10334, 315, 27848, 2191, 1766, 70225, 17614, 304, 9822, 13, 3296, 279, 3389, 220, 9674, 15, 82, 11, 5370, 78431, 8853, 315, 3463, 1047, 3719, 1664, 39817, 323, 264, 12330, 315, 1243, 31069, 3728, 8082, 10222, 505, 220, 9367, 15, 311, 220, 7529, 19, 13, 1115, 11639, 315, 29924, 44565, 2191, 36513, 3156, 279, 842, 315, 279, 15506, 16803, 5111, 323, 374, 6646, 279, 21411, 4325, 315, 44565, 2191, 382, 38537, 505, 27848, 2191, 11, 92551, 36769, 359, 258, 18538, 6667, 80244, 44565, 2191, 323, 10862, 279, 7327, 22938, 5794, 596, 10229, 11, 264, 538, 12128, 11552, 3010, 3967, 439, 279, 5629, 7327, 430, 14454, 304, 220, 9714, 19, 311, 52696, 17226, 30191, 60701, 13, 578, 7327, 6244, 264, 5199, 5054, 5457, 11, 449, 35131, 28187, 1694, 264, 6522, 7216, 323, 264, 4562, 315, 1202, 3331, 9251, 13, 36769, 359, 258, 596, 37480, 320, 1820, 622, 5808, 28331, 8, 323, 393, 583, 31721, 263, 596, 20723, 320, 1820, 27848, 1705, 8, 16475, 1614, 51618, 11, 59416, 5054, 63944, 3012, 2191, 323, 2678, 3424, 58348, 13, 4740, 26242, 42254, 11, 279, 36769, 359, 258, 1705, 1051, 67331, 505, 279, 7327, 555, 279, 28187, 1705, 520, 279, 220, 9674, 17, 86026, 8151, 13, 1556, 1132, 1705, 1051, 12020, 30293, 304, 279, 10657, 7327, 11, 1694, 13967, 67331, 304, 220, 9378, 21, 13, 36769, 359, 258, 51287, 19698, 430, 422, 14110, 5548, 18661, 2410, 555, 28187, 596, 3878, 11, 814, 1053, 842, 709, 279, 502, 43049, 1821, 315, 7487, 13, 763, 2077, 311, 872, 95989, 505, 279, 5629, 7327, 11, 93134, 14454, 279, 800, 13, 2417, 1291, 7327, 13, 9636, 279, 10383, 315, 11291, 735, 897, 354, 8148, 11, 264, 8690, 55475, 323, 28568, 11, 459, 277, 971, 88389, 359, 2191, 29204, 5795, 449, 6667, 74050, 13, 1556, 277, 971, 88389, 359, 1705, 11, 889, 24465, 20343, 505, 279, 220, 9674, 16, 12366, 6947, 2957, 11, 64854, 369, 1949, 80375, 323, 369, 279, 8141, 315, 11822, 4184, 311, 832, 596, 3966, 382, 1383, 279, 2543, 315, 279, 220, 508, 339, 9478, 11, 44565, 2191, 1047, 9041, 682, 927, 279, 1917, 13, 1102, 574, 264, 28289, 4668, 315, 279, 6625, 22013, 950, 380, 7351, 13, 763, 5734, 11, 2678, 5315, 315, 4236, 25973, 279, 3823, 4633, 463, 31419, 1873, 2373, 315, 459, 277, 971, 88389, 359, 2191, 13, 27286, 574, 264, 80310, 369, 42301, 1245, 12822, 505, 6460, 14875, 5961, 11, 889, 7882, 311, 279, 11002, 6864, 311, 4007, 13, 763, 20023, 5270, 11, 32164, 574, 264, 86568, 369, 459, 277, 971, 1355, 88, 303, 950, 2191, 11, 1405, 433, 6244, 279, 1455, 21102, 2163, 29480, 34649, 13, 12220, 420, 892, 11, 264, 23413, 315, 93134, 18306, 26411, 315, 30191, 5054, 9349, 11, 3967, 439, 30617, 315, 279, 56408, 13, 578, 834, 9792, 479, 315, 279, 8753, 41289, 7351, 1139, 1690, 5315, 323, 279, 11572, 323, 61087, 315, 1690, 57298, 2402, 311, 47426, 49028, 2768, 279, 46735, 315, 279, 12366, 6947, 2957, 92867, 3927, 380, 5054, 7645, 323, 14385, 13, 7570, 3582, 1690, 93134, 1612, 4979, 5694, 505, 1521, 20320, 14385, 11, 4225, 27322, 3782, 5304, 279, 7351, 323, 13865, 1051, 1903, 311, 5471, 93134, 15644, 1113, 311, 279, 2326, 11, 2737, 279, 40782, 3298, 315, 220, 7028, 18, 11, 1101, 2663, 279, 1556, 1132, 380, 1398, 9134, 3298, 13, 15388, 2191, 574, 2500, 8446, 902, 1063, 93134, 18306, 2391, 420, 4261, 382, 20397, 10742, 11, 93134, 99325, 31408, 304, 279, 8690, 22910, 304, 14076, 311, 279, 5929, 7351, 11, 5423, 304, 279, 386, 22506, 39142, 939, 81236, 26, 4869, 11, 814, 2322, 25984, 46735, 1306, 279, 92501, 3109, 1047, 27276, 4147, 11, 2737, 2391, 279, 97660, 45378, 53848, 13, 26778, 93134, 505, 62579, 6902, 323, 23223, 30010, 311, 19278, 11, 1603, 279, 92501, 82, 33745, 279, 78431, 7351, 1070, 2288, 13, 3161, 279, 93134, 1694]\n",
      "inputs:\n",
      "Anarchism is a political philosophy and movement that is skeptical of all justifications for authority and seeks to abolish the institutions it claims maintain unnecessary coercion and hierarchy, typically including nation-states, and capitalism. Anarchism advocates for the replacement of the state with stateless societies and voluntary free associations. As a historically left-wing movement, this reading of anarchism is placed on the farthest left of the political spectrum, usually described as the libertarian wing of the socialist movement (libertarian socialism).\n",
      "\n",
      "Humans have lived in societies without formal hierarchies long before the establishment of states, realms, or empires. With the rise of organised hierarchical bodies, scepticism toward authority also rose. Although traces of anarchist ideas are found all throughout history, modern anarchism emerged from the Enlightenment. During the latter half of the 19th and the first decades of the 20th century, the anarchist movement flourished in most parts of the world and had a significant role in workers' struggles for emancipation. Various anarchist schools of thought formed during this period. Anarchists have taken part in several revolutions, most notably in the Paris Commune, the Russian Civil War and the Spanish Civil War, whose end marked the end of the classical era of anarchism. In the last decades of the 20th and into the 21st century, the anarchist movement has been resurgent once more, growing in popularity and influence within anti-capitalist, anti-war and anti-globalisation movements.\n",
      "\n",
      "Anarchists employ diverse approaches, which may be generally divided into revolutionary and evolutionary strategies; there is significant overlap between the two. Evolutionary methods try to simulate what an anarchist society might be like, but revolutionary tactics, which have historically taken a violent turn, aim to overthrow authority and the state. Many facets of human civilization have been influenced by anarchist theory, critique, and praxis.\n",
      "\n",
      "Etymology, terminology, and definition \n",
      "\n",
      "The etymological origin of anarchism is from the Ancient Greek anarkhia, meaning \"without a ruler\", composed of the prefix an- (\"without\") and the word arkhos (\"leader\" or \"ruler\"). The suffix -ism denotes the ideological current that favours anarchy. Anarchism appears in English from 1642 as anarchisme and anarchy from 1539; early English usages emphasised a sense of disorder. Various factions within the French Revolution labelled their opponents as anarchists, although few such accused shared many views with later anarchists. Many revolutionaries of the 19th century such as William Godwin (1756–1836) and Wilhelm Weitling (1808–1871) would contribute to the anarchist doctrines of the next generation but did not use anarchist or anarchism in describing themselves or their beliefs.\n",
      "\n",
      "The first political philosopher to call himself an anarchist () was Pierre-Joseph Proudhon (1809–1865), marking the formal birth of anarchism in the mid-19th century. Since the 1890s and beginning in France, libertarianism has often been used as a synonym for anarchism and its use as a synonym is still common outside the United States. Some usages of libertarianism refer to individualistic free-market philosophy only, and free-market anarchism in particular is termed libertarian anarchism.\n",
      "\n",
      "While the term libertarian has been largely synonymous with anarchism, its meaning has more recently been diluted by wider adoption from ideologically disparate groups, including both the New Left and libertarian Marxists, who do not associate themselves with authoritarian socialists or a vanguard party, and extreme cultural liberals, who are primarily concerned with civil liberties. Additionally, some anarchists use libertarian socialist to avoid anarchism's negative connotations and emphasise its connections with socialism. Anarchism is broadly used to describe the anti-authoritarian wing of the socialist movement. Anarchism is contrasted to socialist forms which are state-oriented or from above. Scholars of anarchism generally highlight anarchism's socialist credentials and criticise attempts at creating dichotomies between the two. Some scholars describe anarchism as having many influences from liberalism, and being both liberal and socialist but more so. Many scholars reject anarcho-capitalism as a misunderstanding of anarchist principles.\n",
      "\n",
      "While opposition to the state is central to anarchist thought, defining anarchism is not an easy task for scholars, as there is a lot of discussion among scholars and anarchists on the matter, and various currents perceive anarchism slightly differently. Major definitional elements include the will for a non-coercive society, the rejection of the state apparatus, the belief that human nature allows humans to exist in or progress toward such a non-coercive society, and a suggestion on how to act to pursue the ideal of anarchy.\n",
      "\n",
      "History\n",
      "\n",
      "Pre-modern era \n",
      "\n",
      "Before the creation of towns and cities, established authority did not exist. It was after the institution of authority that anarchistic ideas were espoused as a reaction. The most notable precursors to anarchism in the ancient world were in China and Greece. In China, philosophical anarchism (the discussion on the legitimacy of the state) was delineated by Taoist philosophers Zhuang Zhou and Laozi. Alongside Stoicism, Taoism has been said to have had \"significant anticipations\" of anarchism.\n",
      "\n",
      "Anarchic attitudes were also articulated by tragedians and philosophers in Greece. Aeschylus and Sophocles used the myth of Antigone to illustrate the conflict between laws imposed by the state and personal autonomy. Socrates questioned Athenian authorities constantly and insisted on the right of individual freedom of conscience. Cynics dismissed human law (nomos) and associated authorities while trying to live according to nature (physis). Stoics were supportive of a society based on unofficial and friendly relations among its citizens without the presence of a state.\n",
      "\n",
      "In medieval Europe, there was no anarchistic activity except some ascetic religious movements. These, and other Muslim movements, later gave birth to religious anarchism. In the Sasanian Empire, Mazdak called for an egalitarian society and the abolition of monarchy, only to be soon executed by Emperor Kavad I.\n",
      "\n",
      "In Basra, religious sects preached against the state. In Europe, various sects developed anti-state and libertarian tendencies. Renewed interest in antiquity during the Renaissance and in private judgment during the Reformation restored elements of anti-authoritarian secularism, particularly in France. Enlightenment challenges to intellectual authority (secular and religious) and the revolutions of the 1790s and 1848 all spurred the ideological development of what became the era of classical anarchism.\n",
      "\n",
      "Modern era \n",
      "During the French Revolution, partisan groups such as the Enragés and the  saw a turning point in the fermentation of anti-state and federalist sentiments. The first anarchist currents developed throughout the 18th century as William Godwin espoused philosophical anarchism in England, morally delegitimising the state, Max Stirner's thinking paved the way to individualism and Pierre-Joseph Proudhon's theory of mutualism found fertile soil in France. By the late 1870s, various anarchist schools of thought had become well-defined and a wave of then unprecedented globalisation occurred from 1880 to 1914. This era of classical anarchism lasted until the end of the Spanish Civil War and is considered the golden age of anarchism.\n",
      "\n",
      "Drawing from mutualism, Mikhail Bakunin founded collectivist anarchism and entered the International Workingmen's Association, a class worker union later known as the First International that formed in 1864 to unite diverse revolutionary currents. The International became a significant political force, with Karl Marx being a leading figure and a member of its General Council. Bakunin's faction (the Jura Federation) and Proudhon's followers (the mutualists) opposed state socialism, advocating political abstentionism and small property holdings. After bitter disputes, the Bakuninists were expelled from the International by the Marxists at the 1872 Hague Congress. Anarchists were treated similarly in the Second International, being ultimately expelled in 1896. Bakunin famously predicted that if revolutionaries gained power by Marx's terms, they would end up the new tyrants of workers. In response to their expulsion from the First International, anarchists formed the St. Imier International. Under the influence of Peter Kropotkin, a Russian philosopher and scientist, anarcho-communism overlapped with collectivism. Anarcho-communists, who drew inspiration from the 1871 Paris Commune, advocated for free federation and for the distribution of goods according to one's needs.\n",
      "\n",
      "By the turn of the 20th century, anarchism had spread all over the world. It was a notable feature of the international syndicalist movement. In China, small groups of students imported the humanistic pro-science version of anarcho-communism. Tokyo was a hotspot for rebellious youth from East Asian countries, who moved to the Japanese capital to study. In Latin America, Argentina was a stronghold for anarcho-syndicalism, where it became the most prominent left-wing ideology. During this time, a minority of anarchists adopted tactics of revolutionary political violence, known as propaganda of the deed. The dismemberment of the French socialist movement into many groups and the execution and exile of many Communards to penal colonies following the suppression of the Paris Commune favoured individualist political expression and acts. Even though many anarchists distanced themselves from these terrorist acts, infamy came upon the movement and attempts were made to prevent anarchists immigrating to the US, including the Immigration Act of 1903, also called the Anarchist Exclusion Act. Illegalism was another strategy which some anarchists adopted during this period.\n",
      "\n",
      "Despite concerns, anarchists enthusiastically participated in the Russian Revolution in opposition to the White movement, especially in the Makhnovshchina; however, they met harsh suppression after the Bolshevik government had stabilised, including during the Kronstadt rebellion. Several anarchists from Petrograd and Moscow fled to Ukraine, before the Bolsheviks crushed the anarchist movement there too. With the anarchists being\n",
      "[INFO|configuration_utils.py:698] 2025-06-23 09:40:20,635 >> loading configuration file config.json from cache at /home/ai-research-lab/.cache/huggingface/hub/models--meta-llama--LLaMA-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95/config.json\n",
      "[INFO|configuration_utils.py:770] 2025-06-23 09:40:20,636 >> Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128008,\n",
      "    128009\n",
      "  ],\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 131072,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 24,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": {\n",
      "    \"factor\": 32.0,\n",
      "    \"high_freq_factor\": 4.0,\n",
      "    \"low_freq_factor\": 1.0,\n",
      "    \"original_max_position_embeddings\": 8192,\n",
      "    \"rope_type\": \"llama3\"\n",
      "  },\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "[INFO|2025-06-23 09:40:20] llamafactory.model.model_utils.kv_cache:143 >> KV cache is disabled during training.\n",
      "[INFO|modeling_utils.py:1151] 2025-06-23 09:40:20,761 >> loading weights file model.safetensors from cache at /home/ai-research-lab/.cache/huggingface/hub/models--meta-llama--LLaMA-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95/model.safetensors.index.json\n",
      "[INFO|modeling_utils.py:2241] 2025-06-23 09:40:20,762 >> Instantiating LlamaForCausalLM model under default dtype torch.bfloat16.\n",
      "[INFO|configuration_utils.py:1135] 2025-06-23 09:40:20,762 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128008,\n",
      "    128009\n",
      "  ],\n",
      "  \"use_cache\": false\n",
      "}\n",
      "\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:05<00:00,  2.73s/it]\n",
      "[INFO|modeling_utils.py:5131] 2025-06-23 09:40:26,242 >> All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
      "\n",
      "[INFO|modeling_utils.py:5139] 2025-06-23 09:40:26,242 >> All the weights of LlamaForCausalLM were initialized from the model checkpoint at meta-llama/LLaMA-3.2-3B-Instruct.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:05<00:00,  2.71s/it]\n",
      "[INFO|configuration_utils.py:1090] 2025-06-23 09:40:26,756 >> loading configuration file generation_config.json from cache at /home/ai-research-lab/.cache/huggingface/hub/models--meta-llama--LLaMA-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95/generation_config.json\n",
      "[INFO|configuration_utils.py:1135] 2025-06-23 09:40:26,756 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"do_sample\": true,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128008,\n",
      "    128009\n",
      "  ],\n",
      "  \"temperature\": 0.6,\n",
      "  \"top_p\": 0.9\n",
      "}\n",
      "\n",
      "[INFO|2025-06-23 09:40:27] llamafactory.model.model_utils.checkpointing:143 >> Gradient checkpointing enabled.\n",
      "[INFO|2025-06-23 09:40:27] llamafactory.model.model_utils.attention:143 >> Using torch SDPA for faster training and inference.\n",
      "[INFO|2025-06-23 09:40:27] llamafactory.model.adapter:143 >> Upcasting trainable params to float32.\n",
      "[INFO|2025-06-23 09:40:27] llamafactory.model.adapter:143 >> Fine-tuning method: Freeze\n",
      "[INFO|2025-06-23 09:40:27] llamafactory.model.adapter:143 >> Set trainable layers: .24.,.25.,.26.,.27.\n",
      "[INFO|2025-06-23 09:40:27] llamafactory.model.loader:143 >> trainable params: 402,677,760 || all params: 3,212,749,824 || trainable%: 12.5337\n",
      "[INFO|trainer.py:756] 2025-06-23 09:40:27,284 >> Using auto half precision backend\n",
      "[INFO|trainer.py:2409] 2025-06-23 09:40:27,967 >> ***** Running training *****\n",
      "[INFO|trainer.py:2410] 2025-06-23 09:40:27,967 >>   Num examples = 149,143\n",
      "[INFO|trainer.py:2411] 2025-06-23 09:40:27,967 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:2412] 2025-06-23 09:40:27,967 >>   Instantaneous batch size per device = 1\n",
      "[INFO|trainer.py:2415] 2025-06-23 09:40:27,967 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "[INFO|trainer.py:2416] 2025-06-23 09:40:27,967 >>   Gradient Accumulation steps = 8\n",
      "[INFO|trainer.py:2417] 2025-06-23 09:40:27,967 >>   Total optimization steps = 9,322\n",
      "[INFO|trainer.py:2418] 2025-06-23 09:40:27,967 >>   Number of trainable parameters = 402,677,760\n",
      "{'loss': 2.3204, 'grad_norm': 0.5110549926757812, 'learning_rate': 9.64630225080386e-07, 'epoch': 0.0}\n",
      "{'loss': 2.3394, 'grad_norm': 0.4662763476371765, 'learning_rate': 2.0364415862808147e-06, 'epoch': 0.0}\n",
      "{'loss': 2.3151, 'grad_norm': 0.4755650460720062, 'learning_rate': 3.1082529474812435e-06, 'epoch': 0.0}\n",
      "{'loss': 2.2927, 'grad_norm': 0.43105220794677734, 'learning_rate': 4.180064308681672e-06, 'epoch': 0.0}\n",
      "{'loss': 2.2484, 'grad_norm': 0.41626882553100586, 'learning_rate': 5.251875669882101e-06, 'epoch': 0.01}\n",
      "  1%|▏                                      | 50/9322 [02:36<8:04:39,  3.14s/it]"
     ]
    }
   ],
   "source": [
    "!llamafactory-cli train CPT_LayerFreezing_5per.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91076680",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98c5cef",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'llamafactory'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgc\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mllamafactory\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatModel\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtorch_gc\u001b[39m():\n\u001b[1;32m      6\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Clean up GPU memory.\"\"\"\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'llamafactory'"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import torch\n",
    "from llamafactory.chat import ChatModel\n",
    "\n",
    "def torch_gc():\n",
    "    \"\"\"Clean up GPU memory.\"\"\"\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "def init_model(model_path: str, template: str, quant_bit: int) -> ChatModel:\n",
    "    \"\"\"Instantiate the chat model with minimal retries.\"\"\"\n",
    "    args = {\n",
    "        \"model_name_or_path\": model_path,\n",
    "        \"template\": template,\n",
    "        \"quantization_bit\": quant_bit,\n",
    "        # \"flash_attn\": True,  # Uncomment if supported and benchmarks show improvement\n",
    "    }\n",
    "    print(\"Initializing model…\", end=\" \", flush=True)\n",
    "    try:\n",
    "        model = ChatModel(args)\n",
    "        print(\"✅\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(\"❌\")\n",
    "        raise RuntimeError(f\"Failed to load model: {e}\") from e\n",
    "\n",
    "def process_query(chat_model: ChatModel, messages: list, query: str) -> tuple[bool, str]:\n",
    "    \"\"\"Handle special commands or stream a response from the model.\"\"\"\n",
    "    cmd = query.strip().lower()\n",
    "    if cmd == \"exit\":\n",
    "        return False, \"Exiting…\"\n",
    "    if cmd == \"clear\":\n",
    "        messages.clear()\n",
    "        torch_gc()\n",
    "        return True, \"🗑️ Conversation history cleared\"\n",
    "\n",
    "    # Regular user message\n",
    "    messages.append({\"role\": \"user\", \"content\": query})\n",
    "    print(\"Assistant: \", end=\"\", flush=True)\n",
    "\n",
    "    response = []\n",
    "    try:\n",
    "        for chunk in chat_model.stream_chat(messages):\n",
    "            print(chunk, end=\"\", flush=True)\n",
    "            response.append(chunk)\n",
    "    except Exception as e:\n",
    "        return True, f\"⚠️ Error during generation: {e}\"\n",
    "\n",
    "    reply = \"\".join(response)\n",
    "    print()  # newline after completion\n",
    "    messages.append({\"role\": \"assistant\", \"content\": reply})\n",
    "    return True, \"\"\n",
    "\n",
    "def main():\n",
    "    # Initial cleanup\n",
    "    torch_gc()\n",
    "\n",
    "    model_path = \"/home/ai-research-lab/MCSProjectbyWajahatalibasharat5Percent/LLaMA-Factory/llama3-3b_freeze_5per\"\n",
    "    chat_model = init_model(model_path, template=\"llama3\", quant_bit=8)\n",
    "\n",
    "    messages: list[dict] = []\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Welcome to LLaMA Chat Interface!\")\n",
    "    print(\"Commands:\")\n",
    "    print(\"- Type 'clear' to reset conversation history\")\n",
    "    print(\"- Type 'exit' to end the session\")\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            query = input(\"User: \")\n",
    "            cont, out = process_query(chat_model, messages, query)\n",
    "            if out:\n",
    "                print(out)\n",
    "            if not cont:\n",
    "                break\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n🛑 Session interrupted by user\")\n",
    "    finally:\n",
    "        torch_gc()\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"Session ended. GPU resources freed.\")\n",
    "        print(\"=\"*50)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e296b50",
   "metadata": {},
   "source": [
    "## Merging with unfrozen layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3454a523",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "args = dict(\n",
    "  model_name_or_path=\"llama3-3b_freeze_5per\",                # use official non-quantized Llama-3-8B-Instruct model                      # load the saved LoRA adapters\n",
    "  template=\"llama3\",                                        # same to the one in training\n",
    "  finetuning_type=\"freeze\",                                   # same to the one in training\n",
    "  export_dir=\"llama3_freeze_merged_5per\",                          # the path to save the merged model\n",
    "  export_size=2,                                            # the file shard size (in GB) of the merged model\n",
    "  export_device=\"cpu\",                                      # the device used in export, can be chosen from `cpu` and `auto`\n",
    "  export_hub_model_id=\"wbasharat/llama3-3b_freeze_5per\",               # the Hugging Face hub ID to upload model\n",
    ")\n",
    "json.dump(args, open(\"merged_5Per_freeze_llama3.json\", \"w\", encoding=\"utf-8\"), indent=2)\n",
    "\n",
    "%cd /content/LLaMA-Factory/\n",
    "\n",
    "!llamafactory-cli export merged_5Per_freeze_llama3.json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
