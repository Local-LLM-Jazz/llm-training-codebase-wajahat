{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1b3686d",
   "metadata": {},
   "source": [
    "## CPT Using Layer Freezing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2303cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/content/'\n",
      "/home/ai-research-lab/MCSProjectbyWajahatalibasharat5Percent\n",
      "Cloning into 'LLaMA-Factory'...\n",
      "remote: Enumerating objects: 360, done.\u001b[K\n",
      "remote: Counting objects: 100% (360/360), done.\u001b[K\n",
      "remote: Compressing objects: 100% (279/279), done.\u001b[K\n",
      "remote: Total 360 (delta 79), reused 275 (delta 66), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (360/360), 9.94 MiB | 1.76 MiB/s, done.\n",
      "Resolving deltas: 100% (79/79), done.\n",
      "/home/ai-research-lab/MCSProjectbyWajahatalibasharat5Percent/LLaMA-Factory\n",
      "\u001b[0m\u001b[01;34massets\u001b[0m/       \u001b[01;34mevaluation\u001b[0m/  MANIFEST.in     requirements.txt  \u001b[01;34mtests\u001b[0m/\n",
      "CITATION.cff  \u001b[01;34mexamples\u001b[0m/    pyproject.toml  \u001b[01;34mscripts\u001b[0m/\n",
      "\u001b[01;34mdata\u001b[0m/         LICENSE      README.md       setup.py\n",
      "\u001b[01;34mdocker\u001b[0m/       Makefile     README_zh.md    \u001b[01;34msrc\u001b[0m/\n",
      "Obtaining file:///home/ai-research-lab/MCSProjectbyWajahatalibasharat5Percent/LLaMA-Factory\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: transformers!=4.46.*,!=4.47.*,!=4.48.0,!=4.52.0,<=4.52.4,>=4.45.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from llamafactory==0.9.4.dev0) (4.52.4)\n",
      "Requirement already satisfied: datasets<=3.6.0,>=2.16.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from llamafactory==0.9.4.dev0) (3.6.0)\n",
      "Requirement already satisfied: accelerate<=1.7.0,>=0.34.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from llamafactory==0.9.4.dev0) (1.7.0)\n",
      "Requirement already satisfied: peft<=0.15.2,>=0.14.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from llamafactory==0.9.4.dev0) (0.15.2)\n",
      "Requirement already satisfied: trl<=0.9.6,>=0.8.6 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from llamafactory==0.9.4.dev0) (0.9.6)\n",
      "Requirement already satisfied: tokenizers<=0.21.1,>=0.19.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from llamafactory==0.9.4.dev0) (0.21.1)\n",
      "Requirement already satisfied: gradio<=5.31.0,>=4.38.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from llamafactory==0.9.4.dev0) (5.31.0)\n",
      "Requirement already satisfied: scipy in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from llamafactory==0.9.4.dev0) (1.15.3)\n",
      "Requirement already satisfied: einops in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from llamafactory==0.9.4.dev0) (0.8.1)\n",
      "Requirement already satisfied: sentencepiece in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from llamafactory==0.9.4.dev0) (0.2.0)\n",
      "Requirement already satisfied: tiktoken in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from llamafactory==0.9.4.dev0) (0.9.0)\n",
      "Requirement already satisfied: protobuf in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from llamafactory==0.9.4.dev0) (6.31.1)\n",
      "Requirement already satisfied: uvicorn in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from llamafactory==0.9.4.dev0) (0.34.3)\n",
      "Requirement already satisfied: fastapi in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from llamafactory==0.9.4.dev0) (0.115.13)\n",
      "Requirement already satisfied: sse-starlette in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from llamafactory==0.9.4.dev0) (2.3.6)\n",
      "Requirement already satisfied: matplotlib>=3.7.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from llamafactory==0.9.4.dev0) (3.10.3)\n",
      "Requirement already satisfied: fire in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from llamafactory==0.9.4.dev0) (0.7.0)\n",
      "Requirement already satisfied: omegaconf in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from llamafactory==0.9.4.dev0) (2.3.0)\n",
      "Requirement already satisfied: packaging in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from llamafactory==0.9.4.dev0) (25.0)\n",
      "Requirement already satisfied: pyyaml in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from llamafactory==0.9.4.dev0) (6.0.2)\n",
      "Requirement already satisfied: numpy<2.0.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from llamafactory==0.9.4.dev0) (1.26.4)\n",
      "Requirement already satisfied: pydantic<=2.10.6 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from llamafactory==0.9.4.dev0) (2.10.6)\n",
      "Requirement already satisfied: pandas>=2.0.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from llamafactory==0.9.4.dev0) (2.3.0)\n",
      "Requirement already satisfied: av in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from llamafactory==0.9.4.dev0) (14.4.0)\n",
      "Requirement already satisfied: librosa in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from llamafactory==0.9.4.dev0) (0.11.0)\n",
      "Requirement already satisfied: tyro<0.9.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from llamafactory==0.9.4.dev0) (0.8.14)\n",
      "Requirement already satisfied: torch>=2.0.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from llamafactory==0.9.4.dev0) (2.7.1+cu128)\n",
      "Requirement already satisfied: torchvision>=0.15.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from llamafactory==0.9.4.dev0) (0.22.1+cu128)\n",
      "Requirement already satisfied: bitsandbytes>=0.39.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from llamafactory==0.9.4.dev0) (0.46.0)\n",
      "Requirement already satisfied: psutil in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from accelerate<=1.7.0,>=0.34.0->llamafactory==0.9.4.dev0) (5.9.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from accelerate<=1.7.0,>=0.34.0->llamafactory==0.9.4.dev0) (0.33.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from accelerate<=1.7.0,>=0.34.0->llamafactory==0.9.4.dev0) (0.5.3)\n",
      "Requirement already satisfied: filelock in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (0.3.8)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (3.12.13)\n",
      "Requirement already satisfied: aiofiles<25.0,>=22.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (24.1.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (4.9.0)\n",
      "Requirement already satisfied: ffmpy in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.6.0)\n",
      "Requirement already satisfied: gradio-client==1.10.1 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (1.10.1)\n",
      "Requirement already satisfied: groovy~=0.1 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.1.2)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.28.1)\n",
      "Requirement already satisfied: jinja2<4.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (3.1.4)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (2.1.5)\n",
      "Requirement already satisfied: orjson~=3.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (3.10.18)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (11.0.0)\n",
      "Requirement already satisfied: pydub in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.0.20)\n",
      "Requirement already satisfied: ruff>=0.9.3 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.12.0)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.1.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.46.2)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.13.3)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (4.12.2)\n",
      "Requirement already satisfied: websockets<16.0,>=10.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from gradio-client==1.10.1->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (15.0.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from pandas>=2.0.0->llamafactory==0.9.4.dev0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from pandas>=2.0.0->llamafactory==0.9.4.dev0) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from pandas>=2.0.0->llamafactory==0.9.4.dev0) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from pydantic<=2.10.6->llamafactory==0.9.4.dev0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from pydantic<=2.10.6->llamafactory==0.9.4.dev0) (2.27.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate<=1.7.0,>=0.34.0->llamafactory==0.9.4.dev0) (1.1.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from transformers!=4.46.*,!=4.47.*,!=4.48.0,!=4.52.0,<=4.52.4,>=4.45.0->llamafactory==0.9.4.dev0) (2024.11.6)\n",
      "Requirement already satisfied: click>=8.0.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (14.0.0)\n",
      "Requirement already satisfied: docstring-parser>=0.16 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from tyro<0.9.0->llamafactory==0.9.4.dev0) (0.16)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from tyro<0.9.0->llamafactory==0.9.4.dev0) (1.7.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (6.5.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (1.20.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from torch>=2.0.0->llamafactory==0.9.4.dev0) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from torch>=2.0.0->llamafactory==0.9.4.dev0) (3.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.61 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from torch>=2.0.0->llamafactory==0.9.4.dev0) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.57 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from torch>=2.0.0->llamafactory==0.9.4.dev0) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.57 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from torch>=2.0.0->llamafactory==0.9.4.dev0) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.7.1.26 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from torch>=2.0.0->llamafactory==0.9.4.dev0) (9.7.1.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.3.14 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from torch>=2.0.0->llamafactory==0.9.4.dev0) (12.8.3.14)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.41 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from torch>=2.0.0->llamafactory==0.9.4.dev0) (11.3.3.41)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.55 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from torch>=2.0.0->llamafactory==0.9.4.dev0) (10.3.9.55)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.2.55 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from torch>=2.0.0->llamafactory==0.9.4.dev0) (11.7.2.55)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.7.53 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from torch>=2.0.0->llamafactory==0.9.4.dev0) (12.5.7.53)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from torch>=2.0.0->llamafactory==0.9.4.dev0) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from torch>=2.0.0->llamafactory==0.9.4.dev0) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.55 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from torch>=2.0.0->llamafactory==0.9.4.dev0) (12.8.55)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.61 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from torch>=2.0.0->llamafactory==0.9.4.dev0) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.0.11 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from torch>=2.0.0->llamafactory==0.9.4.dev0) (1.13.0.11)\n",
      "Requirement already satisfied: triton==3.3.1 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from torch>=2.0.0->llamafactory==0.9.4.dev0) (3.3.1)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from triton==3.3.1->torch>=2.0.0->llamafactory==0.9.4.dev0) (78.1.1)\n",
      "Requirement already satisfied: certifi in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from httpx>=0.24.1->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from httpx>=0.24.1->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.16.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from matplotlib>=3.7.0->llamafactory==0.9.4.dev0) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from matplotlib>=3.7.0->llamafactory==0.9.4.dev0) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from matplotlib>=3.7.0->llamafactory==0.9.4.dev0) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from matplotlib>=3.7.0->llamafactory==0.9.4.dev0) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from matplotlib>=3.7.0->llamafactory==0.9.4.dev0) (3.2.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->llamafactory==0.9.4.dev0) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from requests>=2.32.2->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from requests>=2.32.2->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (2.5.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.1.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=2.0.0->llamafactory==0.9.4.dev0) (1.3.0)\n",
      "Requirement already satisfied: termcolor in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from fire->llamafactory==0.9.4.dev0) (3.1.0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from librosa->llamafactory==0.9.4.dev0) (3.0.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from librosa->llamafactory==0.9.4.dev0) (0.61.2)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from librosa->llamafactory==0.9.4.dev0) (1.7.0)\n",
      "Requirement already satisfied: joblib>=1.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from librosa->llamafactory==0.9.4.dev0) (1.5.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from librosa->llamafactory==0.9.4.dev0) (5.2.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from librosa->llamafactory==0.9.4.dev0) (0.13.1)\n",
      "Requirement already satisfied: pooch>=1.1 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from librosa->llamafactory==0.9.4.dev0) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from librosa->llamafactory==0.9.4.dev0) (0.5.0.post1)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from librosa->llamafactory==0.9.4.dev0) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from librosa->llamafactory==0.9.4.dev0) (1.1.1)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from numba>=0.51.0->librosa->llamafactory==0.9.4.dev0) (0.44.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from pooch>=1.1->librosa->llamafactory==0.9.4.dev0) (4.3.8)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from scikit-learn>=1.1.0->librosa->llamafactory==0.9.4.dev0) (3.6.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from soundfile>=0.12.1->librosa->llamafactory==0.9.4.dev0) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa->llamafactory==0.9.4.dev0) (2.22)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages (from omegaconf->llamafactory==0.9.4.dev0) (4.9.3)\n",
      "Building wheels for collected packages: llamafactory\n",
      "  Building editable for llamafactory (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for llamafactory: filename=llamafactory-0.9.4.dev0-0.editable-py3-none-any.whl size=27651 sha256=7ed75f233bfe2ab33e5958a6f85c240c8630c8cc1a7460631a109bcf639310fe\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-jd_wi6v6/wheels/c5/0a/c2/28b4705dbb3d685eb19293f68ed95a6ac31ae294f37787de36\n",
      "Successfully built llamafactory\n",
      "Installing collected packages: llamafactory\n",
      "  Attempting uninstall: llamafactory\n",
      "    Found existing installation: llamafactory 0.9.4.dev0\n",
      "    Uninstalling llamafactory-0.9.4.dev0:\n",
      "      Successfully uninstalled llamafactory-0.9.4.dev0\n",
      "Successfully installed llamafactory-0.9.4.dev0\n"
     ]
    }
   ],
   "source": [
    "%cd /content/\n",
    "%rm -rf LLaMA-Factory\n",
    "!git clone --depth 1 https://github.com/hiyouga/LLaMA-Factory.git\n",
    "%cd LLaMA-Factory\n",
    "%ls\n",
    "!pip install -e .[torch,bitsandbytes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98bd18cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA version: 12.8\n",
      "CUDA available: True\n",
      "Device name: NVIDIA GeForce RTX 4090\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"CUDA version:\", torch.version.cuda)           # e.g. '12.1'\n",
    "print(\"CUDA available:\", torch.cuda.is_available())  # should be True\n",
    "print(\"Device name:\", torch.cuda.get_device_name(0)) # e.g. 'NVIDIA GeForce RTX 4090'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a83c58d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7bcae4fa48e44b3bf23fd68c3f13ab4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##login-info\n",
    "# !pip3 install ipywidgets\n",
    "from huggingface_hub import login, notebook_login\n",
    "notebook_login()\n",
    "# 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\n",
    "# wiki_demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23613ae9",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e9f2045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd1fa7a752fe4e72871755f63199a0f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples written: 320390\n",
      "\n",
      "First 200 characters of the first sample:\n",
      "Anarchism is a political philosophy and movement that is skeptical of all justifications for authority and seeks to abolish the institutions it claims maintain unnecessary coercion and hierarchy, typi\n",
      "\n",
      "✅ Correct: Raw text only.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Define the absolute path to the 'data' directory\n",
    "data_dir = '/home/ai-research-lab/MCSProjectbyWajahatalibasharat5Percent/LLaMA-Factory/data'\n",
    "# Ensure the 'data' directory exists\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "# Define the output file path within the 'data' directory\n",
    "# output_path = os.path.join(data_dir, 'wiki_1percent.json')\n",
    "output_path = os.path.join(data_dir, 'wiki_5percent.json')\n",
    "# Load the dataset with streaming\n",
    "dataset = load_dataset(\n",
    "    'wikimedia/wikipedia',\n",
    "    '20231101.en',\n",
    "    split='train',\n",
    "    streaming=True\n",
    ")\n",
    "\n",
    "# Estimate total size and compute 1%\n",
    "total_samples = dataset.info.splits['train'].num_examples\n",
    "# sample_size = int(0.01 * total_samples)\n",
    "sample_size = int(0.05 * total_samples)\n",
    "# Collect raw text samples\n",
    "text_samples = []\n",
    "for i, example in enumerate(dataset):\n",
    "    if i >= sample_size:\n",
    "        break\n",
    "    text_samples.append(example['text'])\n",
    "\n",
    "# Format as a list of {\"text\": ...}\n",
    "formatted_data = [{'text': t} for t in text_samples]\n",
    "\n",
    "# Save to JSON with UTF-8 encoding\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(formatted_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# Verification\n",
    "with open(output_path, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "    print(f'Total samples written: {len(data)}\\n')\n",
    "    first = data[0]['text'][:200]\n",
    "    print('First 200 characters of the first sample:')\n",
    "    print(first)\n",
    "    if '### Title:' in first or 'Wikipedia Article' in first:\n",
    "        print('\\n⚠️ WARNING: Detected Wikipedia formatting—expected raw text only.')\n",
    "    else:\n",
    "        print('\\n✅ Correct: Raw text only.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ced0467e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning Markdown files in: /home/ai-research-lab/MCSProjectbyWajahatalibasharat5Percent/LLaMA-Factory/data/Markdown/\n",
      "Collected 37 markdown documents and saved to /home/ai-research-lab/MCSProjectbyWajahatalibasharat5Percent/LLaMA-Factory/data/markdown_docs.jsonl\n",
      "\n",
      "First 3 lines of markdown_docs.jsonl:\n",
      "{\"text\": \"## [AS PASSED BY THE MAJLIS-E-SHOORA (PARLIAMENT)]\\n\\n## BILL\\n\\nto provide for setting up of the Pakistan International Airlines Corporation into a public limited company .\\n\\nWHEREAS it for   conversion of the Pakistan International Airlines   Corporation   into a 1984 (XLVII of 1984) and to deal with ancillary matters;\\n\\nIt is hereby enacted as follows:\\n\\n- 1 Short title, extent and commencement.- (l) This Act may be called the Pakistan International Airlines Corporation (Conversion) Act. 2016.\\n- It extends to the whole of Pakistan\\n- It shall come into force at once.\\n- 2 Definitions.- In this Act.  unless there is anything repugnant in the subject or context.\\n- (a) \\\"arrangement\\\" means an arrangement in writing between the Company and any relevant entity setting forth the terms. conditions and manner of transfer of o' Or more assets of the Company to 2 relevant entity along with the consideration for the same, which transfer is subject to be provisions of section 4;\\n- (b) \\\"assets includes all properties. rights and entitlements of every description and nature whatsoever. whether present or future. actual or contingent. and tangible or intangible, in Pakistan or elsewhere and includes but not limited to property held on trust. both movable and immovable. benefits. claims.   receivables, cash balances; documents, investments, privileges and powers;\\n- \\\"Company' mcans Pakistan International Airlines Corporation Limited incorporated under the Companies Ordinance:\\n- \\\"Companies Ordinance\\\" means the   Companies   Ordinance. 1984 (XLVII of 1984);\\n- \\\"Company request\\\" mneans a to the Federal Government to issue an order pursuant to section 4 to effect transfer to a relevant entity of specified assets in terms of the relevant arrangenment, provided nevertheless; such request may only be made once the Company has to that extent complied with the provisions of sub-section (3) of section 196 of the Companies Ordinance and the applicable code of corporate governance;\\n- \\\"conversion with all its cognate expressions means, in accordance with the provisions of this Act. the conversion of the Corporation into a Company:\\n- \\\"commencing date\\\" means the date of promulgation of this Act;\\n- h \\\"Corporation means the Pakistan International Airlines Corporation established under the Pakistan International Airlines Corporation Act. 1956 (XIX of 1956):\\n- \\\"liabilities includes all borrowings; duties. obligations; loans encumbrances of every   description and nature whatsoever in Pakistan elsewhere; whether present or future. actual or contingent, and disclosed or undisclosed; O\\n- \\\"order' means any order issued by the Federal  Government  pursuant to subsection (1 ) of section \\\"orders' shall be construed accordingly;\\n- \\\"PIAC Act\\\" means the Pakistan   International (XIX of 1956):\\n- proceedings includes any  suit. arbitration Or   administrative proceedings applications. appeals. awards, reviews or revisions filed or pending;\\n- m relevant entity' means any body corporate or company owned or controlled by the Federal Government or the Federal Government itself:\\n- (n) \\\"specified assets' means the assets specified in the relevant arrangements;\\n- 'undertakings ' include all projects; ventures and operations undertaken by the Corporation; individually or collectively . in collaboration with some other person; and\\n- \\\"validity period\\\" means   the period   starting   from the  commencing date   and ending on the second anniversary of the commencing date.. or on such earlier date as may be notified by the Federal Government in the official Gazette.\\n- 3 Conversion of Corporation into a Company - (i) The Corporation shall be deemed to have been converted into a company limited by shares with effect from the commencing date public\\n- 2) As and from the commending date,\\n- (a) the Company shall be deemed to hold and own all assets and liabilities of the Corporation  without any conveyance; alienation assignment  and withou. any further act. deed or registration and without   discharging Or invalidating any contract; and\\n- (b without prejudice to the generality of the foregoing clause; the Company shall;\\n- be entitled [0 the benefit of all notitications. licenses.   permissions, sanctions;   authorizations.  concessions;   decrees, orders and benefits whatsoever issued or granted in favour of the Corporation as on the commencing date, including but not limited to the permission connected with the of the securities of the Corporation on the relevant stock exchanges; and listing\\n- (ii) be deemed to have taken over and shall be entitled to enforce, all rights, licenses; and concessions and to have assumed all liabilities of the Corporation and shall be liable to pay and discharge all liabilities of every description and nature whatsoever of the Corporation. grants\\n- (3 The shareholders of the Company shall be deemed without any fresh issuance of shares   to own and hold the same number of fully shares   with such rights   and privileges (including as to class; kind and face value) as owned and Company shall be deemed to be equivalent to the authorized of the Corporation as on the commencing date and no fee or charges shall be payable in this regard. paid they capital\\n- All   proceedings of every description and nature   whatsoever by Or against  or relating to the Corporation pending on the commencing date in any court; tribunal, or other authority shall be continued, defended, prosecuted and enforced by or against or relating to the Corporation; and the same shall not abate, be discontinued, prejudiced or otherwise affected by the provisions of this Act.\\n- (5 The Company shall be deemed to be the successor-in-interest of the Corporation; and the name of the Company shall be deemed to have been substituted for the name of the   Corporation of attorney , consents;   undertakings; leases, grants, concessions, records of Central or documents of every description and nature   whatsoever relating to the Corporation and no objection shall be entertained by any court; tribunal or authority in regard to such substitution or on the ground that any such contract; agreement or document as aforesaid was, or with; the name of the Corporation and not the Company.\\n- (6) All  employees of the Corporation   shall be deemed to be employees of the Company on the same remuneration and other conditions of service, rights and privileges including but not  limited to the provisions as to their pension; provident   fund and gratuity; as the case may and other matters as were applicable to them before the conversion; including all existing retirement benefits of the employees whether funded or non-funded: be,\\n\\n## Provided that\\n\\n- Notwithstanding anything contained in this Act or nay other law; Or any decision of any court or tribunal, the employees of the Company shall continue to be govemed by non-statutory contractual terms, conditions, rules   and regulations which shall not   acquire;, Or be deemed to have acquired or be treated as having acquired, statutory status;\\n- No person deemed to be employed by the Company under this section shall be entitled to any compensation or benefit as a consequence of the conversion of the Corporation into a Company;\\n- (iii) The salaries; emoluments and all other terms of service of employees; whether permanent or contractual, shall not be changed to their disadvantage; and\\n- (iv) Pensions and other of the Corporation to   retired employees shall not be changed to their disadvantage.\\n- Notwithstanding the provisions of section 146 of the Companies Ordinance, the Company shall, upon conversion; continue all business and   undertakings of the Corporation as were carried on immediately to the commencing date. being prior\\n- 4 Power to pass orders for the transfer of assets.- (1) During the validity period and subject to a transfer of specified assets to a relevant entity substantially on the terms set forth in the relevant arrangement. prior\\n- (2) The orders shall binding on the Company; the relevant and any other person having any right; claim or liability in relation to the Company or any relevant entity . entity\\n- (3) As and from the date specified in the order, the specified assets shall, by virtue and to the extent provided in the relevant order, stand transferred and vest in, the relevant without nay conveyance; alienation or assignment and without any further act, deed Or registration and without discharging or invalidating any contract, and be subject to the terms of the relevant order in all cases. to, entity ,\\n- Representation on the Board of Directors and all other rights and privileges of shareholders of the Company; or any of its subsidiary companies carrying on air-transport business; shall be proportionate to their share-holding.\\n- Explanation: - Management control of the Company and any of its subsidiary companies in the above circumstances shall continue to vest in the majority shareholder; which shall be the Federal Government and whose share shall not be less than one percent. fifty\\n- 5 The Federal Government shall carry out or cause to be carried out valuation of the assets of the Company, and its subsidiary companies carrying on air-transport business, by a recognized valuator before transferring any shares of these companies to a third party .\\n- The Public Procurement Regulatory Authority Ordinance; 2002 (Ordinance XXII of 2002) and rules framed thereunder; as presently applicable, shall continue to apply to all transactions under this Act.\\n- 5 Guarantees to remain in force Notwithstanding the repeal of the PIAC Act; all guarantees   given by the Federal Government to any   person;   including   foreign or local institutions; to secure any of the liabilities of the Corporation shall remain in full force and affect as though they were given on behalf of the Company.\\n- 6 The Federal Government may, by notification in the Official Gazette, waive any duty, fee or any other charge that may be under any Federal law for the time in force. payable tax, being\\n- 7 Name and Headquarters of Company - (1) The name of the Company shall not be changed without the consent; in writing; of the Federal Government.\\n- (2) The Headquarters of the Company and any of its subsidiary companies carrying on air-transport business shall be at Karachi.\\n- 8 No or Neither the conversion nor the transfer of any asset of the Company through an order shall given rise to any or loss under the Income Tax Ordinance; 2001 (XLXof 2001) loss gain gain\\n- 9 Act to override - The provisions of this Act and the orders issued hereunder shall have effect notwithstanding anything to the contrary contained in any other law for the time in force. being\\n- 10. difficulty arises during the validity in giving effect to any provision of this Act; the Federal Government may, be notification in the official Gazette; make such provisions as may appear to it to be necessary for the purpose of removing the difficulty . period\\n- 11 Repeal - (1) The PIAC Act is hereby repealed.\\n- On repeal of PIAC Act under sub-section (l), nothing contained in the said Act shall be applicable to the Company; its shareholders Or any other person that may have had interest in the Corporation immediately to the conversion. prior\"}\n",
      "{\"text\": \"<!-- image -->\\n\\nTerminal-1 JIAP , Karachi-75200 Tel: (92-21) 9924-2033 Fax: (92-21) 9924-2032\\n\\n## HEADQUARTERS PAKISTAN CIVIL AVIATION AUTHORITY\\n\\ndairtransport@caapakistan com pk\\n\\nAuqust 30 2021\\n\\n## IMPLEMENTATION OF STANDARD OPERATING PROCEDURES PRIVATEAIRCRAFFLGHTS\\n\\nReference our letter of even number dated August 13, 2021 containing Categorized   Country Lists and   guidelines   concerning inbound travel to Pakistan.\\n\\n- 2. The instructions contained in the above-mentioned letter are hereby extended till September 30, 2021. Consequenlly; all Pakistanis whose return to Pakistan from Category C Countries is scheduled till September 30, 2021, may travel to Pakistan without grant of a special exemption and while in possession of valid negative PCR Test Result conducted within the 72 hours to commencement of travel to Pakistan; subject to conformance with all other applicable rules regulations . Inbound travel to Pakistan from Category € Countries for all other passengers will continue to remain banned. prior\\n- 3. or all passengers arriving in Pakistan will, however, be subjected to and Quarantine stipulations as per procedure in-vogue. Any Testing\\n- 4 All concerned are directed to ensure strict compliance.\\n\\n<!-- image -->\\n\\n(IRFANSABIR)\\n\\nAirCommodore (Retd)\\n\\nDirector AT &amp; ER\\n\\nAll Scheduled and Charter Airline Operators All Ground Handling Agents All Private Operators All Authorized Flight Permission Agents\\n\\n## Copyto:\\n\\n- Additional Deputy DGCAA (Reg) HQCAA; Karachi\\n- Joint Secretary II, Aviation Division; Islamabad\\n- Director Airport Services, HQCAA; Karachi\\n- All Chief Operating OfficerslAirport Managers\\n- PSO to DGCAA, HQCAA, Karachi\\n- Director Operations; Airports Security Force, ASF HQ; Karachi\"}\n",
      "{\"text\": \"<!-- image -->\\n\\n## HEADQUARTERS PAKISTAN CIVIL AVIATION AUTHORITY\\n\\nTerminal-1 JIAP , Karachi-75200\\n\\nTel: (92-21) 9924-2033\\n\\nFax: (92-21) 9924-2032\\n\\ndairtransport @caapakistan compk\\n\\nJuly 27 2021\\n\\n## PRIVATE AIRCRAFT FLIGHTS\\n\\nReference is made to our letters of even number dated June 12 and July 12, 2021 providing guidelines on inbound travel to Pakistan from Categorized Country Lists .\\n\\n- 2 The instructions and guidelines coriained in our above-referred letters are hereby extended upto August 31, 2021\\\\_ Consequently, all Pakistanis whose return to Pakistan from Category C Countries is scheduled till August 38, 2021 may travel to Pakistan without grant of a special exemption and while in possession of a valid negative PCR Test Result conducted within the 72 hours to commencement of travel to Pakistan; subject to conformance with all other applicable rules / regulations. Inbound travel to Pakistan from Category C Countries for all other passengers will continue to remain banned. prior\\n- 3 or all passengers arriving in Pakistan will, however; be subjected to Testing and Quarantine stipulations as per procedure in-vogue. Any\\n- 4 All concerned are directed t0 ensure strict compliance.\\n\\n(IRFAN SABIR)\\n\\nAir Comhodore (Retd.)\\n\\nDirector AT &amp; ER\\n\\n<!-- image -->\\n\\nAll Scheduled and Charter Air Carriers All Private Operators All Authorized Flight Permission Agents All Ground Handling Agents\\n\\n## Copy to:\\n\\n- Joint Secretary II, Aviation Division; Islamabad\\n- PSO to DG CAA; HQCAA, Karachi\\n- Additional Deputy DGCAA, HQCAA, Karachi\\n- All Chief Operating Officers/Airport Managers\\n- Director Operations, ASF, ASF HQ; Karachi\\n\\n<!-- image -->\\n\\n## HEADQUARTERS PAKISTAN CIVIL AVIATION AUTHORITY\\n\\nTerminal-1 JIAP , Karachi-75200\\n\\nTel: (92-21) 9924-2033\\n\\nFax: (92-21) 9924-2032\\n\\ndairtransport @caapakistan compk\\n\\nRef: HQCAA10895O1AINR\\n\\nJuly 12 2021\\n\\n## IMPLEMENIATION OF STANDARD OPERATING PROCEDURES PRIVATE AIRCRAFT FLIGHTS\\n\\nReference is made to our letter of even number dated June 12 and 29, 2021  providing  guidelines on inbound travel to Pakistan from Categorized Country Lists.\\n\\n- 2 The instructions and guidelines coriained in our above-referred letters are hereby extended upto July 31, 2021. Consequently; all Pakistanis whose return to Pakistan from Category C Countries is scheduled till July 31, 2021 may travel to Pakistan wilhout grant of a special   exemption and while in possession of a valid negative PCR Test Result conducted within the 72 hours to commencement of travel to Pakistan, subject to conformance with all other applicable rules / regulations. 'bound travel to Pakistan from Category € Countries for all other passengers will continue to remain banned. prior\\n- 3 or all passengers arriving in Pakistan will, however; be subjected t0 Testing and Quarantine stipulations as per procedure in-vogue. Any\\n- 4 All concerned are directed t0 ensure strict compliance\\n\\nAir Copimodore\\n\\n(IRFAN SABIR) (Retd:)\\n\\nDirector AT &amp; ER\\n\\n<!-- image -->\\n\\nAll Scheduled and Charter Air Carriers\\n\\nAll Private Operators All Authorized Flight Permission Agents All Ground Handling Agents\\n\\n## Copy\\n\\n- Joint Secretary II, Aviation Division; Islamabad\\n- PSO to DG CAA; HQCAA; Karachi\\n- Additional Deputy DGCAA, HQCAA, Karachi\\n- All Chief Operating Officers/Airport Managers\\n- Director Operations; ASF, ASF HQ, Karachi\\n\\n<!-- image -->\\n\\n## HEADQUARTERS PAKISTAN CIVIL AVIATION AUTHORITY\\n\\nTerminal-1 JIAP , Karachi-75200\\n\\nTel: (92-21) 9924-2033\\n\\nFax: (92-21) 9924-2032\\n\\ndairtransport@caapakistan com pk\\n\\nJune 29 2021\\n\\n## IMPLEMENTATION OF STANDARD OPERATING PROCEDURES PRIVATE AIRCRAFTFLIGHIS\\n\\nReference our letter of even number dated June 12, 2021 containing Categorized   Country Lists and guidelines   concerning inbound travel to Pakistan.\\n\\n- 2 The instructions and guidelines contained in our above-referred letter are hereby extended upto July 15, 2021. Consequently; all Pakistanis may return to Pakistan from Category C Countries upto July 15, 2021 while in possession of valid negative PCR Test Result conducted within the 72 hours to commencement of travel to Pakistan; subject to conformance with all other applicable rules regulations. Inbound travel t0 Pakistan from Category € Countries for all other passengers will continue to remain banned. prior\\n- 3 or all passengers arriving in Pakistan will, however; be subjected to Testing and Quarantine stipulations as per procedure in-vogue. Any\\n- 4 All concerned are directed to ensure strict compliance.\\n\\n<!-- image -->\\n\\nAll Scheduled and Charter Airline Operators All Ground Handling Agents All Private Operators All Authorized Flight Permission Agents\\n\\n- Joint Secretary II, Aviation Division; Islamabad\\n- Director Security, HQCAA, Karachi\\n- Additional Deputy DGCAA (Reg), HQCAA; Karachi\\n- PSO to DGCAA, HQCAA, Karachi\\n- All Chief Operating OfficerslAirport Managers\\n\\n<!-- image -->\\n\\n## HEADQUARTERS PAKISTAN CIVIL AVIATION AUTHORITY\\n\\nTerminal-1 JIAP , Karachi-75200\\n\\nTel: (92-21) 9924-2033\\n\\nFax: (92-21) 9924-2032\\n\\ndairtransport@caapakistan com pk\\n\\nJune 12 2021\\n\\n## IMPLEMENTATION OF STANDARD OPERATING PROCEDURES PRIVATE AIRCRAFTFLIGHIS\\n\\nReference our   letter of even number  dated 22 and 23, 2021 containing Categorized Country Lists and guidelines concerning inbound travel to Pakistan. May\\n\\n- 2 Revised Category C Country List duly approved by the Competent Authority is enclosed herewith and will become effective immediately. Accordingly; travel to Pakistan from Category C Countries will   continue to remain banned and only allowed subject to grant of special exemption from the NCOC Exemptions Committee. being\\n- 3. Notwithstanding the foregoing; all Pakistanis who have scheduled return to Pakistan from Category C Countries in the month of June; 2021 will be allowed to travel to Pakistan and will be exempted from the inbound travel ban placed on Category C Countries. Such passengers will; however be subjected to Testing and Quarantine stipulations upon arrival in Pakistan as per procedure in-vogue.\\n- 4 . All concerned are directed to ensure strict compliance.\\n\\n<!-- image -->\\n\\nAll Scheduled and Charter Airline Operators All Ground Handling Agents All Private Operators All Authorized Flight Permission Agents\\n\\n## Copy\\n\\n- Additional Deputy DGCAA (Reg) HQCAA, Karachi\\n- Joint Secretary II, Aviation Division; Islamabad\\n- Director Security; HQCAA, Karachi\\n- All Chief Operating OfficerslAirport Managers\\n- PSO t0 DGCAA, HQCAA, Karachi\\n- Director Operations, Airports Security Force; ASF HQ; Karachi\\n\\n## UPDATED LISI JUNE 12 2021 VALID WITH IMMEDIATEEFFECI\\n\\nINTERNATIONAL TRAVELLERS FROM ANY COUNTRY ARE REQUIRED TO POSSESS VALID NEGATIVE PCR TEST CERTIFICATION CONDUCTED WITHIN THE 72 HOURS PRIOR TO COMMENCEMENT OF TRAVEL TO PAKISTAN\\n\\n## CATEGORYC\\n\\nINTERNATIONAL TRAVEL TO PAKISTAN FROM CATEGORY c COUNTRIES MENTIONED BELOW IS BANNED AND ONLY ALLOWED SUBJECT TO EXEMPTION BY COMMITTEE AS PER PROCEDURE IN VOGUE\\n\\n|   Sr . | Country            |\\n|--------|--------------------|\\n|     01 | Arqentina          |\\n|     02 | Bangladesh         |\\n|     03 | Bhutan             |\\n|     04 | Bolivia            |\\n|     05 | Brazil             |\\n|     06 | Chile              |\\n|     07 | Colombia           |\\n|     08 | Costa Rica         |\\n|     09 | Dominican Republic |\\n|     10 | Ecuador            |\\n|     11 | India              |\\n|     12 | Indonesia          |\\n|     13 | Iran               |\\n|     14 | Iraq               |\\n|     15 | Maldives           |\\n|     16 | Mexico             |\\n|     17 | Namibia            |\\n|     18 | Nepal              |\\n|     19 | Paraquay           |\\n|     20 | Peru               |\\n|     21 | Philippines        |\\n|     22 | South Africa       |\\n|     23 | Sri Lanka          |\\n|     24 | Trinidadand Tobago |\\n|     25 | Tunisia            |\\n|     26 | Uruquay            |\\n\\nNote: Pakistani whose return from Category C countries is scheduled in June 2021 have been excluded from exemption process. However, will undergo already emplaced inbound testing / Quarantine protocols. they\"}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Define the directory containing your Markdown files\n",
    "# --- MAKE SURE THIS PATH IS EXACTLY CORRECT ---\n",
    "markdown_dir = '/home/ai-research-lab/MCSProjectbyWajahatalibasharat5Percent/LLaMA-Factory/data/Markdown/'\n",
    "\n",
    "# Define the output JSONL file path within the 'data' directory\n",
    "# (It's good practice to keep processed data directly in 'data' or a 'processed_data' subfolder)\n",
    "output_jsonl_path = '/home/ai-research-lab/MCSProjectbyWajahatalibasharat5Percent/LLaMA-Factory/data/markdown_docs.jsonl'\n",
    "\n",
    "# Ensure the parent directory for output_jsonl_path exists\n",
    "os.makedirs(os.path.dirname(output_jsonl_path), exist_ok=True)\n",
    "\n",
    "\n",
    "# Collect text from Markdown files\n",
    "markdown_samples = []\n",
    "# Check if the markdown_dir exists\n",
    "if not os.path.exists(markdown_dir):\n",
    "    print(f\"Error: Markdown directory not found at {markdown_dir}\")\n",
    "else:\n",
    "    print(f\"Scanning Markdown files in: {markdown_dir}\")\n",
    "    for filename in os.listdir(markdown_dir):\n",
    "        if filename.endswith(\".md\"):\n",
    "            filepath = os.path.join(markdown_dir, filename)\n",
    "            try:\n",
    "                with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                    content = f.read()\n",
    "                    if content.strip(): # Only add non-empty files after stripping whitespace\n",
    "                        markdown_samples.append({'text': content})\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {filepath}: {e}\")\n",
    "\n",
    "# Save to JSONL\n",
    "if markdown_samples:\n",
    "    with open(output_jsonl_path, 'w', encoding='utf-8') as f:\n",
    "        for sample in markdown_samples:\n",
    "            f.write(json.dumps(sample, ensure_ascii=False) + '\\n')\n",
    "    print(f\"Collected {len(markdown_samples)} markdown documents and saved to {output_jsonl_path}\")\n",
    "\n",
    "    # Optional: Verify first few lines\n",
    "    print(\"\\nFirst 3 lines of markdown_docs.jsonl:\")\n",
    "    with open(output_jsonl_path, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i >= 3:\n",
    "                break\n",
    "            print(line.strip())\n",
    "else:\n",
    "    print(f\"No Markdown files found or processed in {markdown_dir}. Check the directory and file extensions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "085eda19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing /home/ai-research-lab/MCSProjectbyWajahatalibasharat5Percent/LLaMA-Factory/data/dataset_info.json successfully.\n",
      "\n",
      "Successfully updated /home/ai-research-lab/MCSProjectbyWajahatalibasharat5Percent/LLaMA-Factory/data/dataset_info.json with 'wiki_5percent' and 'markdown_docs' entries.\n",
      "\n",
      "--- Current content of dataset_info.json ---\n",
      "{\n",
      "  \"identity\": {\n",
      "    \"file_name\": \"identity.json\"\n",
      "  },\n",
      "  \"alpaca_en_demo\": {\n",
      "    \"file_name\": \"alpaca_en_demo.json\"\n",
      "  },\n",
      "  \"alpaca_zh_demo\": {\n",
      "    \"file_name\": \"alpaca_zh_demo.json\"\n",
      "  },\n",
      "  \"glaive_toolcall_en_demo\": {\n",
      "    \"file_name\": \"glaive_toolcall_en_demo.json\",\n",
      "    \"formatting\": \"sharegpt\",\n",
      "    \"columns\": {\n",
      "      \"messages\": \"conversations\",\n",
      "      \"tools\": \"tools\"\n",
      "    }\n",
      "  },\n",
      "  \"glaive_toolcall_zh_demo\": {\n",
      "    \"file_name\": \"glaive_toolcall_zh_demo.json\",\n",
      "    \"formatting\": \"sharegpt\",\n",
      "    \"columns\": {\n",
      "      \"messages\": \"conversations\",\n",
      "      \"tools\": \"tools\"\n",
      "    }\n",
      "  },\n",
      "  \"mllm_demo\": {\n",
      "    \"file_name\": \"mllm_demo.json\",\n",
      "    \"formatting\": \"sharegpt\",\n",
      "    \"columns\": {\n",
      "      \"messages\": \"messages\",\n",
      "      \"images\": \"images\"\n",
      "    },\n",
      "    \"tags\": {\n",
      "      \"role_tag\": \"role\",\n",
      "      \"content_tag\": \"content\",\n",
      "      \"user_tag\": \"user\",\n",
      "      \"assistant_tag\": \"assistant\"\n",
      "    }\n",
      "  },\n",
      "  \"mllm_audio_demo\": {\n",
      "    \"file_name\": \"mllm_audio_demo.json\",\n",
      "    \"formatting\": \"sharegpt\",\n",
      "    \"columns\": {\n",
      "      \"messages\": \"messages\",\n",
      "      \"audios\": \"audios\"\n",
      "    },\n",
      "    \"tags\": {\n",
      "      \"role_tag\": \"role\",\n",
      "      \"content_tag\": \"content\",\n",
      "      \"user_tag\": \"user\",\n",
      "      \"assistant_tag\": \"assistant\"\n",
      "    }\n",
      "  },\n",
      "  \"mllm_video_demo\": {\n",
      "    \"file_name\": \"mllm_video_demo.json\",\n",
      "    \"formatting\": \"sharegpt\",\n",
      "    \"columns\": {\n",
      "      \"messages\": \"messages\",\n",
      "      \"videos\": \"videos\"\n",
      "    },\n",
      "    \"tags\": {\n",
      "      \"role_tag\": \"role\",\n",
      "      \"content_tag\": \"content\",\n",
      "      \"user_tag\": \"user\",\n",
      "      \"assistant_tag\": \"assistant\"\n",
      "    }\n",
      "  },\n",
      "  \"mllm_video_audio_demo\": {\n",
      "    \"file_name\": \"mllm_video_audio_demo.json\",\n",
      "    \"formatting\": \"sharegpt\",\n",
      "    \"columns\": {\n",
      "      \"messages\": \"messages\",\n",
      "      \"videos\": \"videos\",\n",
      "      \"audios\": \"audios\"\n",
      "    },\n",
      "    \"tags\": {\n",
      "      \"role_tag\": \"role\",\n",
      "      \"content_tag\": \"content\",\n",
      "      \"user_tag\": \"user\",\n",
      "      \"assistant_tag\": \"assistant\"\n",
      "    }\n",
      "  },\n",
      "  \"alpaca_en\": {\n",
      "    \"hf_hub_url\": \"llamafactory/alpaca_en\",\n",
      "    \"ms_hub_url\": \"llamafactory/alpaca_en\",\n",
      "    \"om_hub_url\": \"HaM/alpaca_en\"\n",
      "  },\n",
      "  \"alpaca_zh\": {\n",
      "    \"hf_hub_url\": \"llamafactory/alpaca_zh\",\n",
      "    \"ms_hub_url\": \"llamafactory/alpaca_zh\"\n",
      "  },\n",
      "  \"alpaca_gpt4_en\": {\n",
      "    \"hf_hub_url\": \"llamafactory/alpaca_gpt4_en\",\n",
      "    \"ms_hub_url\": \"llamafactory/alpaca_gpt4_en\"\n",
      "  },\n",
      "  \"alpaca_gpt4_zh\": {\n",
      "    \"hf_hub_url\": \"llamafactory/alpaca_gpt4_zh\",\n",
      "    \"ms_hub_url\": \"llamafactory/alpaca_gpt4_zh\",\n",
      "    \"om_hub_url\": \"State_Cloud/alpaca-gpt4-data-zh\"\n",
      "  },\n",
      "  \"glaive_toolcall_en\": {\n",
      "    \"hf_hub_url\": \"llamafactory/glaive_toolcall_en\",\n",
      "    \"formatting\": \"sharegpt\",\n",
      "    \"columns\": {\n",
      "      \"messages\": \"conversations\",\n",
      "      \"tools\": \"tools\"\n",
      "    }\n",
      "  },\n",
      "  \"glaive_toolcall_zh\": {\n",
      "    \"hf_hub_url\": \"llamafactory/glaive_toolcall_zh\",\n",
      "    \"formatting\": \"sharegpt\",\n",
      "    \"columns\": {\n",
      "      \"messages\": \"conversations\",\n",
      "      \"tools\": \"tools\"\n",
      "    }\n",
      "  },\n",
      "  \"lima\": {\n",
      "    \"hf_hub_url\": \"llamafactory/lima\",\n",
      "    \"formatting\": \"sharegpt\"\n",
      "  },\n",
      "  \"guanaco\": {\n",
      "    \"hf_hub_url\": \"JosephusCheung/GuanacoDataset\",\n",
      "    \"ms_hub_url\": \"AI-ModelScope/GuanacoDataset\"\n",
      "  },\n",
      "  \"belle_2m\": {\n",
      "    \"hf_hub_url\": \"BelleGroup/train_2M_CN\",\n",
      "    \"ms_hub_url\": \"AI-ModelScope/train_2M_CN\"\n",
      "  },\n",
      "  \"belle_1m\": {\n",
      "    \"hf_hub_url\": \"BelleGroup/train_1M_CN\",\n",
      "    \"ms_hub_url\": \"AI-ModelScope/train_1M_CN\"\n",
      "  },\n",
      "  \"belle_0.5m\": {\n",
      "    \"hf_hub_url\": \"BelleGroup/train_0.5M_CN\",\n",
      "    \"ms_hub_url\": \"AI-ModelScope/train_0.5M_CN\"\n",
      "  },\n",
      "  \"belle_dialog\": {\n",
      "    \"hf_hub_url\": \"BelleGroup/generated_chat_0.4M\",\n",
      "    \"ms_hub_url\": \"AI-ModelScope/generated_chat_0.4M\"\n",
      "  },\n",
      "  \"belle_math\": {\n",
      "    \"hf_hub_url\": \"BelleGroup/school_math_0.25M\",\n",
      "    \"ms_hub_url\": \"AI-ModelScope/school_math_0.25M\"\n",
      "  },\n",
      "  \"belle_multiturn\": {\n",
      "    \"script_url\": \"belle_multiturn\",\n",
      "    \"formatting\": \"sharegpt\"\n",
      "  },\n",
      "  \"ultra_chat\": {\n",
      "    \"script_url\": \"ultra_chat\",\n",
      "    \"formatting\": \"sharegpt\"\n",
      "  },\n",
      "  \"open_platypus\": {\n",
      "    \"hf_hub_url\": \"garage-bAInd/Open-Platypus\",\n",
      "    \"ms_hub_url\": \"AI-ModelScope/Open-Platypus\"\n",
      "  },\n",
      "  \"codealpaca\": {\n",
      "    \"hf_hub_url\": \"sahil2801/CodeAlpaca-20k\",\n",
      "    \"ms_hub_url\": \"AI-ModelScope/CodeAlpaca-20k\"\n",
      "  },\n",
      "  \"alpaca_cot\": {\n",
      "    \"hf_hub_url\": \"QingyiSi/Alpaca-CoT\",\n",
      "    \"ms_hub_url\": \"AI-ModelScope/Alpaca-CoT\"\n",
      "  },\n",
      "  \"openorca\": {\n",
      "    \"hf_hub_url\": \"Open-Orca/OpenOrca\",\n",
      "    \"ms_hub_url\": \"AI-ModelScope/OpenOrca\",\n",
      "    \"columns\": {\n",
      "      \"prompt\": \"question\",\n",
      "      \"response\": \"response\",\n",
      "      \"system\": \"system_prompt\"\n",
      "    }\n",
      "  },\n",
      "  \"slimorca\": {\n",
      "    \"hf_hub_url\": \"Open-Orca/SlimOrca\",\n",
      "    \"formatting\": \"sharegpt\"\n",
      "  },\n",
      "  \"mathinstruct\": {\n",
      "    \"hf_hub_url\": \"TIGER-Lab/MathInstruct\",\n",
      "    \"ms_hub_url\": \"AI-ModelScope/MathInstruct\",\n",
      "    \"columns\": {\n",
      "      \"prompt\": \"instruction\",\n",
      "      \"response\": \"output\"\n",
      "    }\n",
      "  },\n",
      "  \"firefly\": {\n",
      "    \"hf_hub_url\": \"YeungNLP/firefly-train-1.1M\",\n",
      "    \"columns\": {\n",
      "      \"prompt\": \"input\",\n",
      "      \"response\": \"target\"\n",
      "    }\n",
      "  },\n",
      "  \"wikiqa\": {\n",
      "    \"hf_hub_url\": \"wiki_qa\",\n",
      "    \"columns\": {\n",
      "      \"prompt\": \"question\",\n",
      "      \"response\": \"answer\"\n",
      "    }\n",
      "  },\n",
      "  \"webqa\": {\n",
      "    \"hf_hub_url\": \"suolyer/webqa\",\n",
      "    \"ms_hub_url\": \"AI-ModelScope/webqa\",\n",
      "    \"columns\": {\n",
      "      \"prompt\": \"input\",\n",
      "      \"response\": \"output\"\n",
      "    }\n",
      "  },\n",
      "  \"webnovel\": {\n",
      "    \"hf_hub_url\": \"zxbsmk/webnovel_cn\",\n",
      "    \"ms_hub_url\": \"AI-ModelScope/webnovel_cn\"\n",
      "  },\n",
      "  \"nectar_sft\": {\n",
      "    \"hf_hub_url\": \"AstraMindAI/SFT-Nectar\",\n",
      "    \"ms_hub_url\": \"AI-ModelScope/SFT-Nectar\"\n",
      "  },\n",
      "  \"deepctrl\": {\n",
      "    \"ms_hub_url\": \"deepctrl/deepctrl-sft-data\"\n",
      "  },\n",
      "  \"adgen_train\": {\n",
      "    \"hf_hub_url\": \"HasturOfficial/adgen\",\n",
      "    \"ms_hub_url\": \"AI-ModelScope/adgen\",\n",
      "    \"split\": \"train\",\n",
      "    \"columns\": {\n",
      "      \"prompt\": \"content\",\n",
      "      \"response\": \"summary\"\n",
      "    }\n",
      "  },\n",
      "  \"adgen_eval\": {\n",
      "    \"hf_hub_url\": \"HasturOfficial/adgen\",\n",
      "    \"ms_hub_url\": \"AI-ModelScope/adgen\",\n",
      "    \"split\": \"validation\",\n",
      "    \"columns\": {\n",
      "      \"prompt\": \"content\",\n",
      "      \"response\": \"summary\"\n",
      "    }\n",
      "  },\n",
      "  \"sharegpt_hyper\": {\n",
      "    \"hf_hub_url\": \"totally-not-an-llm/sharegpt-hyperfiltered-3k\",\n",
      "    \"formatting\": \"sharegpt\"\n",
      "  },\n",
      "  \"sharegpt4\": {\n",
      "    \"hf_hub_url\": \"shibing624/sharegpt_gpt4\",\n",
      "    \"ms_hub_url\": \"AI-ModelScope/sharegpt_gpt4\",\n",
      "    \"formatting\": \"sharegpt\"\n",
      "  },\n",
      "  \"ultrachat_200k\": {\n",
      "    \"hf_hub_url\": \"HuggingFaceH4/ultrachat_200k\",\n",
      "    \"ms_hub_url\": \"AI-ModelScope/ultrachat_200k\",\n",
      "    \"split\": \"train_sft\",\n",
      "    \"formatting\": \"sharegpt\",\n",
      "    \"columns\": {\n",
      "      \"messages\": \"messages\"\n",
      "    },\n",
      "    \"tags\": {\n",
      "      \"role_tag\": \"role\",\n",
      "      \"content_tag\": \"content\",\n",
      "      \"user_tag\": \"user\",\n",
      "      \"assistant_tag\": \"assistant\"\n",
      "    }\n",
      "  },\n",
      "  \"agent_instruct\": {\n",
      "    \"hf_hub_url\": \"THUDM/AgentInstruct\",\n",
      "    \"ms_hub_url\": \"ZhipuAI/AgentInstruct\",\n",
      "    \"formatting\": \"sharegpt\"\n",
      "  },\n",
      "  \"lmsys_chat\": {\n",
      "    \"hf_hub_url\": \"lmsys/lmsys-chat-1m\",\n",
      "    \"ms_hub_url\": \"AI-ModelScope/lmsys-chat-1m\",\n",
      "    \"formatting\": \"sharegpt\",\n",
      "    \"columns\": {\n",
      "      \"messages\": \"conversation\"\n",
      "    },\n",
      "    \"tags\": {\n",
      "      \"role_tag\": \"role\",\n",
      "      \"content_tag\": \"content\",\n",
      "      \"user_tag\": \"user\",\n",
      "      \"assistant_tag\": \"assistant\"\n",
      "    }\n",
      "  },\n",
      "  \"evol_instruct\": {\n",
      "    \"hf_hub_url\": \"WizardLM/WizardLM_evol_instruct_V2_196k\",\n",
      "    \"ms_hub_url\": \"AI-ModelScope/WizardLM_evol_instruct_V2_196k\",\n",
      "    \"formatting\": \"sharegpt\"\n",
      "  },\n",
      "  \"glaive_toolcall_100k\": {\n",
      "    \"hf_hub_url\": \"hiyouga/glaive-function-calling-v2-sharegpt\",\n",
      "    \"formatting\": \"sharegpt\",\n",
      "    \"columns\": {\n",
      "      \"messages\": \"conversations\",\n",
      "      \"tools\": \"tools\"\n",
      "    }\n",
      "  },\n",
      "  \"cosmopedia\": {\n",
      "    \"hf_hub_url\": \"HuggingFaceTB/cosmopedia\",\n",
      "    \"columns\": {\n",
      "      \"prompt\": \"prompt\",\n",
      "      \"response\": \"text\"\n",
      "    }\n",
      "  },\n",
      "  \"stem_zh\": {\n",
      "    \"hf_hub_url\": \"hfl/stem_zh_instruction\"\n",
      "  },\n",
      "  \"ruozhiba_gpt4\": {\n",
      "    \"hf_hub_url\": \"hfl/ruozhiba_gpt4_turbo\"\n",
      "  },\n",
      "  \"neo_sft\": {\n",
      "    \"hf_hub_url\": \"m-a-p/neo_sft_phase2\",\n",
      "    \"formatting\": \"sharegpt\"\n",
      "  },\n",
      "  \"magpie_pro_300k\": {\n",
      "    \"hf_hub_url\": \"Magpie-Align/Magpie-Pro-300K-Filtered\",\n",
      "    \"formatting\": \"sharegpt\"\n",
      "  },\n",
      "  \"magpie_ultra\": {\n",
      "    \"hf_hub_url\": \"argilla/magpie-ultra-v0.1\",\n",
      "    \"columns\": {\n",
      "      \"prompt\": \"instruction\",\n",
      "      \"response\": \"response\"\n",
      "    }\n",
      "  },\n",
      "  \"web_instruct\": {\n",
      "    \"hf_hub_url\": \"TIGER-Lab/WebInstructSub\",\n",
      "    \"columns\": {\n",
      "      \"prompt\": \"question\",\n",
      "      \"response\": \"answer\"\n",
      "    }\n",
      "  },\n",
      "  \"openo1_sft\": {\n",
      "    \"hf_hub_url\": \"llamafactory/OpenO1-SFT\",\n",
      "    \"ms_hub_url\": \"llamafactory/OpenO1-SFT\",\n",
      "    \"columns\": {\n",
      "      \"prompt\": \"prompt\",\n",
      "      \"response\": \"response\"\n",
      "    }\n",
      "  },\n",
      "  \"open_thoughts\": {\n",
      "    \"hf_hub_url\": \"llamafactory/OpenThoughts-114k\",\n",
      "    \"formatting\": \"sharegpt\",\n",
      "    \"columns\": {\n",
      "      \"messages\": \"messages\"\n",
      "    },\n",
      "    \"tags\": {\n",
      "      \"role_tag\": \"role\",\n",
      "      \"content_tag\": \"content\",\n",
      "      \"user_tag\": \"user\",\n",
      "      \"assistant_tag\": \"assistant\",\n",
      "      \"system_tag\": \"system\"\n",
      "    }\n",
      "  },\n",
      "  \"open_r1_math\": {\n",
      "    \"hf_hub_url\": \"llamafactory/OpenR1-Math-94k\",\n",
      "    \"formatting\": \"sharegpt\",\n",
      "    \"columns\": {\n",
      "      \"messages\": \"messages\"\n",
      "    },\n",
      "    \"tags\": {\n",
      "      \"role_tag\": \"role\",\n",
      "      \"content_tag\": \"content\",\n",
      "      \"user_tag\": \"user\",\n",
      "      \"assistant_tag\": \"assistant\",\n",
      "      \"system_tag\": \"system\"\n",
      "    }\n",
      "  },\n",
      "  \"chinese_r1_distill\": {\n",
      "    \"hf_hub_url\": \"Congliu/Chinese-DeepSeek-R1-Distill-data-110k-SFT\",\n",
      "    \"ms_hub_url\": \"liucong/Chinese-DeepSeek-R1-Distill-data-110k-SFT\"\n",
      "  },\n",
      "  \"llava_1k_en\": {\n",
      "    \"hf_hub_url\": \"BUAADreamer/llava-en-zh-2k\",\n",
      "    \"subset\": \"en\",\n",
      "    \"formatting\": \"sharegpt\",\n",
      "    \"columns\": {\n",
      "      \"messages\": \"messages\",\n",
      "      \"images\": \"images\"\n",
      "    },\n",
      "    \"tags\": {\n",
      "      \"role_tag\": \"role\",\n",
      "      \"content_tag\": \"content\",\n",
      "      \"user_tag\": \"user\",\n",
      "      \"assistant_tag\": \"assistant\"\n",
      "    }\n",
      "  },\n",
      "  \"llava_1k_zh\": {\n",
      "    \"hf_hub_url\": \"BUAADreamer/llava-en-zh-2k\",\n",
      "    \"subset\": \"zh\",\n",
      "    \"formatting\": \"sharegpt\",\n",
      "    \"columns\": {\n",
      "      \"messages\": \"messages\",\n",
      "      \"images\": \"images\"\n",
      "    },\n",
      "    \"tags\": {\n",
      "      \"role_tag\": \"role\",\n",
      "      \"content_tag\": \"content\",\n",
      "      \"user_tag\": \"user\",\n",
      "      \"assistant_tag\": \"assistant\"\n",
      "    }\n",
      "  },\n",
      "  \"llava_150k_en\": {\n",
      "    \"hf_hub_url\": \"BUAADreamer/llava-en-zh-300k\",\n",
      "    \"subset\": \"en\",\n",
      "    \"formatting\": \"sharegpt\",\n",
      "    \"columns\": {\n",
      "      \"messages\": \"messages\",\n",
      "      \"images\": \"images\"\n",
      "    },\n",
      "    \"tags\": {\n",
      "      \"role_tag\": \"role\",\n",
      "      \"content_tag\": \"content\",\n",
      "      \"user_tag\": \"user\",\n",
      "      \"assistant_tag\": \"assistant\"\n",
      "    }\n",
      "  },\n",
      "  \"llava_150k_zh\": {\n",
      "    \"hf_hub_url\": \"BUAADreamer/llava-en-zh-300k\",\n",
      "    \"subset\": \"zh\",\n",
      "    \"formatting\": \"sharegpt\",\n",
      "    \"columns\": {\n",
      "      \"messages\": \"messages\",\n",
      "      \"images\": \"images\"\n",
      "    },\n",
      "    \"tags\": {\n",
      "      \"role_tag\": \"role\",\n",
      "      \"content_tag\": \"content\",\n",
      "      \"user_tag\": \"user\",\n",
      "      \"assistant_tag\": \"assistant\"\n",
      "    }\n",
      "  },\n",
      "  \"pokemon_cap\": {\n",
      "    \"hf_hub_url\": \"llamafactory/pokemon-gpt4o-captions\",\n",
      "    \"formatting\": \"sharegpt\",\n",
      "    \"columns\": {\n",
      "      \"messages\": \"conversations\",\n",
      "      \"images\": \"images\"\n",
      "    }\n",
      "  },\n",
      "  \"mllm_pt_demo\": {\n",
      "    \"hf_hub_url\": \"BUAADreamer/mllm_pt_demo\",\n",
      "    \"formatting\": \"sharegpt\",\n",
      "    \"columns\": {\n",
      "      \"messages\": \"messages\",\n",
      "      \"images\": \"images\"\n",
      "    },\n",
      "    \"tags\": {\n",
      "      \"role_tag\": \"role\",\n",
      "      \"content_tag\": \"content\",\n",
      "      \"user_tag\": \"user\",\n",
      "      \"assistant_tag\": \"assistant\"\n",
      "    }\n",
      "  },\n",
      "  \"oasst_de\": {\n",
      "    \"hf_hub_url\": \"mayflowergmbh/oasst_de\"\n",
      "  },\n",
      "  \"dolly_15k_de\": {\n",
      "    \"hf_hub_url\": \"mayflowergmbh/dolly-15k_de\"\n",
      "  },\n",
      "  \"alpaca-gpt4_de\": {\n",
      "    \"hf_hub_url\": \"mayflowergmbh/alpaca-gpt4_de\"\n",
      "  },\n",
      "  \"openschnabeltier_de\": {\n",
      "    \"hf_hub_url\": \"mayflowergmbh/openschnabeltier_de\"\n",
      "  },\n",
      "  \"evol_instruct_de\": {\n",
      "    \"hf_hub_url\": \"mayflowergmbh/evol-instruct_de\"\n",
      "  },\n",
      "  \"dolphin_de\": {\n",
      "    \"hf_hub_url\": \"mayflowergmbh/dolphin_de\"\n",
      "  },\n",
      "  \"booksum_de\": {\n",
      "    \"hf_hub_url\": \"mayflowergmbh/booksum_de\"\n",
      "  },\n",
      "  \"airoboros_de\": {\n",
      "    \"hf_hub_url\": \"mayflowergmbh/airoboros-3.0_de\"\n",
      "  },\n",
      "  \"ultrachat_de\": {\n",
      "    \"hf_hub_url\": \"mayflowergmbh/ultra-chat_de\"\n",
      "  },\n",
      "  \"dpo_en_demo\": {\n",
      "    \"file_name\": \"dpo_en_demo.json\",\n",
      "    \"ranking\": true,\n",
      "    \"formatting\": \"sharegpt\",\n",
      "    \"columns\": {\n",
      "      \"messages\": \"conversations\",\n",
      "      \"chosen\": \"chosen\",\n",
      "      \"rejected\": \"rejected\"\n",
      "    }\n",
      "  },\n",
      "  \"dpo_zh_demo\": {\n",
      "    \"file_name\": \"dpo_zh_demo.json\",\n",
      "    \"ranking\": true,\n",
      "    \"formatting\": \"sharegpt\",\n",
      "    \"columns\": {\n",
      "      \"messages\": \"conversations\",\n",
      "      \"chosen\": \"chosen\",\n",
      "      \"rejected\": \"rejected\"\n",
      "    }\n",
      "  },\n",
      "  \"dpo_mix_en\": {\n",
      "    \"hf_hub_url\": \"llamafactory/DPO-En-Zh-20k\",\n",
      "    \"subset\": \"en\",\n",
      "    \"ranking\": true,\n",
      "    \"formatting\": \"sharegpt\",\n",
      "    \"columns\": {\n",
      "      \"messages\": \"conversations\",\n",
      "      \"chosen\": \"chosen\",\n",
      "      \"rejected\": \"rejected\"\n",
      "    }\n",
      "  },\n",
      "  \"dpo_mix_zh\": {\n",
      "    \"hf_hub_url\": \"llamafactory/DPO-En-Zh-20k\",\n",
      "    \"subset\": \"zh\",\n",
      "    \"ranking\": true,\n",
      "    \"formatting\": \"sharegpt\",\n",
      "    \"columns\": {\n",
      "      \"messages\": \"conversations\",\n",
      "      \"chosen\": \"chosen\",\n",
      "      \"rejected\": \"rejected\"\n",
      "    }\n",
      "  },\n",
      "  \"ultrafeedback\": {\n",
      "    \"hf_hub_url\": \"llamafactory/ultrafeedback_binarized\",\n",
      "    \"ms_hub_url\": \"llamafactory/ultrafeedback_binarized\",\n",
      "    \"ranking\": true,\n",
      "    \"columns\": {\n",
      "      \"prompt\": \"instruction\",\n",
      "      \"chosen\": \"chosen\",\n",
      "      \"rejected\": \"rejected\"\n",
      "    }\n",
      "  },\n",
      "  \"coig_p\": {\n",
      "    \"hf_hub_url\": \"m-a-p/COIG-P\",\n",
      "    \"ranking\": true,\n",
      "    \"formatting\": \"sharegpt\",\n",
      "    \"columns\": {\n",
      "      \"messages\": \"conversations\",\n",
      "      \"chosen\": \"chosen\",\n",
      "      \"rejected\": \"rejected\"\n",
      "    }\n",
      "  },\n",
      "  \"rlhf_v\": {\n",
      "    \"hf_hub_url\": \"llamafactory/RLHF-V\",\n",
      "    \"ranking\": true,\n",
      "    \"formatting\": \"sharegpt\",\n",
      "    \"columns\": {\n",
      "      \"messages\": \"conversations\",\n",
      "      \"chosen\": \"chosen\",\n",
      "      \"rejected\": \"rejected\",\n",
      "      \"images\": \"images\"\n",
      "    }\n",
      "  },\n",
      "  \"vlfeedback\": {\n",
      "    \"hf_hub_url\": \"Zhihui/VLFeedback\",\n",
      "    \"ranking\": true,\n",
      "    \"formatting\": \"sharegpt\",\n",
      "    \"columns\": {\n",
      "      \"messages\": \"conversations\",\n",
      "      \"chosen\": \"chosen\",\n",
      "      \"rejected\": \"rejected\",\n",
      "      \"images\": \"images\"\n",
      "    }\n",
      "  },\n",
      "  \"rlaif_v\": {\n",
      "    \"hf_hub_url\": \"openbmb/RLAIF-V-Dataset\",\n",
      "    \"ranking\": true,\n",
      "    \"columns\": {\n",
      "      \"prompt\": \"question\",\n",
      "      \"chosen\": \"chosen\",\n",
      "      \"rejected\": \"rejected\",\n",
      "      \"images\": \"image\"\n",
      "    }\n",
      "  },\n",
      "  \"orca_pairs\": {\n",
      "    \"hf_hub_url\": \"Intel/orca_dpo_pairs\",\n",
      "    \"ranking\": true,\n",
      "    \"columns\": {\n",
      "      \"prompt\": \"question\",\n",
      "      \"chosen\": \"chosen\",\n",
      "      \"rejected\": \"rejected\",\n",
      "      \"system\": \"system\"\n",
      "    }\n",
      "  },\n",
      "  \"hh_rlhf_en\": {\n",
      "    \"script_url\": \"hh_rlhf_en\",\n",
      "    \"ranking\": true,\n",
      "    \"columns\": {\n",
      "      \"prompt\": \"instruction\",\n",
      "      \"chosen\": \"chosen\",\n",
      "      \"rejected\": \"rejected\",\n",
      "      \"history\": \"history\"\n",
      "    }\n",
      "  },\n",
      "  \"nectar_rm\": {\n",
      "    \"hf_hub_url\": \"AstraMindAI/RLAIF-Nectar\",\n",
      "    \"ms_hub_url\": \"AI-ModelScope/RLAIF-Nectar\",\n",
      "    \"ranking\": true\n",
      "  },\n",
      "  \"orca_dpo_de\": {\n",
      "    \"hf_hub_url\": \"mayflowergmbh/intel_orca_dpo_pairs_de\",\n",
      "    \"ranking\": true\n",
      "  },\n",
      "  \"kto_en_demo\": {\n",
      "    \"file_name\": \"kto_en_demo.json\",\n",
      "    \"formatting\": \"sharegpt\",\n",
      "    \"columns\": {\n",
      "      \"messages\": \"messages\",\n",
      "      \"kto_tag\": \"label\"\n",
      "    },\n",
      "    \"tags\": {\n",
      "      \"role_tag\": \"role\",\n",
      "      \"content_tag\": \"content\",\n",
      "      \"user_tag\": \"user\",\n",
      "      \"assistant_tag\": \"assistant\"\n",
      "    }\n",
      "  },\n",
      "  \"kto_mix_en\": {\n",
      "    \"hf_hub_url\": \"argilla/kto-mix-15k\",\n",
      "    \"formatting\": \"sharegpt\",\n",
      "    \"columns\": {\n",
      "      \"messages\": \"completion\",\n",
      "      \"kto_tag\": \"label\"\n",
      "    },\n",
      "    \"tags\": {\n",
      "      \"role_tag\": \"role\",\n",
      "      \"content_tag\": \"content\",\n",
      "      \"user_tag\": \"user\",\n",
      "      \"assistant_tag\": \"assistant\"\n",
      "    }\n",
      "  },\n",
      "  \"ultrafeedback_kto\": {\n",
      "    \"hf_hub_url\": \"argilla/ultrafeedback-binarized-preferences-cleaned-kto\",\n",
      "    \"ms_hub_url\": \"AI-ModelScope/ultrafeedback-binarized-preferences-cleaned-kto\",\n",
      "    \"columns\": {\n",
      "      \"prompt\": \"prompt\",\n",
      "      \"response\": \"completion\",\n",
      "      \"kto_tag\": \"label\"\n",
      "    }\n",
      "  },\n",
      "  \"wiki_demo\": {\n",
      "    \"file_name\": \"wiki_demo.txt\",\n",
      "    \"columns\": {\n",
      "      \"prompt\": \"text\"\n",
      "    }\n",
      "  },\n",
      "  \"c4_demo\": {\n",
      "    \"file_name\": \"c4_demo.jsonl\",\n",
      "    \"columns\": {\n",
      "      \"prompt\": \"text\"\n",
      "    }\n",
      "  },\n",
      "  \"refinedweb\": {\n",
      "    \"hf_hub_url\": \"tiiuae/falcon-refinedweb\",\n",
      "    \"columns\": {\n",
      "      \"prompt\": \"content\"\n",
      "    }\n",
      "  },\n",
      "  \"redpajama_v2\": {\n",
      "    \"hf_hub_url\": \"togethercomputer/RedPajama-Data-V2\",\n",
      "    \"columns\": {\n",
      "      \"prompt\": \"raw_content\"\n",
      "    },\n",
      "    \"subset\": \"default\"\n",
      "  },\n",
      "  \"wikipedia_en\": {\n",
      "    \"hf_hub_url\": \"olm/olm-wikipedia-20221220\",\n",
      "    \"ms_hub_url\": \"AI-ModelScope/olm-wikipedia-20221220\",\n",
      "    \"columns\": {\n",
      "      \"prompt\": \"text\"\n",
      "    }\n",
      "  },\n",
      "  \"wikipedia_zh\": {\n",
      "    \"hf_hub_url\": \"pleisto/wikipedia-cn-20230720-filtered\",\n",
      "    \"ms_hub_url\": \"AI-ModelScope/wikipedia-cn-20230720-filtered\",\n",
      "    \"columns\": {\n",
      "      \"prompt\": \"completion\"\n",
      "    }\n",
      "  },\n",
      "  \"pile\": {\n",
      "    \"hf_hub_url\": \"monology/pile-uncopyrighted\",\n",
      "    \"ms_hub_url\": \"AI-ModelScope/pile\",\n",
      "    \"columns\": {\n",
      "      \"prompt\": \"text\"\n",
      "    }\n",
      "  },\n",
      "  \"skypile\": {\n",
      "    \"hf_hub_url\": \"Skywork/SkyPile-150B\",\n",
      "    \"ms_hub_url\": \"AI-ModelScope/SkyPile-150B\",\n",
      "    \"columns\": {\n",
      "      \"prompt\": \"text\"\n",
      "    }\n",
      "  },\n",
      "  \"fineweb\": {\n",
      "    \"hf_hub_url\": \"HuggingFaceFW/fineweb\",\n",
      "    \"columns\": {\n",
      "      \"prompt\": \"text\"\n",
      "    }\n",
      "  },\n",
      "  \"fineweb_edu\": {\n",
      "    \"hf_hub_url\": \"HuggingFaceFW/fineweb-edu\",\n",
      "    \"columns\": {\n",
      "      \"prompt\": \"text\"\n",
      "    }\n",
      "  },\n",
      "  \"the_stack\": {\n",
      "    \"hf_hub_url\": \"bigcode/the-stack\",\n",
      "    \"ms_hub_url\": \"AI-ModelScope/the-stack\",\n",
      "    \"columns\": {\n",
      "      \"prompt\": \"content\"\n",
      "    }\n",
      "  },\n",
      "  \"starcoder_python\": {\n",
      "    \"hf_hub_url\": \"bigcode/starcoderdata\",\n",
      "    \"ms_hub_url\": \"AI-ModelScope/starcoderdata\",\n",
      "    \"columns\": {\n",
      "      \"prompt\": \"content\"\n",
      "    },\n",
      "    \"folder\": \"python\"\n",
      "  },\n",
      "  \"wiki_5percent\": {\n",
      "    \"file_name\": \"wiki_5percent.json\",\n",
      "    \"columns\": {\n",
      "      \"prompt\": \"text\"\n",
      "    }\n",
      "  },\n",
      "  \"markdown_docs\": {\n",
      "    \"file_name\": \"markdown_docs.jsonl\",\n",
      "    \"columns\": {\n",
      "      \"prompt\": \"text\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Define the base directory of your LLaMA-Factory installation\n",
    "llama_factory_base_dir = '/home/ai-research-lab/MCSProjectbyWajahatalibasharat5Percent/LLaMA-Factory'\n",
    "data_dir = os.path.join(llama_factory_base_dir, 'data')\n",
    "dataset_info_path = os.path.join(data_dir, 'dataset_info.json')\n",
    "\n",
    "# Define the new entry for your markdown data\n",
    "# This assumes you ran Step 1 and created markdown_docs.jsonl in the 'data' directory\n",
    "new_markdown_entry = {\n",
    "    \"file_name\": \"markdown_docs.jsonl\",\n",
    "    \"columns\": {\n",
    "        \"prompt\": \"text\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Define the updated entry for wiki_1percent\n",
    "# This ensures it has the correct 'columns' and 'formatting' for pre-training\n",
    "updated_wiki_entry = {\n",
    "    \"file_name\": \"wiki_5percent.json\",\n",
    "    \"columns\": {\n",
    "        \"prompt\": \"text\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Load existing dataset_info.json\n",
    "existing_data = {}\n",
    "if os.path.exists(dataset_info_path):\n",
    "    try:\n",
    "        with open(dataset_info_path, 'r', encoding='utf-8') as f:\n",
    "            existing_data = json.load(f)\n",
    "        print(f\"Loaded existing {dataset_info_path} successfully.\")\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Warning: Could not decode existing {dataset_info_path} ({e}). \"\n",
    "              \"Starting with an empty configuration, any previous entries might be lost if not valid JSON.\")\n",
    "        existing_data = {}\n",
    "else:\n",
    "    print(f\"No existing {dataset_info_path} found. Creating a new one.\")\n",
    "    # Ensure the 'data' directory exists if it's not there for some reason\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "# Add or update the entries\n",
    "existing_data[\"wiki_5percent\"] = updated_wiki_entry\n",
    "existing_data[\"markdown_docs\"] = new_markdown_entry\n",
    "\n",
    "# Save the combined content back to the file\n",
    "with open(dataset_info_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(existing_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\nSuccessfully updated {dataset_info_path} with 'wiki_5percent' and 'markdown_docs' entries.\")\n",
    "print(\"\\n--- Current content of dataset_info.json ---\")\n",
    "with open(dataset_info_path, 'r', encoding='utf-8') as f:\n",
    "    print(f.read())\n",
    "print(\"---------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a27bc086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changed\n",
    "import json\n",
    "args = dict(\n",
    "    # model settings\n",
    "    model_name_or_path=\"meta-llama/LLaMA-3.2-3B-Instruct\",\n",
    "    trust_remote_code=True,\n",
    "\n",
    "    # training stage\n",
    "    stage=\"pt\",\n",
    "    do_train=True,\n",
    "    finetuning_type=\"freeze\",\n",
    "    freeze_trainable_layers=4,\n",
    "    freeze_trainable_modules=\"all\",\n",
    "\n",
    "    # dataset settings\n",
    "    dataset=\"wiki_5percent,markdown_docs\",\n",
    "    # dataset=\"wiki_2percent\",\n",
    "    # max_samples=1000,\n",
    "    cutoff_len=2048,\n",
    "    overwrite_cache=True,\n",
    "    preprocessing_num_workers=16,\n",
    "    dataloader_num_workers=4,\n",
    "\n",
    "    # output and checkpointing\n",
    "    output_dir=\"llama3-3b_freeze_5per\",\n",
    "    # output_dir=\"llama3-3b_freeze_1per_8layers\",\n",
    "    logging_steps=10,\n",
    "    overwrite_output_dir=True,\n",
    "    plot_loss=True,\n",
    "    report_to=\"none\",\n",
    "\n",
    "    # optimizer and schedule\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=16,\n",
    "    learning_rate=0.0001,\n",
    "    num_train_epochs=1.0,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_ratio=0.1,\n",
    "\n",
    "    # precision and device\n",
    "    bf16=True,\n",
    "\n",
    "    # distributed training timeout\n",
    "    ddp_timeout=18000,\n",
    "    # deepspeed=\"ds_config.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f0c8f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(args, open(\"CPT_LayerFreezing_5per.json\", \"w\", encoding=\"utf-8\"), indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87f6e39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|2025-06-23 09:49:50] llamafactory.cli:143 >> Initializing 2 distributed tasks at: 127.0.0.1:48961\n",
      "W0623 09:49:51.406000 8998 site-packages/torch/distributed/run.py:766] \n",
      "W0623 09:49:51.406000 8998 site-packages/torch/distributed/run.py:766] *****************************************\n",
      "W0623 09:49:51.406000 8998 site-packages/torch/distributed/run.py:766] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0623 09:49:51.406000 8998 site-packages/torch/distributed/run.py:766] *****************************************\n",
      "[INFO|2025-06-23 09:49:53] llamafactory.hparams.parser:406 >> Process rank: 0, world size: 2, device: cuda:0, distributed training: True, compute dtype: torch.bfloat16\n",
      "[INFO|2025-06-23 09:49:53] llamafactory.hparams.parser:406 >> Process rank: 1, world size: 2, device: cuda:1, distributed training: True, compute dtype: torch.bfloat16\n",
      "[INFO|tokenization_utils_base.py:2023] 2025-06-23 09:49:55,789 >> loading file tokenizer.json from cache at /home/ai-research-lab/.cache/huggingface/hub/models--meta-llama--LLaMA-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2023] 2025-06-23 09:49:55,789 >> loading file tokenizer.model from cache at None\n",
      "[INFO|tokenization_utils_base.py:2023] 2025-06-23 09:49:55,789 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2023] 2025-06-23 09:49:55,789 >> loading file special_tokens_map.json from cache at /home/ai-research-lab/.cache/huggingface/hub/models--meta-llama--LLaMA-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2023] 2025-06-23 09:49:55,789 >> loading file tokenizer_config.json from cache at /home/ai-research-lab/.cache/huggingface/hub/models--meta-llama--LLaMA-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2023] 2025-06-23 09:49:55,789 >> loading file chat_template.jinja from cache at None\n",
      "[INFO|tokenization_utils_base.py:2299] 2025-06-23 09:49:55,984 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "[INFO|configuration_utils.py:698] 2025-06-23 09:49:59,463 >> loading configuration file config.json from cache at /home/ai-research-lab/.cache/huggingface/hub/models--meta-llama--LLaMA-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95/config.json\n",
      "[INFO|configuration_utils.py:770] 2025-06-23 09:49:59,464 >> Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128008,\n",
      "    128009\n",
      "  ],\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 131072,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 24,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": {\n",
      "    \"factor\": 32.0,\n",
      "    \"high_freq_factor\": 4.0,\n",
      "    \"low_freq_factor\": 1.0,\n",
      "    \"original_max_position_embeddings\": 8192,\n",
      "    \"rope_type\": \"llama3\"\n",
      "  },\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "/home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "  warnings.warn(  # warn only once\n",
      "[rank1]:[W623 09:49:59.989125115 ProcessGroupNCCL.cpp:4718] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.\n",
      "[INFO|tokenization_utils_base.py:2023] 2025-06-23 09:50:00,473 >> loading file tokenizer.json from cache at /home/ai-research-lab/.cache/huggingface/hub/models--meta-llama--LLaMA-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2023] 2025-06-23 09:50:00,473 >> loading file tokenizer.model from cache at None\n",
      "[INFO|tokenization_utils_base.py:2023] 2025-06-23 09:50:00,473 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2023] 2025-06-23 09:50:00,473 >> loading file special_tokens_map.json from cache at /home/ai-research-lab/.cache/huggingface/hub/models--meta-llama--LLaMA-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2023] 2025-06-23 09:50:00,473 >> loading file tokenizer_config.json from cache at /home/ai-research-lab/.cache/huggingface/hub/models--meta-llama--LLaMA-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2023] 2025-06-23 09:50:00,473 >> loading file chat_template.jinja from cache at None\n",
      "[INFO|tokenization_utils_base.py:2299] 2025-06-23 09:50:00,670 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "[WARNING|2025-06-23 09:50:00] llamafactory.data.template:148 >> `template` was not specified, try parsing the chat template from the tokenizer.\n",
      "[INFO|2025-06-23 09:50:00] llamafactory.data.template:143 >> Add pad token: <|eot_id|>\n",
      "[INFO|2025-06-23 09:50:00] llamafactory.data.loader:143 >> Loading dataset wiki_5percent.json...\n",
      "Converting format of dataset (num_proc=16): 100%|█| 320390/320390 [00:01<00:00, \n",
      "[INFO|2025-06-23 09:50:03] llamafactory.data.loader:143 >> Loading dataset markdown_docs.jsonl...\n",
      "Converting format of dataset (num_proc=16): 100%|█| 37/37 [00:00<00:00, 363.94 e\n",
      "/home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "  warnings.warn(  # warn only once\n",
      "[rank0]:[W623 09:50:03.084432659 ProcessGroupNCCL.cpp:4718] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.\n",
      "Running tokenizer on dataset (num_proc=16): 100%|█| 320427/320427 [00:39<00:00, \n",
      "training example:\n",
      "input_ids:\n",
      "[2127, 1132, 2191, 374, 264, 5054, 19675, 323, 7351, 430, 374, 44929, 315, 682, 1120, 7174, 369, 11447, 323, 26737, 311, 90376, 279, 14673, 433, 8349, 10519, 26225, 78242, 323, 30022, 11, 11383, 2737, 7140, 90160, 11, 323, 32682, 13, 1556, 1132, 2191, 28424, 369, 279, 14039, 315, 279, 1614, 449, 1614, 1752, 34775, 323, 37079, 1949, 30257, 13, 1666, 264, 35901, 2163, 29480, 7351, 11, 420, 5403, 315, 44565, 2191, 374, 9277, 389, 279, 3117, 61943, 2163, 315, 279, 5054, 20326, 11, 6118, 7633, 439, 279, 57125, 20611, 315, 279, 41289, 7351, 320, 2808, 531, 8997, 51618, 3677, 95668, 617, 12439, 304, 34775, 2085, 16287, 12694, 1132, 552, 1317, 1603, 279, 21967, 315, 5415, 11, 77563, 11, 477, 991, 19505, 13, 3161, 279, 10205, 315, 39433, 70994, 13162, 11, 67451, 42914, 9017, 11447, 1101, 16392, 13, 10541, 35483, 315, 78431, 6848, 527, 1766, 682, 6957, 3925, 11, 6617, 44565, 2191, 22763, 505, 279, 92931, 13, 12220, 279, 15629, 4376, 315, 279, 220, 777, 339, 323, 279, 1176, 11026, 315, 279, 220, 508, 339, 9478, 11, 279, 78431, 7351, 20415, 3384, 304, 1455, 5596, 315, 279, 1917, 323, 1047, 264, 5199, 3560, 304, 7487, 6, 28970, 369, 91225, 49686, 13, 40741, 78431, 8853, 315, 3463, 14454, 2391, 420, 4261, 13, 1556, 1132, 1705, 617, 4529, 961, 304, 3892, 93574, 11, 1455, 35146, 304, 279, 12366, 6947, 2957, 11, 279, 8690, 16803, 5111, 323, 279, 15506, 16803, 5111, 11, 6832, 842, 13160, 279, 842, 315, 279, 29924, 11639, 315, 44565, 2191, 13, 763, 279, 1566, 11026, 315, 279, 220, 508, 339, 323, 1139, 279, 220, 1691, 267, 9478, 11, 279, 78431, 7351, 706, 1027, 594, 86153, 3131, 810, 11, 7982, 304, 23354, 323, 10383, 2949, 7294, 98231, 380, 11, 7294, 48260, 323, 7294, 74419, 8082, 19567, 382, 2127, 1132, 1705, 3539, 17226, 20414, 11, 902, 1253, 387, 8965, 18255, 1139, 30191, 323, 41993, 15174, 26, 1070, 374, 5199, 28347, 1990, 279, 1403, 13, 38321, 661, 5528, 1456, 311, 38553, 1148, 459, 78431, 8396, 2643, 387, 1093, 11, 719, 30191, 26411, 11, 902, 617, 35901, 4529, 264, 16806, 2543, 11, 9395, 311, 63331, 11447, 323, 279, 1614, 13, 9176, 62814, 315, 3823, 36017, 617, 1027, 28160, 555, 78431, 10334, 11, 43665, 11, 323, 550, 7332, 382, 32960, 99174, 11, 57726, 11, 323, 7419, 4815, 791, 1880, 1631, 5848, 6371, 315, 44565, 2191, 374, 505, 279, 38050, 18341, 459, 847, 71, 689, 11, 7438, 330, 30096, 264, 49080, 498, 24306, 315, 279, 9436, 459, 12, 3573, 30096, 909, 323, 279, 3492, 802, 31764, 437, 3573, 38491, 1, 477, 330, 81, 8646, 1865, 578, 21166, 482, 2191, 72214, 279, 42933, 1510, 430, 9428, 2530, 459, 15630, 13, 1556, 1132, 2191, 8111, 304, 6498, 505, 220, 10513, 17, 439, 44565, 44618, 323, 459, 15630, 505, 220, 9800, 24, 26, 4216, 6498, 603, 1154, 20654, 4147, 264, 5647, 315, 19823, 13, 40741, 48752, 2949, 279, 8753, 22910, 61336, 872, 19949, 439, 93134, 11, 8051, 2478, 1778, 13487, 6222, 1690, 6325, 449, 3010, 93134, 13, 9176, 14110, 5548, 315, 279, 220, 777, 339, 9478, 1778, 439, 12656, 4359, 7678, 320, 10005, 21, 4235, 10750, 21, 8, 323, 93537, 1226, 275, 2785, 320, 5245, 23, 4235, 9674, 16, 8, 1053, 17210, 311, 279, 78431, 83258, 315, 279, 1828, 9659, 719, 1550, 539, 1005, 78431, 477, 44565, 2191, 304, 23524, 5694, 477, 872, 21463, 382, 791, 1176, 5054, 55475, 311, 1650, 5678, 459, 78431, 1754, 574, 38077, 12278, 974, 764, 393, 583, 31721, 263, 320, 5245, 24, 4235, 9714, 20, 705, 36024, 279, 16287, 7342, 315, 44565, 2191, 304, 279, 5209, 12, 777, 339, 9478, 13, 8876, 279, 220, 9378, 15, 82, 323, 7314, 304, 9822, 11, 57125, 2191, 706, 3629, 1027, 1511, 439, 264, 74450, 369, 44565, 2191, 323, 1202, 1005, 439, 264, 74450, 374, 2103, 4279, 4994, 279, 3723, 4273, 13, 4427, 603, 1154, 315, 57125, 2191, 8464, 311, 3927, 4633, 1949, 48831, 19675, 1193, 11, 323, 1949, 48831, 44565, 2191, 304, 4040, 374, 61937, 57125, 44565, 2191, 382, 8142, 279, 4751, 57125, 706, 1027, 14090, 69593, 449, 44565, 2191, 11, 1202, 7438, 706, 810, 6051, 1027, 80703, 555, 22622, 25375, 505, 2679, 30450, 85129, 5315, 11, 2737, 2225, 279, 1561, 14043, 323, 57125, 28187, 1705, 11, 889, 656, 539, 22712, 5694, 449, 59021, 3674, 1705, 477, 264, 348, 53290, 4717, 11, 323, 14560, 13042, 45750, 11, 889, 527, 15871, 11920, 449, 8431, 58455, 13, 23212, 11, 1063, 93134, 1005, 57125, 41289, 311, 5766, 44565, 2191, 596, 8389, 390, 14632, 323, 20654, 1082, 1202, 13537, 449, 51618, 13, 1556, 1132, 2191, 374, 44029, 1511, 311, 7664, 279, 7294, 43802, 20631, 20611, 315, 279, 41289, 7351, 13, 1556, 1132, 2191, 374, 13168, 291, 311, 41289, 7739, 902, 527, 1614, 36185, 477, 505, 3485, 13, 99394, 315, 44565, 2191, 8965, 11415, 44565, 2191, 596, 41289, 16792, 323, 9940, 1082, 13865, 520, 6968, 29953, 354, 316, 552, 1990, 279, 1403, 13, 4427, 31839, 7664, 44565, 2191, 439, 3515, 1690, 34453, 505, 84581, 11, 323, 1694, 2225, 18250, 323, 41289, 719, 810, 779, 13, 9176, 31839, 8007, 459, 277, 971, 98231, 2191, 439, 264, 70847, 315, 78431, 16565, 382, 8142, 14076, 311, 279, 1614, 374, 8792, 311, 78431, 3463, 11, 27409, 44565, 2191, 374, 539, 459, 4228, 3465, 369, 31839, 11, 439, 1070, 374, 264, 2763, 315, 10430, 4315, 31839, 323, 93134, 389, 279, 5030, 11, 323, 5370, 60701, 45493, 44565, 2191, 10284, 22009, 13, 17559, 36222, 3079, 5540, 2997, 279, 690, 369, 264, 2536, 23283, 3035, 535, 8396, 11, 279, 38001, 315, 279, 1614, 41705, 11, 279, 16801, 430, 3823, 7138, 6276, 12966, 311, 3073, 304, 477, 5208, 9017, 1778, 264, 2536, 23283, 3035, 535, 8396, 11, 323, 264, 24710, 389, 1268, 311, 1180, 311, 23564, 279, 10728, 315, 459, 15630, 382, 13730, 271, 4808, 17515, 944, 11639, 4815, 10438, 279, 9886, 315, 25861, 323, 9919, 11, 9749, 11447, 1550, 539, 3073, 13, 1102, 574, 1306, 279, 15244, 315, 11447, 430, 44565, 4633, 6848, 1051, 16948, 37588, 439, 264, 13010, 13, 578, 1455, 28289, 5956, 34291, 311, 44565, 2191, 304, 279, 14154, 1917, 1051, 304, 5734, 323, 25431, 13, 763, 5734, 11, 41903, 44565, 2191, 320, 1820, 10430, 389, 279, 57008, 315, 279, 1614, 8, 574, 91784, 660, 555, 60608, 380, 61787, 68844, 526, 67927, 323, 445, 3524, 8510, 13, 32944, 3002, 71883, 42914, 11, 60608, 2191, 706, 1027, 1071, 311, 617, 1047, 330, 91645, 16961, 811, 1, 315, 44565, 2191, 382, 2127, 1132, 292, 33726, 1051, 1101, 83280, 555, 28375, 5493, 323, 61787, 304, 25431, 13, 362, 60478, 4010, 355, 323, 34940, 511, 645, 1511, 279, 21849, 315, 6898, 343, 606, 311, 41468, 279, 12324, 1990, 7016, 27070, 555, 279, 1614, 323, 4443, 51360, 13, 328, 78046, 29440, 59652, 1122, 11527, 15320, 323, 29676, 389, 279, 1314, 315, 3927, 11542, 315, 42563, 13, 356, 1910, 1233, 27292, 3823, 2383, 320, 17101, 437, 8, 323, 5938, 11527, 1418, 4560, 311, 3974, 4184, 311, 7138, 320, 764, 4548, 570, 71883, 1233, 1051, 33445, 315, 264, 8396, 3196, 389, 57751, 323, 11919, 4398, 4315, 1202, 10495, 2085, 279, 9546, 315, 264, 1614, 382, 644, 42108, 4606, 11, 1070, 574, 912, 44565, 4633, 5820, 3734, 1063, 14943, 5411, 10597, 19567, 13, 4314, 11, 323, 1023, 10451, 19567, 11, 3010, 6688, 7342, 311, 10597, 44565, 2191, 13, 763, 279, 328, 46488, 1122, 21080, 11, 40091, 67, 587, 2663, 369, 459, 77271, 20631, 8396, 323, 279, 76445, 315, 87149, 11, 1193, 311, 387, 5246, 16070, 555, 35414, 735, 38155, 358, 382, 644, 15004, 969, 11, 10597, 31237, 82, 89194, 2403, 279, 1614, 13, 763, 4606, 11, 5370, 31237, 82, 8040, 7294, 21395, 323, 57125, 61555, 13, 50086, 291, 2802, 304, 61386, 488, 2391, 279, 55383, 323, 304, 879, 19971, 2391, 279, 1050, 1659, 28101, 5540, 315, 7294, 43802, 20631, 37019, 2191, 11, 8104, 304, 9822, 13, 92931, 11774, 311, 20207, 11447, 320, 5132, 1299, 323, 10597, 8, 323, 279, 93574, 315, 279, 220, 11128, 15, 82, 323, 220, 10336, 23, 682, 85747, 279, 42933, 4500, 315, 1148, 6244, 279, 11639, 315, 29924, 44565, 2191, 382, 49552, 11639, 720, 16397, 279, 8753, 22910, 11, 49638, 5315, 1778, 439, 279, 2998, 4193, 5512, 323, 279, 220, 5602, 264, 13353, 1486, 304, 279, 74454, 315, 7294, 21395, 323, 6918, 380, 58214, 13, 578, 1176, 78431, 60701, 8040, 6957, 279, 220, 972, 339, 9478, 439, 12656, 4359, 7678, 16948, 37588, 41903, 44565, 2191, 304, 9635, 11, 57323, 20445, 275, 318, 3876, 279, 1614, 11, 7639, 65292, 1215, 596, 7422, 63675, 279, 1648, 311, 3927, 2191, 323, 38077, 12278, 974, 764, 393, 583, 31721, 263, 596, 10334, 315, 27848, 2191, 1766, 70225, 17614, 304, 9822, 13, 3296, 279, 3389, 220, 9674, 15, 82, 11, 5370, 78431, 8853, 315, 3463, 1047, 3719, 1664, 39817, 323, 264, 12330, 315, 1243, 31069, 3728, 8082, 10222, 505, 220, 9367, 15, 311, 220, 7529, 19, 13, 1115, 11639, 315, 29924, 44565, 2191, 36513, 3156, 279, 842, 315, 279, 15506, 16803, 5111, 323, 374, 6646, 279, 21411, 4325, 315, 44565, 2191, 382, 38537, 505, 27848, 2191, 11, 92551, 36769, 359, 258, 18538, 6667, 80244, 44565, 2191, 323, 10862, 279, 7327, 22938, 5794, 596, 10229, 11, 264, 538, 12128, 11552, 3010, 3967, 439, 279, 5629, 7327, 430, 14454, 304, 220, 9714, 19, 311, 52696, 17226, 30191, 60701, 13, 578, 7327, 6244, 264, 5199, 5054, 5457, 11, 449, 35131, 28187, 1694, 264, 6522, 7216, 323, 264, 4562, 315, 1202, 3331, 9251, 13, 36769, 359, 258, 596, 37480, 320, 1820, 622, 5808, 28331, 8, 323, 393, 583, 31721, 263, 596, 20723, 320, 1820, 27848, 1705, 8, 16475, 1614, 51618, 11, 59416, 5054, 63944, 3012, 2191, 323, 2678, 3424, 58348, 13, 4740, 26242, 42254, 11, 279, 36769, 359, 258, 1705, 1051, 67331, 505, 279, 7327, 555, 279, 28187, 1705, 520, 279, 220, 9674, 17, 86026, 8151, 13, 1556, 1132, 1705, 1051, 12020, 30293, 304, 279, 10657, 7327, 11, 1694, 13967, 67331, 304, 220, 9378, 21, 13, 36769, 359, 258, 51287, 19698, 430, 422, 14110, 5548, 18661, 2410, 555, 28187, 596, 3878, 11, 814, 1053, 842, 709, 279, 502, 43049, 1821, 315, 7487, 13, 763, 2077, 311, 872, 95989, 505, 279, 5629, 7327, 11, 93134, 14454, 279, 800, 13, 2417, 1291, 7327, 13, 9636, 279, 10383, 315, 11291, 735, 897, 354, 8148, 11, 264, 8690, 55475, 323, 28568, 11, 459, 277, 971, 88389, 359, 2191, 29204, 5795, 449, 6667, 74050, 13, 1556, 277, 971, 88389, 359, 1705, 11, 889, 24465, 20343, 505, 279, 220, 9674, 16, 12366, 6947, 2957, 11, 64854, 369, 1949, 80375, 323, 369, 279, 8141, 315, 11822, 4184, 311, 832, 596, 3966, 382, 1383, 279, 2543, 315, 279, 220, 508, 339, 9478, 11, 44565, 2191, 1047, 9041, 682, 927, 279, 1917, 13, 1102, 574, 264, 28289, 4668, 315, 279, 6625, 22013, 950, 380, 7351, 13, 763, 5734, 11, 2678, 5315, 315, 4236, 25973, 279, 3823, 4633, 463, 31419, 1873, 2373, 315, 459, 277, 971, 88389, 359, 2191, 13, 27286, 574, 264, 80310, 369, 42301, 1245, 12822, 505, 6460, 14875, 5961, 11, 889, 7882, 311, 279, 11002, 6864, 311, 4007, 13, 763, 20023, 5270, 11, 32164, 574, 264, 86568, 369, 459, 277, 971, 1355, 88, 303, 950, 2191, 11, 1405, 433, 6244, 279, 1455, 21102, 2163, 29480, 34649, 13, 12220, 420, 892, 11, 264, 23413, 315, 93134, 18306, 26411, 315, 30191, 5054, 9349, 11, 3967, 439, 30617, 315, 279, 56408, 13, 578, 834, 9792, 479, 315, 279, 8753, 41289, 7351, 1139, 1690, 5315, 323, 279, 11572, 323, 61087, 315, 1690, 57298, 2402, 311, 47426, 49028, 2768, 279, 46735, 315, 279, 12366, 6947, 2957, 92867, 3927, 380, 5054, 7645, 323, 14385, 13, 7570, 3582, 1690, 93134, 1612, 4979, 5694, 505, 1521, 20320, 14385, 11, 4225, 27322, 3782, 5304, 279, 7351, 323, 13865, 1051, 1903, 311, 5471, 93134, 15644, 1113, 311, 279, 2326, 11, 2737, 279, 40782, 3298, 315, 220, 7028, 18, 11, 1101, 2663, 279, 1556, 1132, 380, 1398, 9134, 3298, 13, 15388, 2191, 574, 2500, 8446, 902, 1063, 93134, 18306, 2391, 420, 4261, 382, 20397, 10742, 11, 93134, 99325, 31408, 304, 279, 8690, 22910, 304, 14076, 311, 279, 5929, 7351, 11, 5423, 304, 279, 386, 22506, 39142, 939, 81236, 26, 4869, 11, 814, 2322, 25984, 46735, 1306, 279, 92501, 3109, 1047, 27276, 4147, 11, 2737, 2391, 279, 97660, 45378, 53848, 13, 26778, 93134, 505, 62579, 6902, 323, 23223, 30010, 311, 19278, 11, 1603, 279, 92501, 82, 33745, 279, 78431, 7351, 1070, 2288, 13, 3161, 279, 93134, 1694]\n",
      "inputs:\n",
      "Anarchism is a political philosophy and movement that is skeptical of all justifications for authority and seeks to abolish the institutions it claims maintain unnecessary coercion and hierarchy, typically including nation-states, and capitalism. Anarchism advocates for the replacement of the state with stateless societies and voluntary free associations. As a historically left-wing movement, this reading of anarchism is placed on the farthest left of the political spectrum, usually described as the libertarian wing of the socialist movement (libertarian socialism).\n",
      "\n",
      "Humans have lived in societies without formal hierarchies long before the establishment of states, realms, or empires. With the rise of organised hierarchical bodies, scepticism toward authority also rose. Although traces of anarchist ideas are found all throughout history, modern anarchism emerged from the Enlightenment. During the latter half of the 19th and the first decades of the 20th century, the anarchist movement flourished in most parts of the world and had a significant role in workers' struggles for emancipation. Various anarchist schools of thought formed during this period. Anarchists have taken part in several revolutions, most notably in the Paris Commune, the Russian Civil War and the Spanish Civil War, whose end marked the end of the classical era of anarchism. In the last decades of the 20th and into the 21st century, the anarchist movement has been resurgent once more, growing in popularity and influence within anti-capitalist, anti-war and anti-globalisation movements.\n",
      "\n",
      "Anarchists employ diverse approaches, which may be generally divided into revolutionary and evolutionary strategies; there is significant overlap between the two. Evolutionary methods try to simulate what an anarchist society might be like, but revolutionary tactics, which have historically taken a violent turn, aim to overthrow authority and the state. Many facets of human civilization have been influenced by anarchist theory, critique, and praxis.\n",
      "\n",
      "Etymology, terminology, and definition \n",
      "\n",
      "The etymological origin of anarchism is from the Ancient Greek anarkhia, meaning \"without a ruler\", composed of the prefix an- (\"without\") and the word arkhos (\"leader\" or \"ruler\"). The suffix -ism denotes the ideological current that favours anarchy. Anarchism appears in English from 1642 as anarchisme and anarchy from 1539; early English usages emphasised a sense of disorder. Various factions within the French Revolution labelled their opponents as anarchists, although few such accused shared many views with later anarchists. Many revolutionaries of the 19th century such as William Godwin (1756–1836) and Wilhelm Weitling (1808–1871) would contribute to the anarchist doctrines of the next generation but did not use anarchist or anarchism in describing themselves or their beliefs.\n",
      "\n",
      "The first political philosopher to call himself an anarchist () was Pierre-Joseph Proudhon (1809–1865), marking the formal birth of anarchism in the mid-19th century. Since the 1890s and beginning in France, libertarianism has often been used as a synonym for anarchism and its use as a synonym is still common outside the United States. Some usages of libertarianism refer to individualistic free-market philosophy only, and free-market anarchism in particular is termed libertarian anarchism.\n",
      "\n",
      "While the term libertarian has been largely synonymous with anarchism, its meaning has more recently been diluted by wider adoption from ideologically disparate groups, including both the New Left and libertarian Marxists, who do not associate themselves with authoritarian socialists or a vanguard party, and extreme cultural liberals, who are primarily concerned with civil liberties. Additionally, some anarchists use libertarian socialist to avoid anarchism's negative connotations and emphasise its connections with socialism. Anarchism is broadly used to describe the anti-authoritarian wing of the socialist movement. Anarchism is contrasted to socialist forms which are state-oriented or from above. Scholars of anarchism generally highlight anarchism's socialist credentials and criticise attempts at creating dichotomies between the two. Some scholars describe anarchism as having many influences from liberalism, and being both liberal and socialist but more so. Many scholars reject anarcho-capitalism as a misunderstanding of anarchist principles.\n",
      "\n",
      "While opposition to the state is central to anarchist thought, defining anarchism is not an easy task for scholars, as there is a lot of discussion among scholars and anarchists on the matter, and various currents perceive anarchism slightly differently. Major definitional elements include the will for a non-coercive society, the rejection of the state apparatus, the belief that human nature allows humans to exist in or progress toward such a non-coercive society, and a suggestion on how to act to pursue the ideal of anarchy.\n",
      "\n",
      "History\n",
      "\n",
      "Pre-modern era \n",
      "\n",
      "Before the creation of towns and cities, established authority did not exist. It was after the institution of authority that anarchistic ideas were espoused as a reaction. The most notable precursors to anarchism in the ancient world were in China and Greece. In China, philosophical anarchism (the discussion on the legitimacy of the state) was delineated by Taoist philosophers Zhuang Zhou and Laozi. Alongside Stoicism, Taoism has been said to have had \"significant anticipations\" of anarchism.\n",
      "\n",
      "Anarchic attitudes were also articulated by tragedians and philosophers in Greece. Aeschylus and Sophocles used the myth of Antigone to illustrate the conflict between laws imposed by the state and personal autonomy. Socrates questioned Athenian authorities constantly and insisted on the right of individual freedom of conscience. Cynics dismissed human law (nomos) and associated authorities while trying to live according to nature (physis). Stoics were supportive of a society based on unofficial and friendly relations among its citizens without the presence of a state.\n",
      "\n",
      "In medieval Europe, there was no anarchistic activity except some ascetic religious movements. These, and other Muslim movements, later gave birth to religious anarchism. In the Sasanian Empire, Mazdak called for an egalitarian society and the abolition of monarchy, only to be soon executed by Emperor Kavad I.\n",
      "\n",
      "In Basra, religious sects preached against the state. In Europe, various sects developed anti-state and libertarian tendencies. Renewed interest in antiquity during the Renaissance and in private judgment during the Reformation restored elements of anti-authoritarian secularism, particularly in France. Enlightenment challenges to intellectual authority (secular and religious) and the revolutions of the 1790s and 1848 all spurred the ideological development of what became the era of classical anarchism.\n",
      "\n",
      "Modern era \n",
      "During the French Revolution, partisan groups such as the Enragés and the  saw a turning point in the fermentation of anti-state and federalist sentiments. The first anarchist currents developed throughout the 18th century as William Godwin espoused philosophical anarchism in England, morally delegitimising the state, Max Stirner's thinking paved the way to individualism and Pierre-Joseph Proudhon's theory of mutualism found fertile soil in France. By the late 1870s, various anarchist schools of thought had become well-defined and a wave of then unprecedented globalisation occurred from 1880 to 1914. This era of classical anarchism lasted until the end of the Spanish Civil War and is considered the golden age of anarchism.\n",
      "\n",
      "Drawing from mutualism, Mikhail Bakunin founded collectivist anarchism and entered the International Workingmen's Association, a class worker union later known as the First International that formed in 1864 to unite diverse revolutionary currents. The International became a significant political force, with Karl Marx being a leading figure and a member of its General Council. Bakunin's faction (the Jura Federation) and Proudhon's followers (the mutualists) opposed state socialism, advocating political abstentionism and small property holdings. After bitter disputes, the Bakuninists were expelled from the International by the Marxists at the 1872 Hague Congress. Anarchists were treated similarly in the Second International, being ultimately expelled in 1896. Bakunin famously predicted that if revolutionaries gained power by Marx's terms, they would end up the new tyrants of workers. In response to their expulsion from the First International, anarchists formed the St. Imier International. Under the influence of Peter Kropotkin, a Russian philosopher and scientist, anarcho-communism overlapped with collectivism. Anarcho-communists, who drew inspiration from the 1871 Paris Commune, advocated for free federation and for the distribution of goods according to one's needs.\n",
      "\n",
      "By the turn of the 20th century, anarchism had spread all over the world. It was a notable feature of the international syndicalist movement. In China, small groups of students imported the humanistic pro-science version of anarcho-communism. Tokyo was a hotspot for rebellious youth from East Asian countries, who moved to the Japanese capital to study. In Latin America, Argentina was a stronghold for anarcho-syndicalism, where it became the most prominent left-wing ideology. During this time, a minority of anarchists adopted tactics of revolutionary political violence, known as propaganda of the deed. The dismemberment of the French socialist movement into many groups and the execution and exile of many Communards to penal colonies following the suppression of the Paris Commune favoured individualist political expression and acts. Even though many anarchists distanced themselves from these terrorist acts, infamy came upon the movement and attempts were made to prevent anarchists immigrating to the US, including the Immigration Act of 1903, also called the Anarchist Exclusion Act. Illegalism was another strategy which some anarchists adopted during this period.\n",
      "\n",
      "Despite concerns, anarchists enthusiastically participated in the Russian Revolution in opposition to the White movement, especially in the Makhnovshchina; however, they met harsh suppression after the Bolshevik government had stabilised, including during the Kronstadt rebellion. Several anarchists from Petrograd and Moscow fled to Ukraine, before the Bolsheviks crushed the anarchist movement there too. With the anarchists being\n",
      "[INFO|configuration_utils.py:698] 2025-06-23 09:50:44,080 >> loading configuration file config.json from cache at /home/ai-research-lab/.cache/huggingface/hub/models--meta-llama--LLaMA-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95/config.json\n",
      "[INFO|configuration_utils.py:770] 2025-06-23 09:50:44,081 >> Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128008,\n",
      "    128009\n",
      "  ],\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 131072,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 24,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": {\n",
      "    \"factor\": 32.0,\n",
      "    \"high_freq_factor\": 4.0,\n",
      "    \"low_freq_factor\": 1.0,\n",
      "    \"original_max_position_embeddings\": 8192,\n",
      "    \"rope_type\": \"llama3\"\n",
      "  },\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "[INFO|2025-06-23 09:50:44] llamafactory.model.model_utils.kv_cache:143 >> KV cache is disabled during training.\n",
      "[INFO|modeling_utils.py:1151] 2025-06-23 09:50:44,175 >> loading weights file model.safetensors from cache at /home/ai-research-lab/.cache/huggingface/hub/models--meta-llama--LLaMA-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95/model.safetensors.index.json\n",
      "[INFO|modeling_utils.py:2241] 2025-06-23 09:50:44,175 >> Instantiating LlamaForCausalLM model under default dtype torch.bfloat16.\n",
      "[INFO|configuration_utils.py:1135] 2025-06-23 09:50:44,176 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128008,\n",
      "    128009\n",
      "  ],\n",
      "  \"use_cache\": false\n",
      "}\n",
      "\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:00<00:00,  3.33it/s]\n",
      "[INFO|modeling_utils.py:5131] 2025-06-23 09:50:44,955 >> All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
      "\n",
      "[INFO|modeling_utils.py:5139] 2025-06-23 09:50:44,955 >> All the weights of LlamaForCausalLM were initialized from the model checkpoint at meta-llama/LLaMA-3.2-3B-Instruct.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
      "[INFO|configuration_utils.py:1090] 2025-06-23 09:50:45,503 >> loading configuration file generation_config.json from cache at /home/ai-research-lab/.cache/huggingface/hub/models--meta-llama--LLaMA-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95/generation_config.json\n",
      "[INFO|configuration_utils.py:1135] 2025-06-23 09:50:45,503 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"do_sample\": true,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128008,\n",
      "    128009\n",
      "  ],\n",
      "  \"temperature\": 0.6,\n",
      "  \"top_p\": 0.9\n",
      "}\n",
      "\n",
      "[INFO|2025-06-23 09:50:46] llamafactory.model.model_utils.checkpointing:143 >> Gradient checkpointing enabled.\n",
      "[INFO|2025-06-23 09:50:46] llamafactory.model.model_utils.attention:143 >> Using torch SDPA for faster training and inference.\n",
      "[INFO|2025-06-23 09:50:46] llamafactory.model.adapter:143 >> Upcasting trainable params to float32.\n",
      "[INFO|2025-06-23 09:50:46] llamafactory.model.adapter:143 >> Fine-tuning method: Freeze\n",
      "[INFO|2025-06-23 09:50:46] llamafactory.model.adapter:143 >> Set trainable layers: .24.,.25.,.26.,.27.\n",
      "[INFO|2025-06-23 09:50:46] llamafactory.model.loader:143 >> trainable params: 402,677,760 || all params: 3,212,749,824 || trainable%: 12.5337\n",
      "[INFO|trainer.py:756] 2025-06-23 09:50:46,023 >> Using auto half precision backend\n",
      "[WARNING|2025-06-23 09:50:46] llamafactory.train.callbacks:154 >> Previous trainer log in this folder will be deleted.\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:04<00:00,  2.07s/it]\n",
      "[INFO|trainer.py:2409] 2025-06-23 09:50:50,215 >> ***** Running training *****\n",
      "[INFO|trainer.py:2410] 2025-06-23 09:50:50,215 >>   Num examples = 149,143\n",
      "[INFO|trainer.py:2411] 2025-06-23 09:50:50,215 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:2412] 2025-06-23 09:50:50,215 >>   Instantaneous batch size per device = 1\n",
      "[INFO|trainer.py:2415] 2025-06-23 09:50:50,215 >>   Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "[INFO|trainer.py:2416] 2025-06-23 09:50:50,215 >>   Gradient Accumulation steps = 16\n",
      "[INFO|trainer.py:2417] 2025-06-23 09:50:50,215 >>   Total optimization steps = 4,661\n",
      "[INFO|trainer.py:2418] 2025-06-23 09:50:50,215 >>   Number of trainable parameters = 402,677,760\n",
      "{'loss': 2.3306, 'grad_norm': 0.4187232255935669, 'learning_rate': 1.9271948608137047e-06, 'epoch': 0.0}\n",
      "{'loss': 2.3095, 'grad_norm': 0.35032007098197937, 'learning_rate': 4.0685224839400435e-06, 'epoch': 0.0}\n",
      "{'loss': 2.2548, 'grad_norm': 0.31067854166030884, 'learning_rate': 6.209850107066381e-06, 'epoch': 0.01}\n",
      "{'loss': 2.2836, 'grad_norm': 0.31570735573768616, 'learning_rate': 8.35117773019272e-06, 'epoch': 0.01}\n",
      "{'loss': 2.2433, 'grad_norm': 0.3065086901187897, 'learning_rate': 1.0492505353319059e-05, 'epoch': 0.01}\n",
      "{'loss': 2.2793, 'grad_norm': 0.291928231716156, 'learning_rate': 1.2633832976445397e-05, 'epoch': 0.01}\n",
      "{'loss': 2.2329, 'grad_norm': 0.30609121918678284, 'learning_rate': 1.4775160599571736e-05, 'epoch': 0.02}\n",
      "{'loss': 2.2531, 'grad_norm': 0.2877193093299866, 'learning_rate': 1.6916488222698074e-05, 'epoch': 0.02}\n",
      "{'loss': 2.2412, 'grad_norm': 0.28876417875289917, 'learning_rate': 1.905781584582441e-05, 'epoch': 0.02}\n",
      "{'loss': 2.2368, 'grad_norm': 0.2981189489364624, 'learning_rate': 2.119914346895075e-05, 'epoch': 0.02}\n",
      "{'loss': 2.2267, 'grad_norm': 0.30062514543533325, 'learning_rate': 2.334047109207709e-05, 'epoch': 0.02}\n",
      "{'loss': 2.2633, 'grad_norm': 0.2913389205932617, 'learning_rate': 2.5481798715203425e-05, 'epoch': 0.03}\n",
      "{'loss': 2.2481, 'grad_norm': 0.3218705356121063, 'learning_rate': 2.7623126338329765e-05, 'epoch': 0.03}\n",
      "{'loss': 2.2621, 'grad_norm': 0.31212615966796875, 'learning_rate': 2.9764453961456108e-05, 'epoch': 0.03}\n",
      "{'loss': 2.2145, 'grad_norm': 0.31418919563293457, 'learning_rate': 3.190578158458244e-05, 'epoch': 0.03}\n",
      "{'loss': 2.2435, 'grad_norm': 0.32539018988609314, 'learning_rate': 3.404710920770878e-05, 'epoch': 0.03}\n",
      "{'loss': 2.231, 'grad_norm': 0.3037357032299042, 'learning_rate': 3.618843683083512e-05, 'epoch': 0.04}\n",
      "{'loss': 2.2308, 'grad_norm': 0.31263044476509094, 'learning_rate': 3.832976445396146e-05, 'epoch': 0.04}\n",
      "{'loss': 2.2293, 'grad_norm': 0.3241458833217621, 'learning_rate': 4.0471092077087795e-05, 'epoch': 0.04}\n",
      "{'loss': 2.2148, 'grad_norm': 0.33667266368865967, 'learning_rate': 4.2612419700214135e-05, 'epoch': 0.04}\n",
      "{'loss': 2.23, 'grad_norm': 0.309222012758255, 'learning_rate': 4.4753747323340476e-05, 'epoch': 0.05}\n",
      "{'loss': 2.2123, 'grad_norm': 0.31356897950172424, 'learning_rate': 4.689507494646681e-05, 'epoch': 0.05}\n",
      "{'loss': 2.229, 'grad_norm': 0.31060829758644104, 'learning_rate': 4.903640256959315e-05, 'epoch': 0.05}\n",
      "{'loss': 2.2347, 'grad_norm': 0.29592597484588623, 'learning_rate': 5.117773019271949e-05, 'epoch': 0.05}\n",
      "{'loss': 2.1984, 'grad_norm': 0.30620312690734863, 'learning_rate': 5.331905781584583e-05, 'epoch': 0.05}\n",
      "{'loss': 2.2138, 'grad_norm': 0.309536337852478, 'learning_rate': 5.546038543897216e-05, 'epoch': 0.06}\n",
      "{'loss': 2.206, 'grad_norm': 0.3245522975921631, 'learning_rate': 5.76017130620985e-05, 'epoch': 0.06}\n",
      "{'loss': 2.1978, 'grad_norm': 0.3547234833240509, 'learning_rate': 5.9743040685224836e-05, 'epoch': 0.06}\n",
      "{'loss': 2.2292, 'grad_norm': 0.3397403657436371, 'learning_rate': 6.188436830835118e-05, 'epoch': 0.06}\n",
      "{'loss': 2.2259, 'grad_norm': 0.33372703194618225, 'learning_rate': 6.402569593147751e-05, 'epoch': 0.06}\n",
      "{'loss': 2.2383, 'grad_norm': 0.31935131549835205, 'learning_rate': 6.616702355460386e-05, 'epoch': 0.07}\n",
      "{'loss': 2.2327, 'grad_norm': 0.36800873279571533, 'learning_rate': 6.83083511777302e-05, 'epoch': 0.07}\n",
      "{'loss': 2.2434, 'grad_norm': 0.32652080059051514, 'learning_rate': 7.044967880085654e-05, 'epoch': 0.07}\n",
      "{'loss': 2.2529, 'grad_norm': 0.29575487971305847, 'learning_rate': 7.259100642398287e-05, 'epoch': 0.07}\n",
      "{'loss': 2.2152, 'grad_norm': 0.2890518605709076, 'learning_rate': 7.47323340471092e-05, 'epoch': 0.08}\n",
      "{'loss': 2.2146, 'grad_norm': 0.30165916681289673, 'learning_rate': 7.687366167023555e-05, 'epoch': 0.08}\n",
      "{'loss': 2.1843, 'grad_norm': 0.3240520656108856, 'learning_rate': 7.901498929336188e-05, 'epoch': 0.08}\n",
      "{'loss': 2.1949, 'grad_norm': 0.3680410385131836, 'learning_rate': 8.115631691648823e-05, 'epoch': 0.08}\n",
      "{'loss': 2.1716, 'grad_norm': 0.3226267993450165, 'learning_rate': 8.329764453961456e-05, 'epoch': 0.08}\n",
      "{'loss': 2.2038, 'grad_norm': 0.33160144090652466, 'learning_rate': 8.543897216274091e-05, 'epoch': 0.09}\n",
      "{'loss': 2.208, 'grad_norm': 0.3048815131187439, 'learning_rate': 8.758029978586723e-05, 'epoch': 0.09}\n",
      "{'loss': 2.2268, 'grad_norm': 0.33539053797721863, 'learning_rate': 8.972162740899358e-05, 'epoch': 0.09}\n",
      "{'loss': 2.2159, 'grad_norm': 0.28625765442848206, 'learning_rate': 9.186295503211992e-05, 'epoch': 0.09}\n",
      "{'loss': 2.2063, 'grad_norm': 0.2943548262119293, 'learning_rate': 9.400428265524626e-05, 'epoch': 0.09}\n",
      "{'loss': 2.2259, 'grad_norm': 0.28983989357948303, 'learning_rate': 9.61456102783726e-05, 'epoch': 0.1}\n",
      "{'loss': 2.1973, 'grad_norm': 0.3206685781478882, 'learning_rate': 9.828693790149894e-05, 'epoch': 0.1}\n",
      "{'loss': 2.2086, 'grad_norm': 0.28545311093330383, 'learning_rate': 9.999994388967142e-05, 'epoch': 0.1}\n",
      "{'loss': 2.1946, 'grad_norm': 0.30156517028808594, 'learning_rate': 9.999798004139435e-05, 'epoch': 0.1}\n",
      "{'loss': 2.1854, 'grad_norm': 0.33318212628364563, 'learning_rate': 9.999321080262189e-05, 'epoch': 0.11}\n",
      "{'loss': 2.2209, 'grad_norm': 0.2806209921836853, 'learning_rate': 9.998563644095643e-05, 'epoch': 0.11}\n",
      " 11%|████                                  | 500/4661 [39:59<5:33:11,  4.80s/it][INFO|trainer.py:3993] 2025-06-23 10:30:53,282 >> Saving model checkpoint to llama3-3b_freeze_5per/checkpoint-500\n",
      "[INFO|configuration_utils.py:424] 2025-06-23 10:30:53,283 >> Configuration saved in llama3-3b_freeze_5per/checkpoint-500/config.json\n",
      "[INFO|configuration_utils.py:904] 2025-06-23 10:30:53,284 >> Configuration saved in llama3-3b_freeze_5per/checkpoint-500/generation_config.json\n",
      "[INFO|modeling_utils.py:3733] 2025-06-23 10:30:57,186 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at llama3-3b_freeze_5per/checkpoint-500/model.safetensors.index.json.\n",
      "[INFO|tokenization_utils_base.py:2356] 2025-06-23 10:30:57,186 >> chat template saved in llama3-3b_freeze_5per/checkpoint-500/chat_template.jinja\n",
      "[INFO|tokenization_utils_base.py:2525] 2025-06-23 10:30:57,187 >> tokenizer config file saved in llama3-3b_freeze_5per/checkpoint-500/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2534] 2025-06-23 10:30:57,187 >> Special tokens file saved in llama3-3b_freeze_5per/checkpoint-500/special_tokens_map.json\n",
      "{'loss': 2.2096, 'grad_norm': 0.2800004184246063, 'learning_rate': 9.997525738139593e-05, 'epoch': 0.11}\n",
      "{'loss': 2.2056, 'grad_norm': 0.3043842017650604, 'learning_rate': 9.996207420631029e-05, 'epoch': 0.11}\n",
      "{'loss': 2.2136, 'grad_norm': 0.3217737674713135, 'learning_rate': 9.994608765540841e-05, 'epoch': 0.11}\n",
      "{'loss': 2.2026, 'grad_norm': 0.30513375997543335, 'learning_rate': 9.992729862569695e-05, 'epoch': 0.12}\n",
      "{'loss': 2.1955, 'grad_norm': 0.35209178924560547, 'learning_rate': 9.990570817142974e-05, 'epoch': 0.12}\n",
      "{'loss': 2.2091, 'grad_norm': 0.27788618206977844, 'learning_rate': 9.988131750404888e-05, 'epoch': 0.12}\n",
      "{'loss': 2.2329, 'grad_norm': 0.2870039641857147, 'learning_rate': 9.985412799211658e-05, 'epoch': 0.12}\n",
      "{'loss': 2.2109, 'grad_norm': 0.28877967596054077, 'learning_rate': 9.98241411612384e-05, 'epoch': 0.12}\n",
      "{'loss': 2.2393, 'grad_norm': 0.2724924087524414, 'learning_rate': 9.979135869397777e-05, 'epoch': 0.13}\n",
      "{'loss': 2.2021, 'grad_norm': 0.2942122220993042, 'learning_rate': 9.97557824297614e-05, 'epoch': 0.13}\n",
      "{'loss': 2.2065, 'grad_norm': 0.3038180470466614, 'learning_rate': 9.971741436477625e-05, 'epoch': 0.13}\n",
      "{'loss': 2.216, 'grad_norm': 0.28694048523902893, 'learning_rate': 9.967625665185736e-05, 'epoch': 0.13}\n",
      "{'loss': 2.1996, 'grad_norm': 0.27733710408210754, 'learning_rate': 9.963231160036714e-05, 'epoch': 0.14}\n",
      "{'loss': 2.2086, 'grad_norm': 0.28376659750938416, 'learning_rate': 9.958558167606585e-05, 'epoch': 0.14}\n",
      "{'loss': 2.2073, 'grad_norm': 0.29128891229629517, 'learning_rate': 9.95360695009731e-05, 'epoch': 0.14}\n",
      "{'loss': 2.2101, 'grad_norm': 0.2900727093219757, 'learning_rate': 9.948377785322082e-05, 'epoch': 0.14}\n",
      "{'loss': 2.1819, 'grad_norm': 0.32297319173812866, 'learning_rate': 9.942870966689742e-05, 'epoch': 0.14}\n",
      "{'loss': 2.216, 'grad_norm': 0.30849453806877136, 'learning_rate': 9.937086803188299e-05, 'epoch': 0.15}\n",
      "{'loss': 2.1948, 'grad_norm': 0.2833743691444397, 'learning_rate': 9.931025619367616e-05, 'epoch': 0.15}\n",
      "{'loss': 2.2169, 'grad_norm': 0.2980232536792755, 'learning_rate': 9.924687755321182e-05, 'epoch': 0.15}\n",
      "{'loss': 2.1779, 'grad_norm': 0.29763028025627136, 'learning_rate': 9.918073566667032e-05, 'epoch': 0.15}\n",
      "{'loss': 2.1854, 'grad_norm': 0.2765275835990906, 'learning_rate': 9.911183424527801e-05, 'epoch': 0.15}\n",
      "{'loss': 2.1993, 'grad_norm': 0.28905367851257324, 'learning_rate': 9.904017715509894e-05, 'epoch': 0.16}\n",
      "{'loss': 2.2012, 'grad_norm': 0.2747562825679779, 'learning_rate': 9.89657684168179e-05, 'epoch': 0.16}\n",
      "{'loss': 2.2022, 'grad_norm': 0.28479719161987305, 'learning_rate': 9.888861220551493e-05, 'epoch': 0.16}\n",
      "{'loss': 2.2065, 'grad_norm': 0.30017033219337463, 'learning_rate': 9.880871285043094e-05, 'epoch': 0.16}\n",
      "{'loss': 2.2188, 'grad_norm': 0.2918013334274292, 'learning_rate': 9.872607483472491e-05, 'epoch': 0.17}\n",
      "{'loss': 2.2311, 'grad_norm': 0.30123504996299744, 'learning_rate': 9.864070279522222e-05, 'epoch': 0.17}\n",
      "{'loss': 2.1883, 'grad_norm': 0.2900785803794861, 'learning_rate': 9.855260152215454e-05, 'epoch': 0.17}\n",
      "{'loss': 2.228, 'grad_norm': 0.2795523703098297, 'learning_rate': 9.846177595889109e-05, 'epoch': 0.17}\n",
      "{'loss': 2.1624, 'grad_norm': 0.2830331325531006, 'learning_rate': 9.836823120166116e-05, 'epoch': 0.17}\n",
      "{'loss': 2.2052, 'grad_norm': 0.29008790850639343, 'learning_rate': 9.82719724992683e-05, 'epoch': 0.18}\n",
      "{'loss': 2.2052, 'grad_norm': 0.2884165644645691, 'learning_rate': 9.817300525279562e-05, 'epoch': 0.18}\n",
      "{'loss': 2.1714, 'grad_norm': 0.34893107414245605, 'learning_rate': 9.807133501530296e-05, 'epoch': 0.18}\n",
      "{'loss': 2.2123, 'grad_norm': 0.27715879678726196, 'learning_rate': 9.796696749151516e-05, 'epoch': 0.18}\n",
      "{'loss': 2.177, 'grad_norm': 0.2737463712692261, 'learning_rate': 9.785990853750193e-05, 'epoch': 0.18}\n",
      "{'loss': 2.1546, 'grad_norm': 0.27323660254478455, 'learning_rate': 9.775016416034941e-05, 'epoch': 0.19}\n",
      "{'loss': 2.2111, 'grad_norm': 0.2975998520851135, 'learning_rate': 9.763774051782305e-05, 'epoch': 0.19}\n",
      "{'loss': 2.1625, 'grad_norm': 0.2861101031303406, 'learning_rate': 9.752264391802203e-05, 'epoch': 0.19}\n",
      "{'loss': 2.1823, 'grad_norm': 0.27344778180122375, 'learning_rate': 9.740488081902539e-05, 'epoch': 0.19}\n",
      "{'loss': 2.1671, 'grad_norm': 0.27685481309890747, 'learning_rate': 9.728445782852966e-05, 'epoch': 0.2}\n",
      "{'loss': 2.1811, 'grad_norm': 0.2631957530975342, 'learning_rate': 9.716138170347808e-05, 'epoch': 0.2}\n",
      "{'loss': 2.224, 'grad_norm': 0.29955995082855225, 'learning_rate': 9.703565934968146e-05, 'epoch': 0.2}\n",
      "{'loss': 2.2047, 'grad_norm': 0.28017792105674744, 'learning_rate': 9.690729782143071e-05, 'epoch': 0.2}\n",
      "{'loss': 2.2249, 'grad_norm': 0.264180064201355, 'learning_rate': 9.677630432110103e-05, 'epoch': 0.2}\n",
      "{'loss': 2.2157, 'grad_norm': 0.27051180601119995, 'learning_rate': 9.664268619874777e-05, 'epoch': 0.21}\n",
      "{'loss': 2.1805, 'grad_norm': 0.2716348171234131, 'learning_rate': 9.650645095169404e-05, 'epoch': 0.21}\n",
      "{'loss': 2.1883, 'grad_norm': 0.2675918936729431, 'learning_rate': 9.636760622410997e-05, 'epoch': 0.21}\n",
      "{'loss': 2.2068, 'grad_norm': 0.2672065794467926, 'learning_rate': 9.622615980658391e-05, 'epoch': 0.21}\n",
      "{'loss': 2.1435, 'grad_norm': 0.2860785126686096, 'learning_rate': 9.608211963568518e-05, 'epoch': 0.21}\n",
      " 21%|███████▌                           | 1000/4661 [1:20:09<4:53:06,  4.80s/it][INFO|trainer.py:3993] 2025-06-23 11:11:03,780 >> Saving model checkpoint to llama3-3b_freeze_5per/checkpoint-1000\n",
      "[INFO|configuration_utils.py:424] 2025-06-23 11:11:03,781 >> Configuration saved in llama3-3b_freeze_5per/checkpoint-1000/config.json\n",
      "[INFO|configuration_utils.py:904] 2025-06-23 11:11:03,781 >> Configuration saved in llama3-3b_freeze_5per/checkpoint-1000/generation_config.json\n",
      "[INFO|modeling_utils.py:3733] 2025-06-23 11:11:07,655 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at llama3-3b_freeze_5per/checkpoint-1000/model.safetensors.index.json.\n",
      "[INFO|tokenization_utils_base.py:2356] 2025-06-23 11:11:07,656 >> chat template saved in llama3-3b_freeze_5per/checkpoint-1000/chat_template.jinja\n",
      "[INFO|tokenization_utils_base.py:2525] 2025-06-23 11:11:07,657 >> tokenizer config file saved in llama3-3b_freeze_5per/checkpoint-1000/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2534] 2025-06-23 11:11:07,657 >> Special tokens file saved in llama3-3b_freeze_5per/checkpoint-1000/special_tokens_map.json\n",
      "{'loss': 2.2116, 'grad_norm': 0.2661207616329193, 'learning_rate': 9.59354937935188e-05, 'epoch': 0.22}\n",
      "{'loss': 2.2074, 'grad_norm': 0.26165705919265747, 'learning_rate': 9.578629050727208e-05, 'epoch': 0.22}\n",
      "{'loss': 2.2156, 'grad_norm': 0.2610805034637451, 'learning_rate': 9.56345181487528e-05, 'epoch': 0.22}\n",
      "{'loss': 2.1893, 'grad_norm': 0.270254522562027, 'learning_rate': 9.548018523391965e-05, 'epoch': 0.22}\n",
      "{'loss': 2.2311, 'grad_norm': 0.2840074598789215, 'learning_rate': 9.532330042240434e-05, 'epoch': 0.23}\n",
      "{'loss': 2.1853, 'grad_norm': 0.26659294962882996, 'learning_rate': 9.516387251702565e-05, 'epoch': 0.23}\n",
      "{'loss': 2.1674, 'grad_norm': 0.2640215754508972, 'learning_rate': 9.500191046329561e-05, 'epoch': 0.23}\n",
      "{'loss': 2.1921, 'grad_norm': 0.25988104939460754, 'learning_rate': 9.483742334891746e-05, 'epoch': 0.23}\n",
      "{'loss': 2.2259, 'grad_norm': 0.251788854598999, 'learning_rate': 9.467042040327582e-05, 'epoch': 0.23}\n",
      "{'loss': 2.1852, 'grad_norm': 0.27457451820373535, 'learning_rate': 9.450091099691875e-05, 'epoch': 0.24}\n",
      "{'loss': 2.1715, 'grad_norm': 0.2972342371940613, 'learning_rate': 9.432890464103208e-05, 'epoch': 0.24}\n",
      "{'loss': 2.1902, 'grad_norm': 0.2720593512058258, 'learning_rate': 9.415441098690561e-05, 'epoch': 0.24}\n",
      "{'loss': 2.1716, 'grad_norm': 0.27787524461746216, 'learning_rate': 9.397743982539167e-05, 'epoch': 0.24}\n",
      "{'loss': 2.1852, 'grad_norm': 0.2580935060977936, 'learning_rate': 9.37980010863557e-05, 'epoch': 0.24}\n",
      "{'loss': 2.2009, 'grad_norm': 0.27991244196891785, 'learning_rate': 9.36161048381191e-05, 'epoch': 0.25}\n",
      "{'loss': 2.1909, 'grad_norm': 0.25403523445129395, 'learning_rate': 9.343176128689434e-05, 'epoch': 0.25}\n",
      "{'loss': 2.1917, 'grad_norm': 0.2624427378177643, 'learning_rate': 9.32449807762122e-05, 'epoch': 0.25}\n",
      "{'loss': 2.1756, 'grad_norm': 0.26981738209724426, 'learning_rate': 9.305577378634148e-05, 'epoch': 0.25}\n",
      "{'loss': 2.1658, 'grad_norm': 0.27098721265792847, 'learning_rate': 9.286415093370086e-05, 'epoch': 0.26}\n",
      "{'loss': 2.1725, 'grad_norm': 0.2717680335044861, 'learning_rate': 9.267012297026334e-05, 'epoch': 0.26}\n",
      "{'loss': 2.1757, 'grad_norm': 0.2682621479034424, 'learning_rate': 9.24737007829528e-05, 'epoch': 0.26}\n",
      "{'loss': 2.1434, 'grad_norm': 0.2581455111503601, 'learning_rate': 9.227489539303328e-05, 'epoch': 0.26}\n",
      "{'loss': 2.1699, 'grad_norm': 0.2829652428627014, 'learning_rate': 9.207371795549043e-05, 'epoch': 0.26}\n",
      "{'loss': 2.1703, 'grad_norm': 0.2694924771785736, 'learning_rate': 9.187017975840568e-05, 'epoch': 0.27}\n",
      "{'loss': 2.1884, 'grad_norm': 0.2612658143043518, 'learning_rate': 9.166429222232291e-05, 'epoch': 0.27}\n",
      "{'loss': 2.1848, 'grad_norm': 0.2711326479911804, 'learning_rate': 9.145606689960756e-05, 'epoch': 0.27}\n",
      "{'loss': 2.121, 'grad_norm': 0.3061484694480896, 'learning_rate': 9.124551547379846e-05, 'epoch': 0.27}\n",
      "{'loss': 2.1569, 'grad_norm': 0.268764466047287, 'learning_rate': 9.103264975895225e-05, 'epoch': 0.27}\n",
      "{'loss': 2.1867, 'grad_norm': 0.26882076263427734, 'learning_rate': 9.081748169898054e-05, 'epoch': 0.28}\n",
      "{'loss': 2.2139, 'grad_norm': 0.28262874484062195, 'learning_rate': 9.060002336697968e-05, 'epoch': 0.28}\n",
      "{'loss': 2.1893, 'grad_norm': 0.25795426964759827, 'learning_rate': 9.038028696455334e-05, 'epoch': 0.28}\n",
      "{'loss': 2.186, 'grad_norm': 0.2988315224647522, 'learning_rate': 9.015828482112792e-05, 'epoch': 0.28}\n",
      "{'loss': 2.1618, 'grad_norm': 0.2738429605960846, 'learning_rate': 8.993402939326072e-05, 'epoch': 0.29}\n",
      "{'loss': 2.1653, 'grad_norm': 0.2860998511314392, 'learning_rate': 8.970753326394101e-05, 'epoch': 0.29}\n",
      "{'loss': 2.1975, 'grad_norm': 0.26074114441871643, 'learning_rate': 8.947880914188397e-05, 'epoch': 0.29}\n",
      "{'loss': 2.1987, 'grad_norm': 0.26529914140701294, 'learning_rate': 8.924786986081763e-05, 'epoch': 0.29}\n",
      "{'loss': 2.1574, 'grad_norm': 0.27208879590034485, 'learning_rate': 8.90147283787628e-05, 'epoch': 0.29}\n",
      "{'loss': 2.1636, 'grad_norm': 0.2985142469406128, 'learning_rate': 8.877939777730586e-05, 'epoch': 0.3}\n",
      "{'loss': 2.1958, 'grad_norm': 0.2634011209011078, 'learning_rate': 8.854189126086493e-05, 'epoch': 0.3}\n",
      "{'loss': 2.2106, 'grad_norm': 0.2569395899772644, 'learning_rate': 8.83022221559489e-05, 'epoch': 0.3}\n",
      "{'loss': 2.1849, 'grad_norm': 0.2922869920730591, 'learning_rate': 8.806040391040962e-05, 'epoch': 0.3}\n",
      "{'loss': 2.1742, 'grad_norm': 0.30759871006011963, 'learning_rate': 8.781645009268738e-05, 'epoch': 0.3}\n",
      "{'loss': 2.1538, 'grad_norm': 0.27491018176078796, 'learning_rate': 8.75703743910496e-05, 'epoch': 0.31}\n",
      "{'loss': 2.1986, 'grad_norm': 0.27887579798698425, 'learning_rate': 8.732219061282278e-05, 'epoch': 0.31}\n",
      "{'loss': 2.1378, 'grad_norm': 0.2619487941265106, 'learning_rate': 8.707191268361779e-05, 'epoch': 0.31}\n",
      "{'loss': 2.1624, 'grad_norm': 0.26663628220558167, 'learning_rate': 8.681955464654839e-05, 'epoch': 0.31}\n",
      "{'loss': 2.2281, 'grad_norm': 0.2706061601638794, 'learning_rate': 8.656513066144341e-05, 'epoch': 0.32}\n",
      "{'loss': 2.1998, 'grad_norm': 0.3180978000164032, 'learning_rate': 8.630865500405219e-05, 'epoch': 0.32}\n",
      "{'loss': 2.1821, 'grad_norm': 0.25424107909202576, 'learning_rate': 8.605014206524351e-05, 'epoch': 0.32}\n",
      "{'loss': 2.1874, 'grad_norm': 0.270808607339859, 'learning_rate': 8.578960635019823e-05, 'epoch': 0.32}\n",
      " 32%|███████████▎                       | 1500/4661 [2:00:17<4:12:44,  4.80s/it][INFO|trainer.py:3993] 2025-06-23 11:51:11,815 >> Saving model checkpoint to llama3-3b_freeze_5per/checkpoint-1500\n",
      "[INFO|configuration_utils.py:424] 2025-06-23 11:51:11,816 >> Configuration saved in llama3-3b_freeze_5per/checkpoint-1500/config.json\n",
      "[INFO|configuration_utils.py:904] 2025-06-23 11:51:11,816 >> Configuration saved in llama3-3b_freeze_5per/checkpoint-1500/generation_config.json\n",
      "[INFO|modeling_utils.py:3733] 2025-06-23 11:51:15,751 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at llama3-3b_freeze_5per/checkpoint-1500/model.safetensors.index.json.\n",
      "[INFO|tokenization_utils_base.py:2356] 2025-06-23 11:51:15,751 >> chat template saved in llama3-3b_freeze_5per/checkpoint-1500/chat_template.jinja\n",
      "[INFO|tokenization_utils_base.py:2525] 2025-06-23 11:51:15,752 >> tokenizer config file saved in llama3-3b_freeze_5per/checkpoint-1500/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2534] 2025-06-23 11:51:15,752 >> Special tokens file saved in llama3-3b_freeze_5per/checkpoint-1500/special_tokens_map.json\n",
      "{'loss': 2.1789, 'grad_norm': 0.27697816491127014, 'learning_rate': 8.552706247759528e-05, 'epoch': 0.32}\n",
      "{'loss': 2.1957, 'grad_norm': 0.2852042615413666, 'learning_rate': 8.52625251787915e-05, 'epoch': 0.33}\n",
      "{'loss': 2.1833, 'grad_norm': 0.2607614994049072, 'learning_rate': 8.4996009296995e-05, 'epoch': 0.33}\n",
      "{'loss': 2.148, 'grad_norm': 0.27333885431289673, 'learning_rate': 8.472752978643239e-05, 'epoch': 0.33}\n",
      "{'loss': 2.1876, 'grad_norm': 0.26918119192123413, 'learning_rate': 8.445710171150958e-05, 'epoch': 0.33}\n",
      "{'loss': 2.1702, 'grad_norm': 0.2791956067085266, 'learning_rate': 8.418474024596658e-05, 'epoch': 0.33}\n",
      "{'loss': 2.1551, 'grad_norm': 0.26260989904403687, 'learning_rate': 8.391046067202618e-05, 'epoch': 0.34}\n",
      "{'loss': 2.173, 'grad_norm': 0.27910327911376953, 'learning_rate': 8.363427837953621e-05, 'epoch': 0.34}\n",
      "{'loss': 2.1724, 'grad_norm': 0.2642763555049896, 'learning_rate': 8.335620886510638e-05, 'epoch': 0.34}\n",
      "{'loss': 2.2012, 'grad_norm': 0.2605186402797699, 'learning_rate': 8.307626773123843e-05, 'epoch': 0.34}\n",
      "{'loss': 2.1834, 'grad_norm': 0.2600175440311432, 'learning_rate': 8.279447068545085e-05, 'epoch': 0.35}\n",
      "{'loss': 2.1607, 'grad_norm': 0.25334280729293823, 'learning_rate': 8.251083353939752e-05, 'epoch': 0.35}\n",
      "{'loss': 2.1724, 'grad_norm': 0.2570108473300934, 'learning_rate': 8.222537220798045e-05, 'epoch': 0.35}\n",
      "{'loss': 2.1551, 'grad_norm': 0.26575925946235657, 'learning_rate': 8.193810270845684e-05, 'epoch': 0.35}\n",
      "{'loss': 2.155, 'grad_norm': 0.2575252056121826, 'learning_rate': 8.164904115954035e-05, 'epoch': 0.35}\n",
      "{'loss': 2.1661, 'grad_norm': 0.262475848197937, 'learning_rate': 8.135820378049667e-05, 'epoch': 0.36}\n",
      "{'loss': 2.1982, 'grad_norm': 0.2661747336387634, 'learning_rate': 8.106560689023342e-05, 'epoch': 0.36}\n",
      "{'loss': 2.1883, 'grad_norm': 0.25646692514419556, 'learning_rate': 8.07712669063846e-05, 'epoch': 0.36}\n",
      "{'loss': 2.1978, 'grad_norm': 0.2778162360191345, 'learning_rate': 8.047520034438925e-05, 'epoch': 0.36}\n",
      "{'loss': 2.1786, 'grad_norm': 0.2582942545413971, 'learning_rate': 8.017742381656485e-05, 'epoch': 0.36}\n",
      "{'loss': 2.1292, 'grad_norm': 0.25845593214035034, 'learning_rate': 7.987795403117529e-05, 'epoch': 0.37}\n",
      "{'loss': 2.1664, 'grad_norm': 0.2546929717063904, 'learning_rate': 7.957680779149315e-05, 'epoch': 0.37}\n",
      "{'loss': 2.1674, 'grad_norm': 0.2711576521396637, 'learning_rate': 7.927400199485704e-05, 'epoch': 0.37}\n",
      "{'loss': 2.167, 'grad_norm': 0.25480031967163086, 'learning_rate': 7.896955363172347e-05, 'epoch': 0.37}\n",
      "{'loss': 2.1841, 'grad_norm': 0.2504996657371521, 'learning_rate': 7.86634797847134e-05, 'epoch': 0.38}\n",
      "{'loss': 2.2013, 'grad_norm': 0.24743066728115082, 'learning_rate': 7.83557976276539e-05, 'epoch': 0.38}\n",
      "{'loss': 2.2212, 'grad_norm': 0.25400739908218384, 'learning_rate': 7.804652442461439e-05, 'epoch': 0.38}\n",
      "{'loss': 2.1663, 'grad_norm': 0.2696475088596344, 'learning_rate': 7.773567752893802e-05, 'epoch': 0.38}\n",
      "{'loss': 2.1671, 'grad_norm': 0.30160531401634216, 'learning_rate': 7.742327438226796e-05, 'epoch': 0.38}\n",
      "{'loss': 2.1471, 'grad_norm': 0.2519398331642151, 'learning_rate': 7.71093325135687e-05, 'epoch': 0.39}\n",
      "{'loss': 2.1632, 'grad_norm': 0.2463679015636444, 'learning_rate': 7.679386953814263e-05, 'epoch': 0.39}\n",
      "{'loss': 2.1886, 'grad_norm': 0.2607194781303406, 'learning_rate': 7.647690315664144e-05, 'epoch': 0.39}\n",
      "{'loss': 2.1558, 'grad_norm': 0.2695656418800354, 'learning_rate': 7.615845115407316e-05, 'epoch': 0.39}\n",
      "{'loss': 2.1578, 'grad_norm': 0.26762205362319946, 'learning_rate': 7.583853139880406e-05, 'epoch': 0.39}\n",
      "{'loss': 2.1519, 'grad_norm': 0.2544095516204834, 'learning_rate': 7.551716184155614e-05, 'epoch': 0.4}\n",
      "{'loss': 2.1514, 'grad_norm': 0.26001033186912537, 'learning_rate': 7.519436051439991e-05, 'epoch': 0.4}\n",
      "{'loss': 2.1528, 'grad_norm': 0.2500114142894745, 'learning_rate': 7.487014552974263e-05, 'epoch': 0.4}\n",
      "{'loss': 2.1575, 'grad_norm': 0.25618699193000793, 'learning_rate': 7.454453507931192e-05, 'epoch': 0.4}\n",
      "{'loss': 2.1552, 'grad_norm': 0.2581384778022766, 'learning_rate': 7.421754743313514e-05, 'epoch': 0.41}\n",
      "{'loss': 2.1793, 'grad_norm': 0.25151097774505615, 'learning_rate': 7.388920093851421e-05, 'epoch': 0.41}\n",
      "{'loss': 2.1759, 'grad_norm': 0.2680639624595642, 'learning_rate': 7.355951401899613e-05, 'epoch': 0.41}\n",
      "{'loss': 2.1683, 'grad_norm': 0.2645174264907837, 'learning_rate': 7.322850517333923e-05, 'epoch': 0.41}\n",
      "{'loss': 2.158, 'grad_norm': 0.28192487359046936, 'learning_rate': 7.289619297447525e-05, 'epoch': 0.41}\n",
      "{'loss': 2.1678, 'grad_norm': 0.25377318263053894, 'learning_rate': 7.256259606846714e-05, 'epoch': 0.42}\n",
      "{'loss': 2.1702, 'grad_norm': 0.25503817200660706, 'learning_rate': 7.222773317346291e-05, 'epoch': 0.42}\n",
      "{'loss': 2.1497, 'grad_norm': 0.2620047926902771, 'learning_rate': 7.189162307864526e-05, 'epoch': 0.42}\n",
      "{'loss': 2.1841, 'grad_norm': 0.2596342861652374, 'learning_rate': 7.155428464317741e-05, 'epoch': 0.42}\n",
      "{'loss': 2.1504, 'grad_norm': 0.2781568169593811, 'learning_rate': 7.121573679514484e-05, 'epoch': 0.42}\n",
      "{'loss': 2.1507, 'grad_norm': 0.25108373165130615, 'learning_rate': 7.087599853049328e-05, 'epoch': 0.43}\n",
      "{'loss': 2.1857, 'grad_norm': 0.2692611515522003, 'learning_rate': 7.05350889119628e-05, 'epoch': 0.43}\n",
      " 43%|███████████████                    | 2000/4661 [2:40:27<3:32:41,  4.80s/it][INFO|trainer.py:3993] 2025-06-23 12:31:21,508 >> Saving model checkpoint to llama3-3b_freeze_5per/checkpoint-2000\n",
      "[INFO|configuration_utils.py:424] 2025-06-23 12:31:21,509 >> Configuration saved in llama3-3b_freeze_5per/checkpoint-2000/config.json\n",
      "[INFO|configuration_utils.py:904] 2025-06-23 12:31:21,509 >> Configuration saved in llama3-3b_freeze_5per/checkpoint-2000/generation_config.json\n",
      "[INFO|modeling_utils.py:3733] 2025-06-23 12:31:25,617 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at llama3-3b_freeze_5per/checkpoint-2000/model.safetensors.index.json.\n",
      "[INFO|tokenization_utils_base.py:2356] 2025-06-23 12:31:25,617 >> chat template saved in llama3-3b_freeze_5per/checkpoint-2000/chat_template.jinja\n",
      "[INFO|tokenization_utils_base.py:2525] 2025-06-23 12:31:25,618 >> tokenizer config file saved in llama3-3b_freeze_5per/checkpoint-2000/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2534] 2025-06-23 12:31:25,618 >> Special tokens file saved in llama3-3b_freeze_5per/checkpoint-2000/special_tokens_map.json\n",
      "{'loss': 2.1748, 'grad_norm': 0.2659763693809509, 'learning_rate': 7.019302706801826e-05, 'epoch': 0.43}\n",
      "{'loss': 2.1685, 'grad_norm': 0.2629392743110657, 'learning_rate': 6.984983219177598e-05, 'epoch': 0.43}\n",
      "{'loss': 2.1787, 'grad_norm': 0.25913500785827637, 'learning_rate': 6.950552353992678e-05, 'epoch': 0.44}\n",
      "{'loss': 2.178, 'grad_norm': 0.2596590220928192, 'learning_rate': 6.916012043165552e-05, 'epoch': 0.44}\n",
      "{'loss': 2.1639, 'grad_norm': 0.24970029294490814, 'learning_rate': 6.881364224755709e-05, 'epoch': 0.44}\n",
      "{'loss': 2.1649, 'grad_norm': 0.2801102101802826, 'learning_rate': 6.846610842854901e-05, 'epoch': 0.44}\n",
      "{'loss': 2.1708, 'grad_norm': 0.25098296999931335, 'learning_rate': 6.811753847478051e-05, 'epoch': 0.44}\n",
      "{'loss': 2.1933, 'grad_norm': 0.25117427110671997, 'learning_rate': 6.77679519445384e-05, 'epoch': 0.45}\n",
      "{'loss': 2.163, 'grad_norm': 0.2684294879436493, 'learning_rate': 6.741736845314977e-05, 'epoch': 0.45}\n",
      "{'loss': 2.1904, 'grad_norm': 0.2613760530948639, 'learning_rate': 6.706580767188115e-05, 'epoch': 0.45}\n",
      "{'loss': 2.1845, 'grad_norm': 0.2582293748855591, 'learning_rate': 6.671328932683499e-05, 'epoch': 0.45}\n",
      "{'loss': 2.1384, 'grad_norm': 0.2586458623409271, 'learning_rate': 6.635983319784265e-05, 'epoch': 0.45}\n",
      "{'loss': 2.1527, 'grad_norm': 0.2609184682369232, 'learning_rate': 6.600545911735468e-05, 'epoch': 0.46}\n",
      "{'loss': 2.1049, 'grad_norm': 0.24521532654762268, 'learning_rate': 6.565018696932785e-05, 'epoch': 0.46}\n",
      "{'loss': 2.104, 'grad_norm': 0.2638089954853058, 'learning_rate': 6.529403668810968e-05, 'epoch': 0.46}\n",
      "{'loss': 2.1626, 'grad_norm': 0.25052303075790405, 'learning_rate': 6.493702825731976e-05, 'epoch': 0.46}\n",
      "{'loss': 2.1975, 'grad_norm': 0.25321292877197266, 'learning_rate': 6.457918170872854e-05, 'epoch': 0.47}\n",
      "{'loss': 2.154, 'grad_norm': 0.27058449387550354, 'learning_rate': 6.422051712113331e-05, 'epoch': 0.47}\n",
      "{'loss': 2.128, 'grad_norm': 0.2503238022327423, 'learning_rate': 6.386105461923159e-05, 'epoch': 0.47}\n",
      "{'loss': 2.169, 'grad_norm': 0.262753427028656, 'learning_rate': 6.350081437249191e-05, 'epoch': 0.47}\n",
      "{'loss': 2.1727, 'grad_norm': 0.2614835798740387, 'learning_rate': 6.313981659402219e-05, 'epoch': 0.47}\n",
      "{'loss': 2.1607, 'grad_norm': 0.26084545254707336, 'learning_rate': 6.277808153943543e-05, 'epoch': 0.48}\n",
      "{'loss': 2.1603, 'grad_norm': 0.25289186835289, 'learning_rate': 6.241562950571331e-05, 'epoch': 0.48}\n",
      "{'loss': 2.1812, 'grad_norm': 0.25166529417037964, 'learning_rate': 6.205248083006724e-05, 'epoch': 0.48}\n",
      "{'loss': 2.1412, 'grad_norm': 0.2504197657108307, 'learning_rate': 6.16886558887973e-05, 'epoch': 0.48}\n",
      "{'loss': 2.161, 'grad_norm': 0.25622767210006714, 'learning_rate': 6.13241750961488e-05, 'epoch': 0.48}\n",
      "{'loss': 2.1438, 'grad_norm': 0.24570830166339874, 'learning_rate': 6.095905890316701e-05, 'epoch': 0.49}\n",
      "{'loss': 2.1478, 'grad_norm': 0.25766947865486145, 'learning_rate': 6.059332779654953e-05, 'epoch': 0.49}\n",
      "{'loss': 2.1458, 'grad_norm': 0.2490687221288681, 'learning_rate': 6.022700229749676e-05, 'epoch': 0.49}\n",
      "{'loss': 2.1332, 'grad_norm': 0.2550176680088043, 'learning_rate': 5.9860102960560595e-05, 'epoch': 0.49}\n",
      "{'loss': 2.1521, 'grad_norm': 0.253763884305954, 'learning_rate': 5.949265037249097e-05, 'epoch': 0.5}\n",
      "{'loss': 2.1313, 'grad_norm': 0.24452735483646393, 'learning_rate': 5.9124665151080785e-05, 'epoch': 0.5}\n",
      "{'loss': 2.1589, 'grad_norm': 0.24946711957454681, 'learning_rate': 5.875616794400902e-05, 'epoch': 0.5}\n",
      "{'loss': 2.1572, 'grad_norm': 0.2530996799468994, 'learning_rate': 5.838717942768226e-05, 'epoch': 0.5}\n",
      "{'loss': 2.1263, 'grad_norm': 0.2528758645057678, 'learning_rate': 5.8017720306074454e-05, 'epoch': 0.5}\n",
      "{'loss': 2.1243, 'grad_norm': 0.2512599229812622, 'learning_rate': 5.764781130956525e-05, 'epoch': 0.51}\n",
      "{'loss': 2.1702, 'grad_norm': 0.24936656653881073, 'learning_rate': 5.72774731937768e-05, 'epoch': 0.51}\n",
      "{'loss': 2.1372, 'grad_norm': 0.26220235228538513, 'learning_rate': 5.690672673840921e-05, 'epoch': 0.51}\n",
      "{'loss': 2.122, 'grad_norm': 0.262942910194397, 'learning_rate': 5.653559274607455e-05, 'epoch': 0.51}\n",
      "{'loss': 2.147, 'grad_norm': 0.24694694578647614, 'learning_rate': 5.6164092041129546e-05, 'epoch': 0.51}\n",
      "{'loss': 2.1223, 'grad_norm': 0.2577587366104126, 'learning_rate': 5.57922454685073e-05, 'epoch': 0.52}\n",
      "{'loss': 2.1374, 'grad_norm': 0.25675731897354126, 'learning_rate': 5.5420073892547484e-05, 'epoch': 0.52}\n",
      "{'loss': 2.1415, 'grad_norm': 0.2540509104728699, 'learning_rate': 5.504759819582581e-05, 'epoch': 0.52}\n",
      "{'loss': 2.133, 'grad_norm': 0.2502031624317169, 'learning_rate': 5.467483927798217e-05, 'epoch': 0.52}\n",
      "{'loss': 2.168, 'grad_norm': 0.24514570832252502, 'learning_rate': 5.4301818054548046e-05, 'epoch': 0.53}\n",
      "{'loss': 2.149, 'grad_norm': 0.2555648982524872, 'learning_rate': 5.39285554557729e-05, 'epoch': 0.53}\n",
      "{'loss': 2.1764, 'grad_norm': 0.2478078454732895, 'learning_rate': 5.3555072425449784e-05, 'epoch': 0.53}\n",
      "{'loss': 2.1334, 'grad_norm': 0.25117602944374084, 'learning_rate': 5.3181389919740164e-05, 'epoch': 0.53}\n",
      "{'loss': 2.1457, 'grad_norm': 0.24760936200618744, 'learning_rate': 5.280752890599809e-05, 'epoch': 0.53}\n",
      "{'loss': 2.1744, 'grad_norm': 0.24093088507652283, 'learning_rate': 5.243351036159378e-05, 'epoch': 0.54}\n",
      " 54%|██████████████████▊                | 2500/4661 [3:20:35<2:52:49,  4.80s/it][INFO|trainer.py:3993] 2025-06-23 13:11:29,561 >> Saving model checkpoint to llama3-3b_freeze_5per/checkpoint-2500\n",
      "[INFO|configuration_utils.py:424] 2025-06-23 13:11:29,562 >> Configuration saved in llama3-3b_freeze_5per/checkpoint-2500/config.json\n",
      "[INFO|configuration_utils.py:904] 2025-06-23 13:11:29,562 >> Configuration saved in llama3-3b_freeze_5per/checkpoint-2500/generation_config.json\n",
      "[INFO|modeling_utils.py:3733] 2025-06-23 13:11:33,470 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at llama3-3b_freeze_5per/checkpoint-2500/model.safetensors.index.json.\n",
      "[INFO|tokenization_utils_base.py:2356] 2025-06-23 13:11:33,471 >> chat template saved in llama3-3b_freeze_5per/checkpoint-2500/chat_template.jinja\n",
      "[INFO|tokenization_utils_base.py:2525] 2025-06-23 13:11:33,472 >> tokenizer config file saved in llama3-3b_freeze_5per/checkpoint-2500/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2534] 2025-06-23 13:11:33,472 >> Special tokens file saved in llama3-3b_freeze_5per/checkpoint-2500/special_tokens_map.json\n",
      "{'loss': 2.177, 'grad_norm': 0.2474564164876938, 'learning_rate': 5.205935527273638e-05, 'epoch': 0.54}\n",
      "{'loss': 2.15, 'grad_norm': 0.2543984353542328, 'learning_rate': 5.1685084633296665e-05, 'epoch': 0.54}\n",
      "{'loss': 2.1895, 'grad_norm': 0.25552240014076233, 'learning_rate': 5.131071944362893e-05, 'epoch': 0.54}\n",
      "{'loss': 2.1307, 'grad_norm': 0.24866372346878052, 'learning_rate': 5.0936280709392656e-05, 'epoch': 0.54}\n",
      "{'loss': 2.1654, 'grad_norm': 0.2657492756843567, 'learning_rate': 5.0561789440373965e-05, 'epoch': 0.55}\n",
      "{'loss': 2.1949, 'grad_norm': 0.2561178505420685, 'learning_rate': 5.018726664930667e-05, 'epoch': 0.55}\n",
      "{'loss': 2.1563, 'grad_norm': 0.24652999639511108, 'learning_rate': 4.981273335069333e-05, 'epoch': 0.55}\n",
      "{'loss': 2.1537, 'grad_norm': 0.2547764182090759, 'learning_rate': 4.9438210559626047e-05, 'epoch': 0.55}\n",
      "{'loss': 2.1619, 'grad_norm': 0.27212560176849365, 'learning_rate': 4.906371929060734e-05, 'epoch': 0.56}\n",
      "{'loss': 2.1556, 'grad_norm': 0.2629666030406952, 'learning_rate': 4.8689280556371084e-05, 'epoch': 0.56}\n",
      "{'loss': 2.1384, 'grad_norm': 0.25164130330085754, 'learning_rate': 4.831491536670334e-05, 'epoch': 0.56}\n",
      "{'loss': 2.1523, 'grad_norm': 0.23970147967338562, 'learning_rate': 4.794064472726362e-05, 'epoch': 0.56}\n",
      "{'loss': 2.1958, 'grad_norm': 0.24422967433929443, 'learning_rate': 4.756648963840624e-05, 'epoch': 0.56}\n",
      "{'loss': 2.1233, 'grad_norm': 0.23968879878520966, 'learning_rate': 4.7192471094001914e-05, 'epoch': 0.57}\n",
      "{'loss': 2.1606, 'grad_norm': 0.24276188015937805, 'learning_rate': 4.681861008025985e-05, 'epoch': 0.57}\n",
      "{'loss': 2.1675, 'grad_norm': 0.2511262893676758, 'learning_rate': 4.644492757455025e-05, 'epoch': 0.57}\n",
      "{'loss': 2.1468, 'grad_norm': 0.24548207223415375, 'learning_rate': 4.607144454422711e-05, 'epoch': 0.57}\n",
      "{'loss': 2.1552, 'grad_norm': 0.2572818696498871, 'learning_rate': 4.569818194545196e-05, 'epoch': 0.58}\n",
      "{'loss': 2.1184, 'grad_norm': 0.2547788619995117, 'learning_rate': 4.5325160722017845e-05, 'epoch': 0.58}\n",
      "{'loss': 2.18, 'grad_norm': 0.25492337346076965, 'learning_rate': 4.49524018041742e-05, 'epoch': 0.58}\n",
      "{'loss': 2.1503, 'grad_norm': 0.2489088922739029, 'learning_rate': 4.457992610745252e-05, 'epoch': 0.58}\n",
      "{'loss': 2.1874, 'grad_norm': 0.2528853416442871, 'learning_rate': 4.420775453149273e-05, 'epoch': 0.58}\n",
      "{'loss': 2.1483, 'grad_norm': 0.2527490556240082, 'learning_rate': 4.383590795887046e-05, 'epoch': 0.59}\n",
      "{'loss': 2.1338, 'grad_norm': 0.25760510563850403, 'learning_rate': 4.346440725392546e-05, 'epoch': 0.59}\n",
      "{'loss': 2.1318, 'grad_norm': 0.2568468451499939, 'learning_rate': 4.309327326159078e-05, 'epoch': 0.59}\n",
      "{'loss': 2.137, 'grad_norm': 0.26597484946250916, 'learning_rate': 4.272252680622321e-05, 'epoch': 0.59}\n",
      "{'loss': 2.1585, 'grad_norm': 0.2590472400188446, 'learning_rate': 4.235218869043476e-05, 'epoch': 0.59}\n",
      "{'loss': 2.1165, 'grad_norm': 0.2554541826248169, 'learning_rate': 4.198227969392555e-05, 'epoch': 0.6}\n",
      "{'loss': 2.1536, 'grad_norm': 0.26286351680755615, 'learning_rate': 4.161282057231776e-05, 'epoch': 0.6}\n",
      "{'loss': 2.1456, 'grad_norm': 0.24306900799274445, 'learning_rate': 4.1243832055990986e-05, 'epoch': 0.6}\n",
      "{'loss': 2.1343, 'grad_norm': 0.2495495229959488, 'learning_rate': 4.087533484891922e-05, 'epoch': 0.6}\n",
      "{'loss': 2.1606, 'grad_norm': 0.25521618127822876, 'learning_rate': 4.0507349627509036e-05, 'epoch': 0.61}\n",
      "{'loss': 2.1555, 'grad_norm': 0.24853144586086273, 'learning_rate': 4.013989703943941e-05, 'epoch': 0.61}\n",
      "{'loss': 2.1728, 'grad_norm': 0.25317060947418213, 'learning_rate': 3.9772997702503247e-05, 'epoch': 0.61}\n",
      "{'loss': 2.1381, 'grad_norm': 0.2531796991825104, 'learning_rate': 3.9406672203450504e-05, 'epoch': 0.61}\n",
      "{'loss': 2.1705, 'grad_norm': 0.24872525036334991, 'learning_rate': 3.9040941096833e-05, 'epoch': 0.61}\n",
      "{'loss': 2.135, 'grad_norm': 0.24453702569007874, 'learning_rate': 3.86758249038512e-05, 'epoch': 0.62}\n",
      "{'loss': 2.1565, 'grad_norm': 0.2499784231185913, 'learning_rate': 3.831134411120272e-05, 'epoch': 0.62}\n",
      "{'loss': 2.1216, 'grad_norm': 0.2547464966773987, 'learning_rate': 3.7947519169932754e-05, 'epoch': 0.62}\n",
      "{'loss': 2.1198, 'grad_norm': 0.2416042536497116, 'learning_rate': 3.7584370494286697e-05, 'epoch': 0.62}\n",
      "{'loss': 2.1487, 'grad_norm': 0.2432863712310791, 'learning_rate': 3.7221918460564596e-05, 'epoch': 0.62}\n",
      "{'loss': 2.1409, 'grad_norm': 0.2490702122449875, 'learning_rate': 3.686018340597783e-05, 'epoch': 0.63}\n",
      "{'loss': 2.1941, 'grad_norm': 0.24417456984519958, 'learning_rate': 3.64991856275081e-05, 'epoch': 0.63}\n",
      "{'loss': 2.1278, 'grad_norm': 0.24274903535842896, 'learning_rate': 3.613894538076844e-05, 'epoch': 0.63}\n",
      "{'loss': 2.1589, 'grad_norm': 0.23910962045192719, 'learning_rate': 3.57794828788667e-05, 'epoch': 0.63}\n",
      "{'loss': 2.1736, 'grad_norm': 0.2722504138946533, 'learning_rate': 3.542081829127145e-05, 'epoch': 0.64}\n",
      "{'loss': 2.1184, 'grad_norm': 0.2449406534433365, 'learning_rate': 3.5062971742680243e-05, 'epoch': 0.64}\n",
      "{'loss': 2.132, 'grad_norm': 0.2530663311481476, 'learning_rate': 3.470596331189033e-05, 'epoch': 0.64}\n",
      "{'loss': 2.1031, 'grad_norm': 0.2647393047809601, 'learning_rate': 3.4349813030672164e-05, 'epoch': 0.64}\n",
      "{'loss': 2.1209, 'grad_norm': 0.24335139989852905, 'learning_rate': 3.3994540882645354e-05, 'epoch': 0.64}\n",
      " 64%|██████████████████████▌            | 3000/4661 [4:00:44<2:12:58,  4.80s/it][INFO|trainer.py:3993] 2025-06-23 13:51:38,868 >> Saving model checkpoint to llama3-3b_freeze_5per/checkpoint-3000\n",
      "[INFO|configuration_utils.py:424] 2025-06-23 13:51:38,869 >> Configuration saved in llama3-3b_freeze_5per/checkpoint-3000/config.json\n",
      "[INFO|configuration_utils.py:904] 2025-06-23 13:51:38,869 >> Configuration saved in llama3-3b_freeze_5per/checkpoint-3000/generation_config.json\n",
      "[INFO|modeling_utils.py:3733] 2025-06-23 13:51:42,894 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at llama3-3b_freeze_5per/checkpoint-3000/model.safetensors.index.json.\n",
      "[INFO|tokenization_utils_base.py:2356] 2025-06-23 13:51:42,895 >> chat template saved in llama3-3b_freeze_5per/checkpoint-3000/chat_template.jinja\n",
      "[INFO|tokenization_utils_base.py:2525] 2025-06-23 13:51:42,896 >> tokenizer config file saved in llama3-3b_freeze_5per/checkpoint-3000/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2534] 2025-06-23 13:51:42,896 >> Special tokens file saved in llama3-3b_freeze_5per/checkpoint-3000/special_tokens_map.json\n",
      "{'loss': 2.157, 'grad_norm': 0.25402501225471497, 'learning_rate': 3.3640166802157356e-05, 'epoch': 0.65}\n",
      "{'loss': 2.152, 'grad_norm': 0.2566187083721161, 'learning_rate': 3.328671067316501e-05, 'epoch': 0.65}\n",
      "{'loss': 2.1408, 'grad_norm': 0.2481904923915863, 'learning_rate': 3.2934192328118865e-05, 'epoch': 0.65}\n",
      "{'loss': 2.1533, 'grad_norm': 0.24598680436611176, 'learning_rate': 3.258263154685025e-05, 'epoch': 0.65}\n",
      "{'loss': 2.1362, 'grad_norm': 0.24051344394683838, 'learning_rate': 3.223204805546161e-05, 'epoch': 0.65}\n",
      "{'loss': 2.1355, 'grad_norm': 0.24566912651062012, 'learning_rate': 3.18824615252195e-05, 'epoch': 0.66}\n",
      "{'loss': 2.1258, 'grad_norm': 0.25957953929901123, 'learning_rate': 3.1533891571451e-05, 'epoch': 0.66}\n",
      "{'loss': 2.135, 'grad_norm': 0.24824489653110504, 'learning_rate': 3.1186357752442914e-05, 'epoch': 0.66}\n",
      "{'loss': 2.1196, 'grad_norm': 0.2420911341905594, 'learning_rate': 3.083987956834449e-05, 'epoch': 0.66}\n",
      "{'loss': 2.0964, 'grad_norm': 0.24987004697322845, 'learning_rate': 3.0494476460073235e-05, 'epoch': 0.67}\n",
      "{'loss': 2.144, 'grad_norm': 0.2551586925983429, 'learning_rate': 3.0150167808224016e-05, 'epoch': 0.67}\n",
      "{'loss': 2.1356, 'grad_norm': 0.2407235950231552, 'learning_rate': 2.9806972931981737e-05, 'epoch': 0.67}\n",
      "{'loss': 2.1105, 'grad_norm': 0.23917512595653534, 'learning_rate': 2.9464911088037223e-05, 'epoch': 0.67}\n",
      "{'loss': 2.1375, 'grad_norm': 0.2505796253681183, 'learning_rate': 2.9124001469506745e-05, 'epoch': 0.67}\n",
      "{'loss': 2.1334, 'grad_norm': 0.248225599527359, 'learning_rate': 2.8784263204855176e-05, 'epoch': 0.68}\n",
      "{'loss': 2.148, 'grad_norm': 0.2523510754108429, 'learning_rate': 2.8445715356822606e-05, 'epoch': 0.68}\n",
      "{'loss': 2.124, 'grad_norm': 0.24947209656238556, 'learning_rate': 2.810837692135475e-05, 'epoch': 0.68}\n",
      "{'loss': 2.1428, 'grad_norm': 0.25635597109794617, 'learning_rate': 2.7772266826537103e-05, 'epoch': 0.68}\n",
      "{'loss': 2.1311, 'grad_norm': 0.24839040637016296, 'learning_rate': 2.7437403931532867e-05, 'epoch': 0.68}\n",
      "{'loss': 2.1207, 'grad_norm': 0.24948328733444214, 'learning_rate': 2.7103807025524764e-05, 'epoch': 0.69}\n",
      "{'loss': 2.1268, 'grad_norm': 0.24762208759784698, 'learning_rate': 2.677149482666078e-05, 'epoch': 0.69}\n",
      "{'loss': 2.1407, 'grad_norm': 0.25223860144615173, 'learning_rate': 2.644048598100388e-05, 'epoch': 0.69}\n",
      "{'loss': 2.1228, 'grad_norm': 0.24130664765834808, 'learning_rate': 2.61107990614858e-05, 'epoch': 0.69}\n",
      "{'loss': 2.1045, 'grad_norm': 0.2505090832710266, 'learning_rate': 2.578245256686488e-05, 'epoch': 0.7}\n",
      "{'loss': 2.0994, 'grad_norm': 0.24798257648944855, 'learning_rate': 2.5455464920688105e-05, 'epoch': 0.7}\n",
      "{'loss': 2.1104, 'grad_norm': 0.2468559741973877, 'learning_rate': 2.5129854470257397e-05, 'epoch': 0.7}\n",
      "{'loss': 2.1001, 'grad_norm': 0.24117116630077362, 'learning_rate': 2.4805639485600084e-05, 'epoch': 0.7}\n",
      "{'loss': 2.1288, 'grad_norm': 0.24626609683036804, 'learning_rate': 2.4482838158443882e-05, 'epoch': 0.7}\n",
      "{'loss': 2.0961, 'grad_norm': 0.2587791979312897, 'learning_rate': 2.4161468601195964e-05, 'epoch': 0.71}\n",
      "{'loss': 2.1634, 'grad_norm': 0.25304514169692993, 'learning_rate': 2.384154884592684e-05, 'epoch': 0.71}\n",
      "{'loss': 2.1366, 'grad_norm': 0.24242717027664185, 'learning_rate': 2.3523096843358573e-05, 'epoch': 0.71}\n",
      "{'loss': 2.1535, 'grad_norm': 0.248783141374588, 'learning_rate': 2.32061304618574e-05, 'epoch': 0.71}\n",
      "{'loss': 2.1376, 'grad_norm': 0.24935080111026764, 'learning_rate': 2.2890667486431293e-05, 'epoch': 0.71}\n",
      "{'loss': 2.1512, 'grad_norm': 0.2578819990158081, 'learning_rate': 2.257672561773207e-05, 'epoch': 0.72}\n",
      "{'loss': 2.1069, 'grad_norm': 0.25364649295806885, 'learning_rate': 2.2264322471061988e-05, 'epoch': 0.72}\n",
      "{'loss': 2.1175, 'grad_norm': 0.24655431509017944, 'learning_rate': 2.195347557538562e-05, 'epoch': 0.72}\n",
      "{'loss': 2.1368, 'grad_norm': 0.2503563165664673, 'learning_rate': 2.1644202372346113e-05, 'epoch': 0.72}\n",
      "{'loss': 2.1171, 'grad_norm': 0.2526448667049408, 'learning_rate': 2.133652021528661e-05, 'epoch': 0.73}\n",
      "{'loss': 2.1513, 'grad_norm': 0.24905060231685638, 'learning_rate': 2.1030446368276546e-05, 'epoch': 0.73}\n",
      "{'loss': 2.1504, 'grad_norm': 0.24610960483551025, 'learning_rate': 2.072599800514296e-05, 'epoch': 0.73}\n",
      "{'loss': 2.1378, 'grad_norm': 0.2534065246582031, 'learning_rate': 2.042319220850686e-05, 'epoch': 0.73}\n",
      "{'loss': 2.1345, 'grad_norm': 0.24027638137340546, 'learning_rate': 2.0122045968824723e-05, 'epoch': 0.73}\n",
      "{'loss': 2.1232, 'grad_norm': 0.24439364671707153, 'learning_rate': 1.982257618343515e-05, 'epoch': 0.74}\n",
      "{'loss': 2.1183, 'grad_norm': 0.25100165605545044, 'learning_rate': 1.9524799655610776e-05, 'epoch': 0.74}\n",
      "{'loss': 2.113, 'grad_norm': 0.23619677126407623, 'learning_rate': 1.922873309361542e-05, 'epoch': 0.74}\n",
      "{'loss': 2.1212, 'grad_norm': 0.2570075988769531, 'learning_rate': 1.893439310976659e-05, 'epoch': 0.74}\n",
      "{'loss': 2.1223, 'grad_norm': 0.2437722384929657, 'learning_rate': 1.8641796219503348e-05, 'epoch': 0.74}\n",
      "{'loss': 2.1453, 'grad_norm': 0.26268184185028076, 'learning_rate': 1.8350958840459666e-05, 'epoch': 0.75}\n",
      "{'loss': 2.1085, 'grad_norm': 0.25404515862464905, 'learning_rate': 1.8061897291543156e-05, 'epoch': 0.75}\n",
      "{'loss': 2.1483, 'grad_norm': 0.25877055525779724, 'learning_rate': 1.7774627792019565e-05, 'epoch': 0.75}\n",
      " 75%|██████████████████████████▎        | 3500/4661 [4:40:52<1:32:52,  4.80s/it][INFO|trainer.py:3993] 2025-06-23 14:31:46,955 >> Saving model checkpoint to llama3-3b_freeze_5per/checkpoint-3500\n",
      "[INFO|configuration_utils.py:424] 2025-06-23 14:31:46,956 >> Configuration saved in llama3-3b_freeze_5per/checkpoint-3500/config.json\n",
      "[INFO|configuration_utils.py:904] 2025-06-23 14:31:46,956 >> Configuration saved in llama3-3b_freeze_5per/checkpoint-3500/generation_config.json\n",
      "[INFO|modeling_utils.py:3733] 2025-06-23 14:31:50,927 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at llama3-3b_freeze_5per/checkpoint-3500/model.safetensors.index.json.\n",
      "[INFO|tokenization_utils_base.py:2356] 2025-06-23 14:31:50,928 >> chat template saved in llama3-3b_freeze_5per/checkpoint-3500/chat_template.jinja\n",
      "[INFO|tokenization_utils_base.py:2525] 2025-06-23 14:31:50,929 >> tokenizer config file saved in llama3-3b_freeze_5per/checkpoint-3500/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2534] 2025-06-23 14:31:50,929 >> Special tokens file saved in llama3-3b_freeze_5per/checkpoint-3500/special_tokens_map.json\n",
      "{'loss': 2.1154, 'grad_norm': 0.24813517928123474, 'learning_rate': 1.7489166460602495e-05, 'epoch': 0.75}\n",
      "{'loss': 2.1139, 'grad_norm': 0.24472762644290924, 'learning_rate': 1.720552931454915e-05, 'epoch': 0.76}\n",
      "{'loss': 2.095, 'grad_norm': 0.25677940249443054, 'learning_rate': 1.6923732268761595e-05, 'epoch': 0.76}\n",
      "{'loss': 2.1478, 'grad_norm': 0.24804295599460602, 'learning_rate': 1.6643791134893643e-05, 'epoch': 0.76}\n",
      "{'loss': 2.1245, 'grad_norm': 0.24379944801330566, 'learning_rate': 1.6365721620463786e-05, 'epoch': 0.76}\n",
      "{'loss': 2.1595, 'grad_norm': 0.24813926219940186, 'learning_rate': 1.6089539327973857e-05, 'epoch': 0.76}\n",
      "{'loss': 2.1352, 'grad_norm': 0.251045286655426, 'learning_rate': 1.5815259754033407e-05, 'epoch': 0.77}\n",
      "{'loss': 2.1311, 'grad_norm': 0.24807853996753693, 'learning_rate': 1.5542898288490427e-05, 'epoch': 0.77}\n",
      "{'loss': 2.1285, 'grad_norm': 0.25946730375289917, 'learning_rate': 1.527247021356763e-05, 'epoch': 0.77}\n",
      "{'loss': 2.1356, 'grad_norm': 0.25263097882270813, 'learning_rate': 1.5003990703004995e-05, 'epoch': 0.77}\n",
      "{'loss': 2.1182, 'grad_norm': 0.24668310582637787, 'learning_rate': 1.4737474821208513e-05, 'epoch': 0.77}\n",
      "{'loss': 2.1533, 'grad_norm': 0.24814477562904358, 'learning_rate': 1.4472937522404744e-05, 'epoch': 0.78}\n",
      "{'loss': 2.1701, 'grad_norm': 0.2611945867538452, 'learning_rate': 1.4210393649801779e-05, 'epoch': 0.78}\n",
      "{'loss': 2.1744, 'grad_norm': 0.25173550844192505, 'learning_rate': 1.3949857934756495e-05, 'epoch': 0.78}\n",
      "{'loss': 2.1111, 'grad_norm': 0.24945585429668427, 'learning_rate': 1.3691344995947818e-05, 'epoch': 0.78}\n",
      "{'loss': 2.1043, 'grad_norm': 0.2459116131067276, 'learning_rate': 1.3434869338556593e-05, 'epoch': 0.79}\n",
      "{'loss': 2.103, 'grad_norm': 0.24866051971912384, 'learning_rate': 1.318044535345162e-05, 'epoch': 0.79}\n",
      "{'loss': 2.1107, 'grad_norm': 0.2416074126958847, 'learning_rate': 1.2928087316382225e-05, 'epoch': 0.79}\n",
      "{'loss': 2.0779, 'grad_norm': 0.25532472133636475, 'learning_rate': 1.2677809387177219e-05, 'epoch': 0.79}\n",
      "{'loss': 2.1172, 'grad_norm': 0.25019514560699463, 'learning_rate': 1.2429625608950413e-05, 'epoch': 0.79}\n",
      "{'loss': 2.1137, 'grad_norm': 0.25089725852012634, 'learning_rate': 1.2183549907312625e-05, 'epoch': 0.8}\n",
      "{'loss': 2.1245, 'grad_norm': 0.24467048048973083, 'learning_rate': 1.1939596089590394e-05, 'epoch': 0.8}\n",
      "{'loss': 2.1361, 'grad_norm': 0.2470950484275818, 'learning_rate': 1.1697777844051105e-05, 'epoch': 0.8}\n",
      "{'loss': 2.1212, 'grad_norm': 0.25368815660476685, 'learning_rate': 1.145810873913506e-05, 'epoch': 0.8}\n",
      "{'loss': 2.1445, 'grad_norm': 0.24756565690040588, 'learning_rate': 1.1220602222694165e-05, 'epoch': 0.8}\n",
      "{'loss': 2.1236, 'grad_norm': 0.2609533965587616, 'learning_rate': 1.098527162123723e-05, 'epoch': 0.81}\n",
      "{'loss': 2.1515, 'grad_norm': 0.25830888748168945, 'learning_rate': 1.0752130139182365e-05, 'epoch': 0.81}\n",
      "{'loss': 2.1245, 'grad_norm': 0.2560253143310547, 'learning_rate': 1.0521190858116042e-05, 'epoch': 0.81}\n",
      "{'loss': 2.1661, 'grad_norm': 0.4974912106990814, 'learning_rate': 1.0292466736058987e-05, 'epoch': 0.81}\n",
      "{'loss': 2.1206, 'grad_norm': 0.24707941710948944, 'learning_rate': 1.0065970606739273e-05, 'epoch': 0.82}\n",
      "{'loss': 2.1195, 'grad_norm': 0.2548024654388428, 'learning_rate': 9.841715178872092e-06, 'epoch': 0.82}\n",
      "{'loss': 2.1121, 'grad_norm': 0.24038028717041016, 'learning_rate': 9.619713035446665e-06, 'epoch': 0.82}\n",
      "{'loss': 2.1394, 'grad_norm': 0.2432323396205902, 'learning_rate': 9.399976633020325e-06, 'epoch': 0.82}\n",
      "{'loss': 2.1308, 'grad_norm': 0.24841313064098358, 'learning_rate': 9.182518301019466e-06, 'epoch': 0.82}\n",
      "{'loss': 2.1257, 'grad_norm': 0.2476736456155777, 'learning_rate': 8.967350241047745e-06, 'epoch': 0.83}\n",
      "{'loss': 2.1335, 'grad_norm': 0.2482164353132248, 'learning_rate': 8.754484526201544e-06, 'epoch': 0.83}\n",
      "{'loss': 2.1099, 'grad_norm': 0.24642054736614227, 'learning_rate': 8.543933100392459e-06, 'epoch': 0.83}\n",
      "{'loss': 2.1513, 'grad_norm': 0.24317078292369843, 'learning_rate': 8.335707777677098e-06, 'epoch': 0.83}\n",
      "{'loss': 2.1273, 'grad_norm': 0.23895563185214996, 'learning_rate': 8.129820241594333e-06, 'epoch': 0.83}\n",
      "{'loss': 2.1135, 'grad_norm': 0.24797379970550537, 'learning_rate': 7.926282044509592e-06, 'epoch': 0.84}\n",
      "{'loss': 2.1095, 'grad_norm': 0.25386694073677063, 'learning_rate': 7.725104606966726e-06, 'epoch': 0.84}\n",
      "{'loss': 2.1452, 'grad_norm': 0.2474038153886795, 'learning_rate': 7.526299217047194e-06, 'epoch': 0.84}\n",
      "{'loss': 2.104, 'grad_norm': 0.24535544216632843, 'learning_rate': 7.329877029736665e-06, 'epoch': 0.84}\n",
      "{'loss': 2.0679, 'grad_norm': 0.24838286638259888, 'learning_rate': 7.135849066299144e-06, 'epoch': 0.85}\n",
      "{'loss': 2.1426, 'grad_norm': 0.24772538244724274, 'learning_rate': 6.944226213658533e-06, 'epoch': 0.85}\n",
      "{'loss': 2.1202, 'grad_norm': 0.24290579557418823, 'learning_rate': 6.755019223787806e-06, 'epoch': 0.85}\n",
      "{'loss': 2.116, 'grad_norm': 0.2466711401939392, 'learning_rate': 6.5682387131056676e-06, 'epoch': 0.85}\n",
      "{'loss': 2.1244, 'grad_norm': 0.25065961480140686, 'learning_rate': 6.38389516188091e-06, 'epoch': 0.85}\n",
      "{'loss': 2.1164, 'grad_norm': 0.2522112727165222, 'learning_rate': 6.201998913644319e-06, 'epoch': 0.86}\n",
      "{'loss': 2.1428, 'grad_norm': 0.24909278750419617, 'learning_rate': 6.0225601746083495e-06, 'epoch': 0.86}\n",
      " 86%|███████████████████████████████▊     | 4000/4661 [5:21:03<52:58,  4.81s/it][INFO|trainer.py:3993] 2025-06-23 15:11:57,661 >> Saving model checkpoint to llama3-3b_freeze_5per/checkpoint-4000\n",
      "[INFO|configuration_utils.py:424] 2025-06-23 15:11:57,662 >> Configuration saved in llama3-3b_freeze_5per/checkpoint-4000/config.json\n",
      "[INFO|configuration_utils.py:904] 2025-06-23 15:11:57,662 >> Configuration saved in llama3-3b_freeze_5per/checkpoint-4000/generation_config.json\n",
      "[INFO|modeling_utils.py:3733] 2025-06-23 15:12:07,590 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at llama3-3b_freeze_5per/checkpoint-4000/model.safetensors.index.json.\n",
      "[INFO|tokenization_utils_base.py:2356] 2025-06-23 15:12:07,590 >> chat template saved in llama3-3b_freeze_5per/checkpoint-4000/chat_template.jinja\n",
      "[INFO|tokenization_utils_base.py:2525] 2025-06-23 15:12:07,591 >> tokenizer config file saved in llama3-3b_freeze_5per/checkpoint-4000/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2534] 2025-06-23 15:12:07,591 >> Special tokens file saved in llama3-3b_freeze_5per/checkpoint-4000/special_tokens_map.json\n",
      "{'loss': 2.1076, 'grad_norm': 0.24793344736099243, 'learning_rate': 5.845589013094405e-06, 'epoch': 0.86}\n",
      "{'loss': 2.125, 'grad_norm': 0.24747490882873535, 'learning_rate': 5.671095358967926e-06, 'epoch': 0.86}\n",
      "{'loss': 2.1029, 'grad_norm': 0.25176867842674255, 'learning_rate': 5.499089003081259e-06, 'epoch': 0.86}\n",
      "{'loss': 2.107, 'grad_norm': 0.23680239915847778, 'learning_rate': 5.329579596724188e-06, 'epoch': 0.87}\n",
      "{'loss': 2.1289, 'grad_norm': 0.2556436061859131, 'learning_rate': 5.1625766510825404e-06, 'epoch': 0.87}\n",
      "{'loss': 2.1183, 'grad_norm': 0.2550743818283081, 'learning_rate': 4.9980895367043975e-06, 'epoch': 0.87}\n",
      "{'loss': 2.1354, 'grad_norm': 0.24582721292972565, 'learning_rate': 4.836127482974345e-06, 'epoch': 0.87}\n",
      "{'loss': 2.0946, 'grad_norm': 0.25083380937576294, 'learning_rate': 4.676699577595667e-06, 'epoch': 0.88}\n",
      "{'loss': 2.1019, 'grad_norm': 0.2532010078430176, 'learning_rate': 4.5198147660803605e-06, 'epoch': 0.88}\n",
      "{'loss': 2.1217, 'grad_norm': 0.2576945126056671, 'learning_rate': 4.36548185124721e-06, 'epoch': 0.88}\n",
      "{'loss': 2.1129, 'grad_norm': 0.2466059923171997, 'learning_rate': 4.21370949272793e-06, 'epoch': 0.88}\n",
      "{'loss': 2.1092, 'grad_norm': 0.24504202604293823, 'learning_rate': 4.064506206481195e-06, 'epoch': 0.88}\n",
      "{'loss': 2.1027, 'grad_norm': 0.2460263967514038, 'learning_rate': 3.91788036431483e-06, 'epoch': 0.89}\n",
      "{'loss': 2.1245, 'grad_norm': 0.2508507966995239, 'learning_rate': 3.7738401934161005e-06, 'epoch': 0.89}\n",
      "{'loss': 2.1202, 'grad_norm': 0.2472056746482849, 'learning_rate': 3.632393775890036e-06, 'epoch': 0.89}\n",
      "{'loss': 2.114, 'grad_norm': 0.25270363688468933, 'learning_rate': 3.4935490483059772e-06, 'epoch': 0.89}\n",
      "{'loss': 2.1381, 'grad_norm': 0.2534730136394501, 'learning_rate': 3.3573138012522375e-06, 'epoch': 0.89}\n",
      "{'loss': 2.1497, 'grad_norm': 0.24821406602859497, 'learning_rate': 3.22369567889898e-06, 'epoch': 0.9}\n",
      "{'loss': 2.114, 'grad_norm': 0.24748583137989044, 'learning_rate': 3.092702178569301e-06, 'epoch': 0.9}\n",
      "{'loss': 2.1063, 'grad_norm': 0.2542683482170105, 'learning_rate': 2.964340650318548e-06, 'epoch': 0.9}\n",
      "{'loss': 2.1091, 'grad_norm': 0.24399448931217194, 'learning_rate': 2.8386182965219223e-06, 'epoch': 0.9}\n",
      "{'loss': 2.1308, 'grad_norm': 0.2500523030757904, 'learning_rate': 2.715542171470342e-06, 'epoch': 0.91}\n",
      "{'loss': 2.143, 'grad_norm': 0.24125289916992188, 'learning_rate': 2.5951191809746144e-06, 'epoch': 0.91}\n",
      "{'loss': 2.1146, 'grad_norm': 0.2439519166946411, 'learning_rate': 2.477356081977983e-06, 'epoch': 0.91}\n",
      "{'loss': 2.1223, 'grad_norm': 0.24241042137145996, 'learning_rate': 2.3622594821769596e-06, 'epoch': 0.91}\n",
      "{'loss': 2.1236, 'grad_norm': 0.24490965902805328, 'learning_rate': 2.249835839650588e-06, 'epoch': 0.91}\n",
      "{'loss': 2.122, 'grad_norm': 0.25126582384109497, 'learning_rate': 2.140091462498084e-06, 'epoch': 0.92}\n",
      "{'loss': 2.1248, 'grad_norm': 0.24608521163463593, 'learning_rate': 2.033032508484861e-06, 'epoch': 0.92}\n",
      "{'loss': 2.1453, 'grad_norm': 0.2455442100763321, 'learning_rate': 1.9286649846970318e-06, 'epoch': 0.92}\n",
      "{'loss': 2.127, 'grad_norm': 0.24826863408088684, 'learning_rate': 1.8269947472043803e-06, 'epoch': 0.92}\n",
      "{'loss': 2.1106, 'grad_norm': 0.24749593436717987, 'learning_rate': 1.728027500731716e-06, 'epoch': 0.92}\n",
      "{'loss': 2.1318, 'grad_norm': 0.24562720954418182, 'learning_rate': 1.631768798338834e-06, 'epoch': 0.93}\n",
      "{'loss': 2.1077, 'grad_norm': 0.2428652048110962, 'learning_rate': 1.5382240411089155e-06, 'epoch': 0.93}\n",
      "{'loss': 2.1094, 'grad_norm': 0.2399684339761734, 'learning_rate': 1.447398477845463e-06, 'epoch': 0.93}\n",
      "{'loss': 2.1127, 'grad_norm': 0.25583615899086, 'learning_rate': 1.3592972047777874e-06, 'epoch': 0.93}\n",
      "{'loss': 2.0895, 'grad_norm': 0.24036850035190582, 'learning_rate': 1.2739251652750916e-06, 'epoch': 0.94}\n",
      "{'loss': 2.1402, 'grad_norm': 0.24725380539894104, 'learning_rate': 1.1912871495690592e-06, 'epoch': 0.94}\n",
      "{'loss': 2.1079, 'grad_norm': 0.25152283906936646, 'learning_rate': 1.1113877944850804e-06, 'epoch': 0.94}\n",
      "{'loss': 2.1307, 'grad_norm': 0.2462654858827591, 'learning_rate': 1.0342315831821103e-06, 'epoch': 0.94}\n",
      "{'loss': 2.1227, 'grad_norm': 0.24528099596500397, 'learning_rate': 9.598228449010704e-07, 'epoch': 0.94}\n",
      "{'loss': 2.128, 'grad_norm': 0.24786396324634552, 'learning_rate': 8.881657547219868e-07, 'epoch': 0.95}\n",
      "{'loss': 2.1398, 'grad_norm': 0.2452557384967804, 'learning_rate': 8.192643333296779e-07, 'epoch': 0.95}\n",
      "{'loss': 2.1082, 'grad_norm': 0.24267321825027466, 'learning_rate': 7.531224467881847e-07, 'epoch': 0.95}\n",
      "{'loss': 2.0915, 'grad_norm': 0.24953413009643555, 'learning_rate': 6.897438063238392e-07, 'epoch': 0.95}\n",
      "{'loss': 2.1228, 'grad_norm': 0.24316619336605072, 'learning_rate': 6.291319681170138e-07, 'epoch': 0.95}\n",
      "{'loss': 2.1178, 'grad_norm': 0.2480582296848297, 'learning_rate': 5.712903331026031e-07, 'epoch': 0.96}\n",
      "{'loss': 2.1057, 'grad_norm': 0.24838952720165253, 'learning_rate': 5.162221467791772e-07, 'epoch': 0.96}\n",
      "{'loss': 2.1131, 'grad_norm': 0.2550642788410187, 'learning_rate': 4.639304990269044e-07, 'epoch': 0.96}\n",
      "{'loss': 2.1378, 'grad_norm': 0.2441510260105133, 'learning_rate': 4.144183239341515e-07, 'epoch': 0.96}\n",
      "{'loss': 2.1184, 'grad_norm': 0.25069892406463623, 'learning_rate': 3.6768839963285394e-07, 'epoch': 0.97}\n",
      " 97%|███████████████████████████████████▋ | 4500/4661 [6:01:22<12:55,  4.81s/it][INFO|trainer.py:3993] 2025-06-23 15:52:17,171 >> Saving model checkpoint to llama3-3b_freeze_5per/checkpoint-4500\n",
      "[INFO|configuration_utils.py:424] 2025-06-23 15:52:17,172 >> Configuration saved in llama3-3b_freeze_5per/checkpoint-4500/config.json\n",
      "[INFO|configuration_utils.py:904] 2025-06-23 15:52:17,172 >> Configuration saved in llama3-3b_freeze_5per/checkpoint-4500/generation_config.json\n",
      "[INFO|modeling_utils.py:3733] 2025-06-23 15:52:21,165 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at llama3-3b_freeze_5per/checkpoint-4500/model.safetensors.index.json.\n",
      "[INFO|tokenization_utils_base.py:2356] 2025-06-23 15:52:21,165 >> chat template saved in llama3-3b_freeze_5per/checkpoint-4500/chat_template.jinja\n",
      "[INFO|tokenization_utils_base.py:2525] 2025-06-23 15:52:21,166 >> tokenizer config file saved in llama3-3b_freeze_5per/checkpoint-4500/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2534] 2025-06-23 15:52:21,166 >> Special tokens file saved in llama3-3b_freeze_5per/checkpoint-4500/special_tokens_map.json\n",
      "{'loss': 2.0866, 'grad_norm': 0.2472260743379593, 'learning_rate': 3.237433481426522e-07, 'epoch': 0.97}\n",
      "{'loss': 2.1368, 'grad_norm': 0.24779093265533447, 'learning_rate': 2.8258563522375883e-07, 'epoch': 0.97}\n",
      "{'loss': 2.1193, 'grad_norm': 0.2502764165401459, 'learning_rate': 2.4421757023859735e-07, 'epoch': 0.97}\n",
      "{'loss': 2.1202, 'grad_norm': 0.2781692445278168, 'learning_rate': 2.086413060222392e-07, 'epoch': 0.97}\n",
      "{'loss': 2.1198, 'grad_norm': 0.24316631257534027, 'learning_rate': 1.7585883876160002e-07, 'epoch': 0.98}\n",
      "{'loss': 2.1178, 'grad_norm': 0.24901053309440613, 'learning_rate': 1.4587200788343524e-07, 'epoch': 0.98}\n",
      "{'loss': 2.0878, 'grad_norm': 0.2436313033103943, 'learning_rate': 1.186824959511168e-07, 'epoch': 0.98}\n",
      "{'loss': 2.1062, 'grad_norm': 0.2516714334487915, 'learning_rate': 9.429182857025876e-08, 'epoch': 0.98}\n",
      "{'loss': 2.1194, 'grad_norm': 0.25670957565307617, 'learning_rate': 7.270137430306356e-08, 'epoch': 0.98}\n",
      "{'loss': 2.1317, 'grad_norm': 0.24591714143753052, 'learning_rate': 5.3912344591589e-08, 'epoch': 0.99}\n",
      "{'loss': 2.1256, 'grad_norm': 0.24614186584949493, 'learning_rate': 3.792579368972482e-08, 'epoch': 0.99}\n",
      "{'loss': 2.1133, 'grad_norm': 0.24985797703266144, 'learning_rate': 2.4742618604067792e-08, 'epoch': 0.99}\n",
      "{'loss': 2.0747, 'grad_norm': 0.25163188576698303, 'learning_rate': 1.436355904358977e-08, 'epoch': 0.99}\n",
      "{'loss': 2.137, 'grad_norm': 0.2440958172082901, 'learning_rate': 6.789197378115342e-09, 'epoch': 1.0}\n",
      "{'loss': 2.1108, 'grad_norm': 0.24486488103866577, 'learning_rate': 2.019958605659067e-09, 'epoch': 1.0}\n",
      "{'loss': 2.1106, 'grad_norm': 0.24872799217700958, 'learning_rate': 5.611032857788523e-11, 'epoch': 1.0}\n",
      "100%|█████████████████████████████████████| 4661/4661 [6:14:23<00:00,  4.58s/it][INFO|trainer.py:3993] 2025-06-23 16:05:17,864 >> Saving model checkpoint to llama3-3b_freeze_5per/checkpoint-4661\n",
      "[INFO|configuration_utils.py:424] 2025-06-23 16:05:17,865 >> Configuration saved in llama3-3b_freeze_5per/checkpoint-4661/config.json\n",
      "[INFO|configuration_utils.py:904] 2025-06-23 16:05:17,865 >> Configuration saved in llama3-3b_freeze_5per/checkpoint-4661/generation_config.json\n",
      "[INFO|modeling_utils.py:3733] 2025-06-23 16:05:22,030 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at llama3-3b_freeze_5per/checkpoint-4661/model.safetensors.index.json.\n",
      "[INFO|tokenization_utils_base.py:2356] 2025-06-23 16:05:22,031 >> chat template saved in llama3-3b_freeze_5per/checkpoint-4661/chat_template.jinja\n",
      "[INFO|tokenization_utils_base.py:2525] 2025-06-23 16:05:22,032 >> tokenizer config file saved in llama3-3b_freeze_5per/checkpoint-4661/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2534] 2025-06-23 16:05:22,032 >> Special tokens file saved in llama3-3b_freeze_5per/checkpoint-4661/special_tokens_map.json\n",
      "[INFO|trainer.py:2676] 2025-06-23 16:05:23,856 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "{'train_runtime': 22473.6413, 'train_samples_per_second': 6.636, 'train_steps_per_second': 0.207, 'train_loss': 2.160763274495424, 'epoch': 1.0}\n",
      "100%|█████████████████████████████████████| 4661/4661 [6:14:29<00:00,  4.82s/it]\n",
      "[INFO|trainer.py:3993] 2025-06-23 16:05:23,858 >> Saving model checkpoint to llama3-3b_freeze_5per\n",
      "[INFO|configuration_utils.py:424] 2025-06-23 16:05:23,859 >> Configuration saved in llama3-3b_freeze_5per/config.json\n",
      "[INFO|configuration_utils.py:904] 2025-06-23 16:05:23,859 >> Configuration saved in llama3-3b_freeze_5per/generation_config.json\n",
      "[INFO|modeling_utils.py:3733] 2025-06-23 16:05:27,926 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at llama3-3b_freeze_5per/model.safetensors.index.json.\n",
      "[INFO|tokenization_utils_base.py:2356] 2025-06-23 16:05:27,926 >> chat template saved in llama3-3b_freeze_5per/chat_template.jinja\n",
      "[INFO|tokenization_utils_base.py:2525] 2025-06-23 16:05:27,927 >> tokenizer config file saved in llama3-3b_freeze_5per/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2534] 2025-06-23 16:05:27,927 >> Special tokens file saved in llama3-3b_freeze_5per/special_tokens_map.json\n",
      "***** train metrics *****\n",
      "  epoch                    =          1.0\n",
      "  total_flos               = 4811087618GF\n",
      "  train_loss               =       2.1608\n",
      "  train_runtime            =   6:14:33.64\n",
      "  train_samples_per_second =        6.636\n",
      "  train_steps_per_second   =        0.207\n",
      "Figure saved at: llama3-3b_freeze_5per/training_loss.png\n",
      "[WARNING|2025-06-23 16:05:28] llamafactory.extras.ploting:148 >> No metric eval_loss to plot.\n",
      "[INFO|modelcard.py:450] 2025-06-23 16:05:28,066 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}\n"
     ]
    }
   ],
   "source": [
    "!llamafactory-cli train CPT_LayerFreezing_5per.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91076680",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "99106d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'LLaMA-Factory'\n",
      "/home/ai-research-lab/MCSProjectbyWajahatalibasharat5Percent/LLaMA-Factory\n"
     ]
    }
   ],
   "source": [
    "%cd LLaMA-Factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5a3b6b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPT_Lora_and_layerFreezing.ipynb  key  key.pub\tLLaMA-Factory  README.md\n"
     ]
    }
   ],
   "source": [
    "!ls /home/ai-research-lab/MCSProjectbyWajahatalibasharat5Percent/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c98c5cef",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'llamafactory'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgc\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mllamafactory\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatModel\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtorch_gc\u001b[39m():\n\u001b[1;32m      6\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Clean up GPU memory.\"\"\"\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'llamafactory'"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import torch\n",
    "from llamafactory.chat import ChatModel\n",
    "\n",
    "def torch_gc():\n",
    "    \"\"\"Clean up GPU memory.\"\"\"\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "def init_model(model_path: str, template: str, quant_bit: int) -> ChatModel:\n",
    "    \"\"\"Instantiate the chat model with minimal retries.\"\"\"\n",
    "    args = {\n",
    "        \"model_name_or_path\": model_path,\n",
    "        \"template\": template,\n",
    "        \"quantization_bit\": quant_bit,\n",
    "        # \"flash_attn\": True,  # Uncomment if supported and benchmarks show improvement\n",
    "    }\n",
    "    print(\"Initializing model…\", end=\" \", flush=True)\n",
    "    try:\n",
    "        model = ChatModel(args)\n",
    "        print(\"✅\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(\"❌\")\n",
    "        raise RuntimeError(f\"Failed to load model: {e}\") from e\n",
    "\n",
    "def process_query(chat_model: ChatModel, messages: list, query: str) -> tuple[bool, str]:\n",
    "    \"\"\"Handle special commands or stream a response from the model.\"\"\"\n",
    "    cmd = query.strip().lower()\n",
    "    if cmd == \"exit\":\n",
    "        return False, \"Exiting…\"\n",
    "    if cmd == \"clear\":\n",
    "        messages.clear()\n",
    "        torch_gc()\n",
    "        return True, \"🗑️ Conversation history cleared\"\n",
    "\n",
    "    # Regular user message\n",
    "    messages.append({\"role\": \"user\", \"content\": query})\n",
    "    print(\"Assistant: \", end=\"\", flush=True)\n",
    "\n",
    "    response = []\n",
    "    try:\n",
    "        for chunk in chat_model.stream_chat(messages):\n",
    "            print(chunk, end=\"\", flush=True)\n",
    "            response.append(chunk)\n",
    "    except Exception as e:\n",
    "        return True, f\"⚠️ Error during generation: {e}\"\n",
    "\n",
    "    reply = \"\".join(response)\n",
    "    print()  # newline after completion\n",
    "    messages.append({\"role\": \"assistant\", \"content\": reply})\n",
    "    return True, \"\"\n",
    "\n",
    "def main():\n",
    "    # Initial cleanup\n",
    "    torch_gc()\n",
    "\n",
    "    model_path = \"/home/ai-research-lab/MCSProjectbyWajahatalibasharat5Percent/LLaMA-Factory/llama3-3b_freeze_5per\"\n",
    "    chat_model = init_model(model_path, template=\"llama3\", quant_bit=8)\n",
    "\n",
    "    messages: list[dict] = []\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Welcome to LLaMA Chat Interface!\")\n",
    "    print(\"Commands:\")\n",
    "    print(\"- Type 'clear' to reset conversation history\")\n",
    "    print(\"- Type 'exit' to end the session\")\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            query = input(\"User: \")\n",
    "            cont, out = process_query(chat_model, messages, query)\n",
    "            if out:\n",
    "                print(out)\n",
    "            if not cont:\n",
    "                break\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n🛑 Session interrupted by user\")\n",
    "    finally:\n",
    "        torch_gc()\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"Session ended. GPU resources freed.\")\n",
    "        print(\"=\"*50)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e296b50",
   "metadata": {},
   "source": [
    "## Merging with unfrozen layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3454a523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/content/LLaMA-Factory/'\n",
      "/home/ai-research-lab/MCSProjectbyWajahatalibasharat5Percent/LLaMA-Factory\n",
      "[INFO|tokenization_utils_base.py:2021] 2025-06-23 16:08:25,558 >> loading file tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2021] 2025-06-23 16:08:25,558 >> loading file tokenizer.model\n",
      "[INFO|tokenization_utils_base.py:2021] 2025-06-23 16:08:25,558 >> loading file added_tokens.json\n",
      "[INFO|tokenization_utils_base.py:2021] 2025-06-23 16:08:25,558 >> loading file special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2021] 2025-06-23 16:08:25,558 >> loading file tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2021] 2025-06-23 16:08:25,558 >> loading file chat_template.jinja\n",
      "[INFO|tokenization_utils_base.py:2299] 2025-06-23 16:08:25,790 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "[INFO|configuration_utils.py:696] 2025-06-23 16:08:25,790 >> loading configuration file llama3-3b_freeze_5per/config.json\n",
      "[INFO|configuration_utils.py:770] 2025-06-23 16:08:25,794 >> Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128008,\n",
      "    128009\n",
      "  ],\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 131072,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 24,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": {\n",
      "    \"factor\": 32.0,\n",
      "    \"high_freq_factor\": 4.0,\n",
      "    \"low_freq_factor\": 1.0,\n",
      "    \"original_max_position_embeddings\": 8192,\n",
      "    \"rope_type\": \"llama3\"\n",
      "  },\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": false,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2021] 2025-06-23 16:08:25,795 >> loading file tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2021] 2025-06-23 16:08:25,795 >> loading file tokenizer.model\n",
      "[INFO|tokenization_utils_base.py:2021] 2025-06-23 16:08:25,795 >> loading file added_tokens.json\n",
      "[INFO|tokenization_utils_base.py:2021] 2025-06-23 16:08:25,795 >> loading file special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2021] 2025-06-23 16:08:25,795 >> loading file tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2021] 2025-06-23 16:08:25,795 >> loading file chat_template.jinja\n",
      "[INFO|tokenization_utils_base.py:2299] 2025-06-23 16:08:26,039 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "[INFO|2025-06-23 16:08:26] llamafactory.data.template:143 >> Add <|eom_id|> to stop words.\n",
      "[INFO|configuration_utils.py:696] 2025-06-23 16:08:26,056 >> loading configuration file llama3-3b_freeze_5per/config.json\n",
      "[INFO|configuration_utils.py:770] 2025-06-23 16:08:26,057 >> Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128008,\n",
      "    128009\n",
      "  ],\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 131072,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 24,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": {\n",
      "    \"factor\": 32.0,\n",
      "    \"high_freq_factor\": 4.0,\n",
      "    \"low_freq_factor\": 1.0,\n",
      "    \"original_max_position_embeddings\": 8192,\n",
      "    \"rope_type\": \"llama3\"\n",
      "  },\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": false,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "[INFO|2025-06-23 16:08:26] llamafactory.model.model_utils.kv_cache:143 >> KV cache is enabled for faster generation.\n",
      "[INFO|modeling_utils.py:1148] 2025-06-23 16:08:26,193 >> loading weights file llama3-3b_freeze_5per/model.safetensors.index.json\n",
      "[INFO|modeling_utils.py:2241] 2025-06-23 16:08:26,193 >> Instantiating LlamaForCausalLM model under default dtype torch.bfloat16.\n",
      "[INFO|configuration_utils.py:1135] 2025-06-23 16:08:26,194 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128008,\n",
      "    128009\n",
      "  ]\n",
      "}\n",
      "\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:00<00:00, 24.26it/s]\n",
      "[INFO|modeling_utils.py:5131] 2025-06-23 16:08:26,288 >> All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
      "\n",
      "[INFO|modeling_utils.py:5139] 2025-06-23 16:08:26,288 >> All the weights of LlamaForCausalLM were initialized from the model checkpoint at llama3-3b_freeze_5per.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
      "[INFO|configuration_utils.py:1088] 2025-06-23 16:08:26,289 >> loading configuration file llama3-3b_freeze_5per/generation_config.json\n",
      "[INFO|configuration_utils.py:1135] 2025-06-23 16:08:26,289 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"do_sample\": true,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128008,\n",
      "    128009\n",
      "  ],\n",
      "  \"temperature\": 0.6,\n",
      "  \"top_p\": 0.9\n",
      "}\n",
      "\n",
      "[INFO|2025-06-23 16:08:26] llamafactory.model.model_utils.attention:143 >> Using torch SDPA for faster training and inference.\n",
      "[INFO|2025-06-23 16:08:26] llamafactory.model.loader:143 >> all params: 3,212,749,824\n",
      "[INFO|2025-06-23 16:08:26] llamafactory.train.tuner:143 >> Convert model dtype to: torch.bfloat16.\n",
      "[INFO|configuration_utils.py:424] 2025-06-23 16:08:26,294 >> Configuration saved in llama3_freeze_merged_5per/config.json\n",
      "[INFO|configuration_utils.py:904] 2025-06-23 16:08:26,295 >> Configuration saved in llama3_freeze_merged_5per/generation_config.json\n",
      "[INFO|modeling_utils.py:3733] 2025-06-23 16:08:28,722 >> The model is bigger than the maximum size per checkpoint (2GB) and is going to be split in 4 checkpoint shards. You can find where each parameters has been saved in the index located at llama3_freeze_merged_5per/model.safetensors.index.json.\n",
      "[INFO|configuration_utils.py:424] 2025-06-23 16:08:29,665 >> Configuration saved in llama3-3b_freeze_5per/config.json\n",
      "[INFO|configuration_utils.py:904] 2025-06-23 16:08:29,665 >> Configuration saved in llama3-3b_freeze_5per/generation_config.json\n",
      "[INFO|modeling_utils.py:3733] 2025-06-23 16:08:32,064 >> The model is bigger than the maximum size per checkpoint (2GB) and is going to be split in 4 checkpoint shards. You can find where each parameters has been saved in the index located at llama3-3b_freeze_5per/model.safetensors.index.json.\n",
      "[INFO|hub.py:827] 2025-06-23 16:08:34,649 >> Uploading the following files to wbasharat/llama3-3b_freeze_5per: model.safetensors.index.json,model-00002-of-00004.safetensors,generation_config.json,model-00001-of-00004.safetensors,model-00004-of-00004.safetensors,README.md,model-00003-of-00004.safetensors,config.json\n",
      "Uploading...: 100%|████████████████████████| 6.43G/6.43G [05:15<00:00, 20.4MB/s]\n",
      "[INFO|tokenization_utils_base.py:2356] 2025-06-23 16:13:52,725 >> chat template saved in llama3_freeze_merged_5per/chat_template.jinja\n",
      "[INFO|tokenization_utils_base.py:2525] 2025-06-23 16:13:52,726 >> tokenizer config file saved in llama3_freeze_merged_5per/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2534] 2025-06-23 16:13:52,726 >> Special tokens file saved in llama3_freeze_merged_5per/special_tokens_map.json\n",
      "README.md: 100%|███████████████████████████| 5.19k/5.19k [00:00<00:00, 48.7MB/s]\n",
      "[INFO|tokenization_utils_base.py:2356] 2025-06-23 16:13:53,618 >> chat template saved in llama3-3b_freeze_5per/chat_template.jinja\n",
      "[INFO|tokenization_utils_base.py:2525] 2025-06-23 16:13:53,620 >> tokenizer config file saved in llama3-3b_freeze_5per/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2534] 2025-06-23 16:13:53,620 >> Special tokens file saved in llama3-3b_freeze_5per/special_tokens_map.json\n",
      "[INFO|hub.py:827] 2025-06-23 16:13:53,740 >> Uploading the following files to wbasharat/llama3-3b_freeze_5per: special_tokens_map.json,tokenizer_config.json,chat_template.jinja,tokenizer.json,README.md\n",
      "Uploading...: 100%|████████████████████████| 17.2M/17.2M [00:02<00:00, 7.16MB/s]\n",
      "[INFO|2025-06-23 16:13:58] llamafactory.train.tuner:143 >> Ollama modelfile saved in llama3_freeze_merged_5per/Modelfile\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "args = dict(\n",
    "  model_name_or_path=\"llama3-3b_freeze_5per\",                # use official non-quantized Llama-3-8B-Instruct model                      # load the saved LoRA adapters\n",
    "  template=\"llama3\",                                        # same to the one in training\n",
    "  finetuning_type=\"freeze\",                                   # same to the one in training\n",
    "  export_dir=\"llama3_freeze_merged_5per\",                          # the path to save the merged model\n",
    "  export_size=2,                                            # the file shard size (in GB) of the merged model\n",
    "  export_device=\"cpu\",                                      # the device used in export, can be chosen from `cpu` and `auto`\n",
    "  export_hub_model_id=\"wbasharat/llama3-3b_freeze_5per\",               # the Hugging Face hub ID to upload model\n",
    ")\n",
    "json.dump(args, open(\"merged_5Per_freeze_llama3.json\", \"w\", encoding=\"utf-8\"), indent=2)\n",
    "\n",
    "%cd /content/LLaMA-Factory/\n",
    "\n",
    "!llamafactory-cli export merged_5Per_freeze_llama3.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20051170",
   "metadata": {},
   "source": [
    "## CPT Using Lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8e26751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ai-research-lab/MCSProjectbyWajahatalibasharat5Percent/LLaMA-Factory\n"
     ]
    }
   ],
   "source": [
    "%cd LLaMA-Factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0505cd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Define the arguments for training\n",
    "args = dict(\n",
    "    # Model settings\n",
    "    model_name_or_path=\"meta-llama/LLaMA-3.2-3B-Instruct\",\n",
    "    trust_remote_code=True,\n",
    "\n",
    "    # Training method\n",
    "    stage=\"pt\",\n",
    "    do_train=True,\n",
    "    finetuning_type=\"lora\",\n",
    "    lora_rank=32,\n",
    "    lora_target=\"all\",\n",
    "\n",
    "    # Dataset settings\n",
    "    dataset=\"wiki_5percent,markdown_docs\",\n",
    "    cutoff_len=2048,\n",
    "    # max_samples=1000,\n",
    "    overwrite_cache=True,\n",
    "    preprocessing_num_workers=16,\n",
    "    dataloader_num_workers=4,\n",
    "\n",
    "    # Output and checkpointing\n",
    "    output_dir=\"llama3-3b_lora_pretrain\",\n",
    "    logging_steps=10,\n",
    "    save_steps=500,\n",
    "    plot_loss=True,\n",
    "    overwrite_output_dir=False,  # <--- CRUCIAL CHANGE: Set to False to allow resuming\n",
    "    save_only_model=False,\n",
    "    report_to=\"none\",\n",
    "\n",
    "    # Optimizer and schedule\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=8,\n",
    "    learning_rate=1.0e-4,\n",
    "    num_train_epochs=1.0,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_ratio=0.1,\n",
    "\n",
    "    # Precision and device\n",
    "    bf16=True,\n",
    "\n",
    "    # Distributed training timeout\n",
    "    ddp_timeout=18000,\n",
    "\n",
    "    # Resume checkpoint - this will be set dynamically\n",
    "    resume_from_checkpoint=None,\n",
    "\n",
    "    # Eval settings (currently disabled)\n",
    "    # eval_dataset=\"c4_demo\",\n",
    "    # val_size=0.1,\n",
    "    # per_device_eval_batch_size=1,\n",
    "    # eval_strategy=\"steps\",\n",
    "    # eval_steps=500,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a148fd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Logic to find and set the latest checkpoint for resuming ---\n",
    "checkpoint_dir = args[\"output_dir\"]\n",
    "latest_checkpoint = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb67ab30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming from checkpoint: llama3-3b_lora_pretrain/checkpoint-1000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check if the output directory exists\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    # This assumes checkpoints are saved in subdirectories like \"checkpoint-XXXX\"\n",
    "    # within the output_dir. Adjust this logic if your checkpoint saving\n",
    "    # structure is different.\n",
    "    checkpoints = [d for d in os.listdir(checkpoint_dir) if d.startswith(\"checkpoint-\")]\n",
    "    if checkpoints:\n",
    "        # Sort checkpoints numerically to find the latest one\n",
    "        checkpoints.sort(key=lambda x: int(x.split(\"-\")[1]))\n",
    "        latest_checkpoint = os.path.join(checkpoint_dir, checkpoints[-1])\n",
    "\n",
    "if latest_checkpoint:\n",
    "    args[\"resume_from_checkpoint\"] = latest_checkpoint\n",
    "    print(f\"Resuming from checkpoint: {args['resume_from_checkpoint']}\")\n",
    "else:\n",
    "    print(\"No checkpoint found in the output directory. Starting training from scratch.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5e77bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configuration saved to CPT_LoRA_5per.json:\n",
      "{\n",
      "  \"model_name_or_path\": \"meta-llama/LLaMA-3.2-3B-Instruct\",\n",
      "  \"trust_remote_code\": true,\n",
      "  \"stage\": \"pt\",\n",
      "  \"do_train\": true,\n",
      "  \"finetuning_type\": \"lora\",\n",
      "  \"lora_rank\": 32,\n",
      "  \"lora_target\": \"all\",\n",
      "  \"dataset\": \"wiki_5percent,markdown_docs\",\n",
      "  \"cutoff_len\": 2048,\n",
      "  \"overwrite_cache\": true,\n",
      "  \"preprocessing_num_workers\": 16,\n",
      "  \"dataloader_num_workers\": 4,\n",
      "  \"output_dir\": \"llama3-3b_lora_pretrain\",\n",
      "  \"logging_steps\": 10,\n",
      "  \"save_steps\": 500,\n",
      "  \"plot_loss\": true,\n",
      "  \"overwrite_output_dir\": false,\n",
      "  \"save_only_model\": false,\n",
      "  \"report_to\": \"none\",\n",
      "  \"per_device_train_batch_size\": 1,\n",
      "  \"gradient_accumulation_steps\": 8,\n",
      "  \"learning_rate\": 0.0001,\n",
      "  \"num_train_epochs\": 1.0,\n",
      "  \"lr_scheduler_type\": \"cosine\",\n",
      "  \"warmup_ratio\": 0.1,\n",
      "  \"bf16\": true,\n",
      "  \"ddp_timeout\": 18000,\n",
      "  \"resume_from_checkpoint\": \"llama3-3b_lora_pretrain/checkpoint-1000\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Save the updated arguments to a JSON file\n",
    "config_file_name = \"CPT_LoRA_5per.json\"\n",
    "with open(config_file_name, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(args, f, indent=2)\n",
    "\n",
    "print(f\"\\nConfiguration saved to {config_file_name}:\")\n",
    "print(json.dumps(args, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea38612c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running training with: llamafactory-cli train CPT_LoRA_5per.json\n",
      "[INFO|2025-06-24 11:17:18] llamafactory.cli:143 >> Initializing 2 distributed tasks at: 127.0.0.1:58459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0624 11:17:18.717000 19301 site-packages/torch/distributed/run.py:766] \n",
      "W0624 11:17:18.717000 19301 site-packages/torch/distributed/run.py:766] *****************************************\n",
      "W0624 11:17:18.717000 19301 site-packages/torch/distributed/run.py:766] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0624 11:17:18.717000 19301 site-packages/torch/distributed/run.py:766] *****************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|2025-06-24 11:17:21] llamafactory.hparams.parser:143 >> Set `ddp_find_unused_parameters` to False in DDP training since LoRA is enabled.\n",
      "[INFO|2025-06-24 11:17:21] llamafactory.hparams.parser:406 >> Process rank: 0, world size: 2, device: cuda:0, distributed training: True, compute dtype: torch.bfloat16\n",
      "[INFO|2025-06-24 11:17:21] llamafactory.hparams.parser:406 >> Process rank: 1, world size: 2, device: cuda:1, distributed training: True, compute dtype: torch.bfloat16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|tokenization_utils_base.py:2023] 2025-06-24 11:18:26,125 >> loading file tokenizer.json from cache at /home/ai-research-lab/.cache/huggingface/hub/models--meta-llama--LLaMA-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2023] 2025-06-24 11:18:26,125 >> loading file tokenizer.model from cache at None\n",
      "[INFO|tokenization_utils_base.py:2023] 2025-06-24 11:18:26,125 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2023] 2025-06-24 11:18:26,125 >> loading file special_tokens_map.json from cache at /home/ai-research-lab/.cache/huggingface/hub/models--meta-llama--LLaMA-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2023] 2025-06-24 11:18:26,125 >> loading file tokenizer_config.json from cache at /home/ai-research-lab/.cache/huggingface/hub/models--meta-llama--LLaMA-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2023] 2025-06-24 11:18:26,125 >> loading file chat_template.jinja from cache at None\n",
      "[INFO|tokenization_utils_base.py:2299] 2025-06-24 11:18:26,323 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "[INFO|configuration_utils.py:698] 2025-06-24 11:19:26,774 >> loading configuration file config.json from cache at /home/ai-research-lab/.cache/huggingface/hub/models--meta-llama--LLaMA-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95/config.json\n",
      "[INFO|configuration_utils.py:770] 2025-06-24 11:19:26,776 >> Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128008,\n",
      "    128009\n",
      "  ],\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 131072,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 24,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": {\n",
      "    \"factor\": 32.0,\n",
      "    \"high_freq_factor\": 4.0,\n",
      "    \"low_freq_factor\": 1.0,\n",
      "    \"original_max_position_embeddings\": 8192,\n",
      "    \"rope_type\": \"llama3\"\n",
      "  },\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "/home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "  warnings.warn(  # warn only once\n",
      "[rank1]:[W624 11:20:18.696198490 ProcessGroupNCCL.cpp:4718] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.\n",
      "[INFO|tokenization_utils_base.py:2023] 2025-06-24 11:20:27,446 >> loading file tokenizer.json from cache at /home/ai-research-lab/.cache/huggingface/hub/models--meta-llama--LLaMA-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2023] 2025-06-24 11:20:27,446 >> loading file tokenizer.model from cache at None\n",
      "[INFO|tokenization_utils_base.py:2023] 2025-06-24 11:20:27,446 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2023] 2025-06-24 11:20:27,446 >> loading file special_tokens_map.json from cache at /home/ai-research-lab/.cache/huggingface/hub/models--meta-llama--LLaMA-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2023] 2025-06-24 11:20:27,446 >> loading file tokenizer_config.json from cache at /home/ai-research-lab/.cache/huggingface/hub/models--meta-llama--LLaMA-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2023] 2025-06-24 11:20:27,446 >> loading file chat_template.jinja from cache at None\n",
      "[INFO|tokenization_utils_base.py:2299] 2025-06-24 11:20:27,647 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING|2025-06-24 11:20:27] llamafactory.data.template:148 >> `template` was not specified, try parsing the chat template from the tokenizer.\n",
      "[INFO|2025-06-24 11:20:27] llamafactory.data.template:143 >> Add pad token: <|eot_id|>\n",
      "[INFO|2025-06-24 11:20:27] llamafactory.data.loader:143 >> Loading dataset wiki_5percent.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting format of dataset (num_proc=16): 100%|██████████| 320390/320390 [00:01<00:00, 249776.22 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|2025-06-24 11:20:29] llamafactory.data.loader:143 >> Loading dataset markdown_docs.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting format of dataset (num_proc=16): 100%|██████████| 37/37 [00:00<00:00, 372.78 examples/s]\n",
      "/home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "  warnings.warn(  # warn only once\n",
      "[rank0]:[W624 11:20:30.621933271 ProcessGroupNCCL.cpp:4718] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.\n",
      "Running tokenizer on dataset (num_proc=16): 100%|██████████| 320427/320427 [00:40<00:00, 7978.29 examples/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training example:\n",
      "input_ids:\n",
      "[2127, 1132, 2191, 374, 264, 5054, 19675, 323, 7351, 430, 374, 44929, 315, 682, 1120, 7174, 369, 11447, 323, 26737, 311, 90376, 279, 14673, 433, 8349, 10519, 26225, 78242, 323, 30022, 11, 11383, 2737, 7140, 90160, 11, 323, 32682, 13, 1556, 1132, 2191, 28424, 369, 279, 14039, 315, 279, 1614, 449, 1614, 1752, 34775, 323, 37079, 1949, 30257, 13, 1666, 264, 35901, 2163, 29480, 7351, 11, 420, 5403, 315, 44565, 2191, 374, 9277, 389, 279, 3117, 61943, 2163, 315, 279, 5054, 20326, 11, 6118, 7633, 439, 279, 57125, 20611, 315, 279, 41289, 7351, 320, 2808, 531, 8997, 51618, 3677, 95668, 617, 12439, 304, 34775, 2085, 16287, 12694, 1132, 552, 1317, 1603, 279, 21967, 315, 5415, 11, 77563, 11, 477, 991, 19505, 13, 3161, 279, 10205, 315, 39433, 70994, 13162, 11, 67451, 42914, 9017, 11447, 1101, 16392, 13, 10541, 35483, 315, 78431, 6848, 527, 1766, 682, 6957, 3925, 11, 6617, 44565, 2191, 22763, 505, 279, 92931, 13, 12220, 279, 15629, 4376, 315, 279, 220, 777, 339, 323, 279, 1176, 11026, 315, 279, 220, 508, 339, 9478, 11, 279, 78431, 7351, 20415, 3384, 304, 1455, 5596, 315, 279, 1917, 323, 1047, 264, 5199, 3560, 304, 7487, 6, 28970, 369, 91225, 49686, 13, 40741, 78431, 8853, 315, 3463, 14454, 2391, 420, 4261, 13, 1556, 1132, 1705, 617, 4529, 961, 304, 3892, 93574, 11, 1455, 35146, 304, 279, 12366, 6947, 2957, 11, 279, 8690, 16803, 5111, 323, 279, 15506, 16803, 5111, 11, 6832, 842, 13160, 279, 842, 315, 279, 29924, 11639, 315, 44565, 2191, 13, 763, 279, 1566, 11026, 315, 279, 220, 508, 339, 323, 1139, 279, 220, 1691, 267, 9478, 11, 279, 78431, 7351, 706, 1027, 594, 86153, 3131, 810, 11, 7982, 304, 23354, 323, 10383, 2949, 7294, 98231, 380, 11, 7294, 48260, 323, 7294, 74419, 8082, 19567, 382, 2127, 1132, 1705, 3539, 17226, 20414, 11, 902, 1253, 387, 8965, 18255, 1139, 30191, 323, 41993, 15174, 26, 1070, 374, 5199, 28347, 1990, 279, 1403, 13, 38321, 661, 5528, 1456, 311, 38553, 1148, 459, 78431, 8396, 2643, 387, 1093, 11, 719, 30191, 26411, 11, 902, 617, 35901, 4529, 264, 16806, 2543, 11, 9395, 311, 63331, 11447, 323, 279, 1614, 13, 9176, 62814, 315, 3823, 36017, 617, 1027, 28160, 555, 78431, 10334, 11, 43665, 11, 323, 550, 7332, 382, 32960, 99174, 11, 57726, 11, 323, 7419, 4815, 791, 1880, 1631, 5848, 6371, 315, 44565, 2191, 374, 505, 279, 38050, 18341, 459, 847, 71, 689, 11, 7438, 330, 30096, 264, 49080, 498, 24306, 315, 279, 9436, 459, 12, 3573, 30096, 909, 323, 279, 3492, 802, 31764, 437, 3573, 38491, 1, 477, 330, 81, 8646, 1865, 578, 21166, 482, 2191, 72214, 279, 42933, 1510, 430, 9428, 2530, 459, 15630, 13, 1556, 1132, 2191, 8111, 304, 6498, 505, 220, 10513, 17, 439, 44565, 44618, 323, 459, 15630, 505, 220, 9800, 24, 26, 4216, 6498, 603, 1154, 20654, 4147, 264, 5647, 315, 19823, 13, 40741, 48752, 2949, 279, 8753, 22910, 61336, 872, 19949, 439, 93134, 11, 8051, 2478, 1778, 13487, 6222, 1690, 6325, 449, 3010, 93134, 13, 9176, 14110, 5548, 315, 279, 220, 777, 339, 9478, 1778, 439, 12656, 4359, 7678, 320, 10005, 21, 4235, 10750, 21, 8, 323, 93537, 1226, 275, 2785, 320, 5245, 23, 4235, 9674, 16, 8, 1053, 17210, 311, 279, 78431, 83258, 315, 279, 1828, 9659, 719, 1550, 539, 1005, 78431, 477, 44565, 2191, 304, 23524, 5694, 477, 872, 21463, 382, 791, 1176, 5054, 55475, 311, 1650, 5678, 459, 78431, 1754, 574, 38077, 12278, 974, 764, 393, 583, 31721, 263, 320, 5245, 24, 4235, 9714, 20, 705, 36024, 279, 16287, 7342, 315, 44565, 2191, 304, 279, 5209, 12, 777, 339, 9478, 13, 8876, 279, 220, 9378, 15, 82, 323, 7314, 304, 9822, 11, 57125, 2191, 706, 3629, 1027, 1511, 439, 264, 74450, 369, 44565, 2191, 323, 1202, 1005, 439, 264, 74450, 374, 2103, 4279, 4994, 279, 3723, 4273, 13, 4427, 603, 1154, 315, 57125, 2191, 8464, 311, 3927, 4633, 1949, 48831, 19675, 1193, 11, 323, 1949, 48831, 44565, 2191, 304, 4040, 374, 61937, 57125, 44565, 2191, 382, 8142, 279, 4751, 57125, 706, 1027, 14090, 69593, 449, 44565, 2191, 11, 1202, 7438, 706, 810, 6051, 1027, 80703, 555, 22622, 25375, 505, 2679, 30450, 85129, 5315, 11, 2737, 2225, 279, 1561, 14043, 323, 57125, 28187, 1705, 11, 889, 656, 539, 22712, 5694, 449, 59021, 3674, 1705, 477, 264, 348, 53290, 4717, 11, 323, 14560, 13042, 45750, 11, 889, 527, 15871, 11920, 449, 8431, 58455, 13, 23212, 11, 1063, 93134, 1005, 57125, 41289, 311, 5766, 44565, 2191, 596, 8389, 390, 14632, 323, 20654, 1082, 1202, 13537, 449, 51618, 13, 1556, 1132, 2191, 374, 44029, 1511, 311, 7664, 279, 7294, 43802, 20631, 20611, 315, 279, 41289, 7351, 13, 1556, 1132, 2191, 374, 13168, 291, 311, 41289, 7739, 902, 527, 1614, 36185, 477, 505, 3485, 13, 99394, 315, 44565, 2191, 8965, 11415, 44565, 2191, 596, 41289, 16792, 323, 9940, 1082, 13865, 520, 6968, 29953, 354, 316, 552, 1990, 279, 1403, 13, 4427, 31839, 7664, 44565, 2191, 439, 3515, 1690, 34453, 505, 84581, 11, 323, 1694, 2225, 18250, 323, 41289, 719, 810, 779, 13, 9176, 31839, 8007, 459, 277, 971, 98231, 2191, 439, 264, 70847, 315, 78431, 16565, 382, 8142, 14076, 311, 279, 1614, 374, 8792, 311, 78431, 3463, 11, 27409, 44565, 2191, 374, 539, 459, 4228, 3465, 369, 31839, 11, 439, 1070, 374, 264, 2763, 315, 10430, 4315, 31839, 323, 93134, 389, 279, 5030, 11, 323, 5370, 60701, 45493, 44565, 2191, 10284, 22009, 13, 17559, 36222, 3079, 5540, 2997, 279, 690, 369, 264, 2536, 23283, 3035, 535, 8396, 11, 279, 38001, 315, 279, 1614, 41705, 11, 279, 16801, 430, 3823, 7138, 6276, 12966, 311, 3073, 304, 477, 5208, 9017, 1778, 264, 2536, 23283, 3035, 535, 8396, 11, 323, 264, 24710, 389, 1268, 311, 1180, 311, 23564, 279, 10728, 315, 459, 15630, 382, 13730, 271, 4808, 17515, 944, 11639, 4815, 10438, 279, 9886, 315, 25861, 323, 9919, 11, 9749, 11447, 1550, 539, 3073, 13, 1102, 574, 1306, 279, 15244, 315, 11447, 430, 44565, 4633, 6848, 1051, 16948, 37588, 439, 264, 13010, 13, 578, 1455, 28289, 5956, 34291, 311, 44565, 2191, 304, 279, 14154, 1917, 1051, 304, 5734, 323, 25431, 13, 763, 5734, 11, 41903, 44565, 2191, 320, 1820, 10430, 389, 279, 57008, 315, 279, 1614, 8, 574, 91784, 660, 555, 60608, 380, 61787, 68844, 526, 67927, 323, 445, 3524, 8510, 13, 32944, 3002, 71883, 42914, 11, 60608, 2191, 706, 1027, 1071, 311, 617, 1047, 330, 91645, 16961, 811, 1, 315, 44565, 2191, 382, 2127, 1132, 292, 33726, 1051, 1101, 83280, 555, 28375, 5493, 323, 61787, 304, 25431, 13, 362, 60478, 4010, 355, 323, 34940, 511, 645, 1511, 279, 21849, 315, 6898, 343, 606, 311, 41468, 279, 12324, 1990, 7016, 27070, 555, 279, 1614, 323, 4443, 51360, 13, 328, 78046, 29440, 59652, 1122, 11527, 15320, 323, 29676, 389, 279, 1314, 315, 3927, 11542, 315, 42563, 13, 356, 1910, 1233, 27292, 3823, 2383, 320, 17101, 437, 8, 323, 5938, 11527, 1418, 4560, 311, 3974, 4184, 311, 7138, 320, 764, 4548, 570, 71883, 1233, 1051, 33445, 315, 264, 8396, 3196, 389, 57751, 323, 11919, 4398, 4315, 1202, 10495, 2085, 279, 9546, 315, 264, 1614, 382, 644, 42108, 4606, 11, 1070, 574, 912, 44565, 4633, 5820, 3734, 1063, 14943, 5411, 10597, 19567, 13, 4314, 11, 323, 1023, 10451, 19567, 11, 3010, 6688, 7342, 311, 10597, 44565, 2191, 13, 763, 279, 328, 46488, 1122, 21080, 11, 40091, 67, 587, 2663, 369, 459, 77271, 20631, 8396, 323, 279, 76445, 315, 87149, 11, 1193, 311, 387, 5246, 16070, 555, 35414, 735, 38155, 358, 382, 644, 15004, 969, 11, 10597, 31237, 82, 89194, 2403, 279, 1614, 13, 763, 4606, 11, 5370, 31237, 82, 8040, 7294, 21395, 323, 57125, 61555, 13, 50086, 291, 2802, 304, 61386, 488, 2391, 279, 55383, 323, 304, 879, 19971, 2391, 279, 1050, 1659, 28101, 5540, 315, 7294, 43802, 20631, 37019, 2191, 11, 8104, 304, 9822, 13, 92931, 11774, 311, 20207, 11447, 320, 5132, 1299, 323, 10597, 8, 323, 279, 93574, 315, 279, 220, 11128, 15, 82, 323, 220, 10336, 23, 682, 85747, 279, 42933, 4500, 315, 1148, 6244, 279, 11639, 315, 29924, 44565, 2191, 382, 49552, 11639, 720, 16397, 279, 8753, 22910, 11, 49638, 5315, 1778, 439, 279, 2998, 4193, 5512, 323, 279, 220, 5602, 264, 13353, 1486, 304, 279, 74454, 315, 7294, 21395, 323, 6918, 380, 58214, 13, 578, 1176, 78431, 60701, 8040, 6957, 279, 220, 972, 339, 9478, 439, 12656, 4359, 7678, 16948, 37588, 41903, 44565, 2191, 304, 9635, 11, 57323, 20445, 275, 318, 3876, 279, 1614, 11, 7639, 65292, 1215, 596, 7422, 63675, 279, 1648, 311, 3927, 2191, 323, 38077, 12278, 974, 764, 393, 583, 31721, 263, 596, 10334, 315, 27848, 2191, 1766, 70225, 17614, 304, 9822, 13, 3296, 279, 3389, 220, 9674, 15, 82, 11, 5370, 78431, 8853, 315, 3463, 1047, 3719, 1664, 39817, 323, 264, 12330, 315, 1243, 31069, 3728, 8082, 10222, 505, 220, 9367, 15, 311, 220, 7529, 19, 13, 1115, 11639, 315, 29924, 44565, 2191, 36513, 3156, 279, 842, 315, 279, 15506, 16803, 5111, 323, 374, 6646, 279, 21411, 4325, 315, 44565, 2191, 382, 38537, 505, 27848, 2191, 11, 92551, 36769, 359, 258, 18538, 6667, 80244, 44565, 2191, 323, 10862, 279, 7327, 22938, 5794, 596, 10229, 11, 264, 538, 12128, 11552, 3010, 3967, 439, 279, 5629, 7327, 430, 14454, 304, 220, 9714, 19, 311, 52696, 17226, 30191, 60701, 13, 578, 7327, 6244, 264, 5199, 5054, 5457, 11, 449, 35131, 28187, 1694, 264, 6522, 7216, 323, 264, 4562, 315, 1202, 3331, 9251, 13, 36769, 359, 258, 596, 37480, 320, 1820, 622, 5808, 28331, 8, 323, 393, 583, 31721, 263, 596, 20723, 320, 1820, 27848, 1705, 8, 16475, 1614, 51618, 11, 59416, 5054, 63944, 3012, 2191, 323, 2678, 3424, 58348, 13, 4740, 26242, 42254, 11, 279, 36769, 359, 258, 1705, 1051, 67331, 505, 279, 7327, 555, 279, 28187, 1705, 520, 279, 220, 9674, 17, 86026, 8151, 13, 1556, 1132, 1705, 1051, 12020, 30293, 304, 279, 10657, 7327, 11, 1694, 13967, 67331, 304, 220, 9378, 21, 13, 36769, 359, 258, 51287, 19698, 430, 422, 14110, 5548, 18661, 2410, 555, 28187, 596, 3878, 11, 814, 1053, 842, 709, 279, 502, 43049, 1821, 315, 7487, 13, 763, 2077, 311, 872, 95989, 505, 279, 5629, 7327, 11, 93134, 14454, 279, 800, 13, 2417, 1291, 7327, 13, 9636, 279, 10383, 315, 11291, 735, 897, 354, 8148, 11, 264, 8690, 55475, 323, 28568, 11, 459, 277, 971, 88389, 359, 2191, 29204, 5795, 449, 6667, 74050, 13, 1556, 277, 971, 88389, 359, 1705, 11, 889, 24465, 20343, 505, 279, 220, 9674, 16, 12366, 6947, 2957, 11, 64854, 369, 1949, 80375, 323, 369, 279, 8141, 315, 11822, 4184, 311, 832, 596, 3966, 382, 1383, 279, 2543, 315, 279, 220, 508, 339, 9478, 11, 44565, 2191, 1047, 9041, 682, 927, 279, 1917, 13, 1102, 574, 264, 28289, 4668, 315, 279, 6625, 22013, 950, 380, 7351, 13, 763, 5734, 11, 2678, 5315, 315, 4236, 25973, 279, 3823, 4633, 463, 31419, 1873, 2373, 315, 459, 277, 971, 88389, 359, 2191, 13, 27286, 574, 264, 80310, 369, 42301, 1245, 12822, 505, 6460, 14875, 5961, 11, 889, 7882, 311, 279, 11002, 6864, 311, 4007, 13, 763, 20023, 5270, 11, 32164, 574, 264, 86568, 369, 459, 277, 971, 1355, 88, 303, 950, 2191, 11, 1405, 433, 6244, 279, 1455, 21102, 2163, 29480, 34649, 13, 12220, 420, 892, 11, 264, 23413, 315, 93134, 18306, 26411, 315, 30191, 5054, 9349, 11, 3967, 439, 30617, 315, 279, 56408, 13, 578, 834, 9792, 479, 315, 279, 8753, 41289, 7351, 1139, 1690, 5315, 323, 279, 11572, 323, 61087, 315, 1690, 57298, 2402, 311, 47426, 49028, 2768, 279, 46735, 315, 279, 12366, 6947, 2957, 92867, 3927, 380, 5054, 7645, 323, 14385, 13, 7570, 3582, 1690, 93134, 1612, 4979, 5694, 505, 1521, 20320, 14385, 11, 4225, 27322, 3782, 5304, 279, 7351, 323, 13865, 1051, 1903, 311, 5471, 93134, 15644, 1113, 311, 279, 2326, 11, 2737, 279, 40782, 3298, 315, 220, 7028, 18, 11, 1101, 2663, 279, 1556, 1132, 380, 1398, 9134, 3298, 13, 15388, 2191, 574, 2500, 8446, 902, 1063, 93134, 18306, 2391, 420, 4261, 382, 20397, 10742, 11, 93134, 99325, 31408, 304, 279, 8690, 22910, 304, 14076, 311, 279, 5929, 7351, 11, 5423, 304, 279, 386, 22506, 39142, 939, 81236, 26, 4869, 11, 814, 2322, 25984, 46735, 1306, 279, 92501, 3109, 1047, 27276, 4147, 11, 2737, 2391, 279, 97660, 45378, 53848, 13, 26778, 93134, 505, 62579, 6902, 323, 23223, 30010, 311, 19278, 11, 1603, 279, 92501, 82, 33745, 279, 78431, 7351, 1070, 2288, 13, 3161, 279, 93134, 1694]\n",
      "inputs:\n",
      "Anarchism is a political philosophy and movement that is skeptical of all justifications for authority and seeks to abolish the institutions it claims maintain unnecessary coercion and hierarchy, typically including nation-states, and capitalism. Anarchism advocates for the replacement of the state with stateless societies and voluntary free associations. As a historically left-wing movement, this reading of anarchism is placed on the farthest left of the political spectrum, usually described as the libertarian wing of the socialist movement (libertarian socialism).\n",
      "\n",
      "Humans have lived in societies without formal hierarchies long before the establishment of states, realms, or empires. With the rise of organised hierarchical bodies, scepticism toward authority also rose. Although traces of anarchist ideas are found all throughout history, modern anarchism emerged from the Enlightenment. During the latter half of the 19th and the first decades of the 20th century, the anarchist movement flourished in most parts of the world and had a significant role in workers' struggles for emancipation. Various anarchist schools of thought formed during this period. Anarchists have taken part in several revolutions, most notably in the Paris Commune, the Russian Civil War and the Spanish Civil War, whose end marked the end of the classical era of anarchism. In the last decades of the 20th and into the 21st century, the anarchist movement has been resurgent once more, growing in popularity and influence within anti-capitalist, anti-war and anti-globalisation movements.\n",
      "\n",
      "Anarchists employ diverse approaches, which may be generally divided into revolutionary and evolutionary strategies; there is significant overlap between the two. Evolutionary methods try to simulate what an anarchist society might be like, but revolutionary tactics, which have historically taken a violent turn, aim to overthrow authority and the state. Many facets of human civilization have been influenced by anarchist theory, critique, and praxis.\n",
      "\n",
      "Etymology, terminology, and definition \n",
      "\n",
      "The etymological origin of anarchism is from the Ancient Greek anarkhia, meaning \"without a ruler\", composed of the prefix an- (\"without\") and the word arkhos (\"leader\" or \"ruler\"). The suffix -ism denotes the ideological current that favours anarchy. Anarchism appears in English from 1642 as anarchisme and anarchy from 1539; early English usages emphasised a sense of disorder. Various factions within the French Revolution labelled their opponents as anarchists, although few such accused shared many views with later anarchists. Many revolutionaries of the 19th century such as William Godwin (1756–1836) and Wilhelm Weitling (1808–1871) would contribute to the anarchist doctrines of the next generation but did not use anarchist or anarchism in describing themselves or their beliefs.\n",
      "\n",
      "The first political philosopher to call himself an anarchist () was Pierre-Joseph Proudhon (1809–1865), marking the formal birth of anarchism in the mid-19th century. Since the 1890s and beginning in France, libertarianism has often been used as a synonym for anarchism and its use as a synonym is still common outside the United States. Some usages of libertarianism refer to individualistic free-market philosophy only, and free-market anarchism in particular is termed libertarian anarchism.\n",
      "\n",
      "While the term libertarian has been largely synonymous with anarchism, its meaning has more recently been diluted by wider adoption from ideologically disparate groups, including both the New Left and libertarian Marxists, who do not associate themselves with authoritarian socialists or a vanguard party, and extreme cultural liberals, who are primarily concerned with civil liberties. Additionally, some anarchists use libertarian socialist to avoid anarchism's negative connotations and emphasise its connections with socialism. Anarchism is broadly used to describe the anti-authoritarian wing of the socialist movement. Anarchism is contrasted to socialist forms which are state-oriented or from above. Scholars of anarchism generally highlight anarchism's socialist credentials and criticise attempts at creating dichotomies between the two. Some scholars describe anarchism as having many influences from liberalism, and being both liberal and socialist but more so. Many scholars reject anarcho-capitalism as a misunderstanding of anarchist principles.\n",
      "\n",
      "While opposition to the state is central to anarchist thought, defining anarchism is not an easy task for scholars, as there is a lot of discussion among scholars and anarchists on the matter, and various currents perceive anarchism slightly differently. Major definitional elements include the will for a non-coercive society, the rejection of the state apparatus, the belief that human nature allows humans to exist in or progress toward such a non-coercive society, and a suggestion on how to act to pursue the ideal of anarchy.\n",
      "\n",
      "History\n",
      "\n",
      "Pre-modern era \n",
      "\n",
      "Before the creation of towns and cities, established authority did not exist. It was after the institution of authority that anarchistic ideas were espoused as a reaction. The most notable precursors to anarchism in the ancient world were in China and Greece. In China, philosophical anarchism (the discussion on the legitimacy of the state) was delineated by Taoist philosophers Zhuang Zhou and Laozi. Alongside Stoicism, Taoism has been said to have had \"significant anticipations\" of anarchism.\n",
      "\n",
      "Anarchic attitudes were also articulated by tragedians and philosophers in Greece. Aeschylus and Sophocles used the myth of Antigone to illustrate the conflict between laws imposed by the state and personal autonomy. Socrates questioned Athenian authorities constantly and insisted on the right of individual freedom of conscience. Cynics dismissed human law (nomos) and associated authorities while trying to live according to nature (physis). Stoics were supportive of a society based on unofficial and friendly relations among its citizens without the presence of a state.\n",
      "\n",
      "In medieval Europe, there was no anarchistic activity except some ascetic religious movements. These, and other Muslim movements, later gave birth to religious anarchism. In the Sasanian Empire, Mazdak called for an egalitarian society and the abolition of monarchy, only to be soon executed by Emperor Kavad I.\n",
      "\n",
      "In Basra, religious sects preached against the state. In Europe, various sects developed anti-state and libertarian tendencies. Renewed interest in antiquity during the Renaissance and in private judgment during the Reformation restored elements of anti-authoritarian secularism, particularly in France. Enlightenment challenges to intellectual authority (secular and religious) and the revolutions of the 1790s and 1848 all spurred the ideological development of what became the era of classical anarchism.\n",
      "\n",
      "Modern era \n",
      "During the French Revolution, partisan groups such as the Enragés and the  saw a turning point in the fermentation of anti-state and federalist sentiments. The first anarchist currents developed throughout the 18th century as William Godwin espoused philosophical anarchism in England, morally delegitimising the state, Max Stirner's thinking paved the way to individualism and Pierre-Joseph Proudhon's theory of mutualism found fertile soil in France. By the late 1870s, various anarchist schools of thought had become well-defined and a wave of then unprecedented globalisation occurred from 1880 to 1914. This era of classical anarchism lasted until the end of the Spanish Civil War and is considered the golden age of anarchism.\n",
      "\n",
      "Drawing from mutualism, Mikhail Bakunin founded collectivist anarchism and entered the International Workingmen's Association, a class worker union later known as the First International that formed in 1864 to unite diverse revolutionary currents. The International became a significant political force, with Karl Marx being a leading figure and a member of its General Council. Bakunin's faction (the Jura Federation) and Proudhon's followers (the mutualists) opposed state socialism, advocating political abstentionism and small property holdings. After bitter disputes, the Bakuninists were expelled from the International by the Marxists at the 1872 Hague Congress. Anarchists were treated similarly in the Second International, being ultimately expelled in 1896. Bakunin famously predicted that if revolutionaries gained power by Marx's terms, they would end up the new tyrants of workers. In response to their expulsion from the First International, anarchists formed the St. Imier International. Under the influence of Peter Kropotkin, a Russian philosopher and scientist, anarcho-communism overlapped with collectivism. Anarcho-communists, who drew inspiration from the 1871 Paris Commune, advocated for free federation and for the distribution of goods according to one's needs.\n",
      "\n",
      "By the turn of the 20th century, anarchism had spread all over the world. It was a notable feature of the international syndicalist movement. In China, small groups of students imported the humanistic pro-science version of anarcho-communism. Tokyo was a hotspot for rebellious youth from East Asian countries, who moved to the Japanese capital to study. In Latin America, Argentina was a stronghold for anarcho-syndicalism, where it became the most prominent left-wing ideology. During this time, a minority of anarchists adopted tactics of revolutionary political violence, known as propaganda of the deed. The dismemberment of the French socialist movement into many groups and the execution and exile of many Communards to penal colonies following the suppression of the Paris Commune favoured individualist political expression and acts. Even though many anarchists distanced themselves from these terrorist acts, infamy came upon the movement and attempts were made to prevent anarchists immigrating to the US, including the Immigration Act of 1903, also called the Anarchist Exclusion Act. Illegalism was another strategy which some anarchists adopted during this period.\n",
      "\n",
      "Despite concerns, anarchists enthusiastically participated in the Russian Revolution in opposition to the White movement, especially in the Makhnovshchina; however, they met harsh suppression after the Bolshevik government had stabilised, including during the Kronstadt rebellion. Several anarchists from Petrograd and Moscow fled to Ukraine, before the Bolsheviks crushed the anarchist movement there too. With the anarchists being\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:698] 2025-06-24 11:21:21,092 >> loading configuration file config.json from cache at /home/ai-research-lab/.cache/huggingface/hub/models--meta-llama--LLaMA-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95/config.json\n",
      "[INFO|configuration_utils.py:770] 2025-06-24 11:21:21,093 >> Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128008,\n",
      "    128009\n",
      "  ],\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 131072,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 24,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": {\n",
      "    \"factor\": 32.0,\n",
      "    \"high_freq_factor\": 4.0,\n",
      "    \"low_freq_factor\": 1.0,\n",
      "    \"original_max_position_embeddings\": 8192,\n",
      "    \"rope_type\": \"llama3\"\n",
      "  },\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:1151] 2025-06-24 11:21:21,220 >> loading weights file model.safetensors from cache at /home/ai-research-lab/.cache/huggingface/hub/models--meta-llama--LLaMA-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95/model.safetensors.index.json\n",
      "[INFO|modeling_utils.py:2241] 2025-06-24 11:21:21,221 >> Instantiating LlamaForCausalLM model under default dtype torch.bfloat16.\n",
      "[INFO|configuration_utils.py:1135] 2025-06-24 11:21:21,221 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128008,\n",
      "    128009\n",
      "  ],\n",
      "  \"use_cache\": false\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|2025-06-24 11:21:21] llamafactory.model.model_utils.kv_cache:143 >> KV cache is disabled during training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.40it/s]\n",
      "[INFO|modeling_utils.py:5131] 2025-06-24 11:21:21,994 >> All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
      "\n",
      "[INFO|modeling_utils.py:5139] 2025-06-24 11:21:21,994 >> All the weights of LlamaForCausalLM were initialized from the model checkpoint at meta-llama/LLaMA-3.2-3B-Instruct.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
      "[INFO|configuration_utils.py:1090] 2025-06-24 11:21:22,712 >> loading configuration file generation_config.json from cache at /home/ai-research-lab/.cache/huggingface/hub/models--meta-llama--LLaMA-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95/generation_config.json\n",
      "[INFO|configuration_utils.py:1135] 2025-06-24 11:21:22,712 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"do_sample\": true,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128008,\n",
      "    128009\n",
      "  ],\n",
      "  \"temperature\": 0.6,\n",
      "  \"top_p\": 0.9\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|2025-06-24 11:21:22] llamafactory.model.model_utils.checkpointing:143 >> Gradient checkpointing enabled.\n",
      "[INFO|2025-06-24 11:21:22] llamafactory.model.model_utils.attention:143 >> Using torch SDPA for faster training and inference.\n",
      "[INFO|2025-06-24 11:21:22] llamafactory.model.adapter:143 >> Upcasting trainable params to float32.\n",
      "[INFO|2025-06-24 11:21:22] llamafactory.model.adapter:143 >> Fine-tuning method: LoRA\n",
      "[INFO|2025-06-24 11:21:22] llamafactory.model.model_utils.misc:143 >> Found linear modules: down_proj,o_proj,gate_proj,v_proj,k_proj,up_proj,q_proj\n",
      "[INFO|2025-06-24 11:21:23] llamafactory.model.loader:143 >> trainable params: 48,627,712 || all params: 3,261,377,536 || trainable%: 1.4910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:756] 2025-06-24 11:21:23,246 >> Using auto half precision backend\n",
      "[INFO|trainer.py:2808] 2025-06-24 11:21:23,246 >> Loading model from llama3-3b_lora_pretrain/checkpoint-1000.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.07s/it]\n",
      "[INFO|trainer.py:2409] 2025-06-24 11:21:31,532 >> ***** Running training *****\n",
      "[INFO|trainer.py:2410] 2025-06-24 11:21:31,532 >>   Num examples = 149,143\n",
      "[INFO|trainer.py:2411] 2025-06-24 11:21:31,532 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:2412] 2025-06-24 11:21:31,532 >>   Instantaneous batch size per device = 1\n",
      "[INFO|trainer.py:2415] 2025-06-24 11:21:31,532 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "[INFO|trainer.py:2416] 2025-06-24 11:21:31,532 >>   Gradient Accumulation steps = 8\n",
      "[INFO|trainer.py:2417] 2025-06-24 11:21:31,532 >>   Total optimization steps = 9,322\n",
      "[INFO|trainer.py:2418] 2025-06-24 11:21:31,534 >>   Number of trainable parameters = 48,627,712\n",
      "[INFO|trainer.py:2440] 2025-06-24 11:21:31,534 >>   Continuing training from checkpoint, will skip to saved global_step\n",
      "[INFO|trainer.py:2441] 2025-06-24 11:21:31,534 >>   Continuing training from epoch 0\n",
      "[INFO|trainer.py:2442] 2025-06-24 11:21:31,534 >>   Continuing training from global step 1000\n",
      "[INFO|trainer.py:2444] 2025-06-24 11:21:31,534 >>   Will skip the first 0 epochs then the first 8000 batches in the first epoch.\n",
      " 11%|█         | 1010/9322 [00:39<05:28, 25.31it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1322, 'grad_norm': 0.20788027346134186, 'learning_rate': 9.997975036342195e-05, 'epoch': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1020/9322 [01:18<29:48,  4.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1428, 'grad_norm': 0.20687444508075714, 'learning_rate': 9.997407142025104e-05, 'epoch': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1030/9322 [01:57<3:04:13,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1104, 'grad_norm': 0.20823967456817627, 'learning_rate': 9.99676916294935e-05, 'epoch': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1040/9322 [02:37<8:25:36,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.156, 'grad_norm': 0.20744149386882782, 'learning_rate': 9.996061108062096e-05, 'epoch': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 1050/9322 [03:17<9:05:40,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1746, 'grad_norm': 0.1913895308971405, 'learning_rate': 9.99528298729326e-05, 'epoch': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 1060/9322 [03:56<9:06:54,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.11, 'grad_norm': 0.19725659489631653, 'learning_rate': 9.994434811555387e-05, 'epoch': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 1070/9322 [04:36<9:06:34,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1246, 'grad_norm': 0.20072366297245026, 'learning_rate': 9.99351659274348e-05, 'epoch': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 1080/9322 [05:16<9:04:37,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1388, 'grad_norm': 0.19844090938568115, 'learning_rate': 9.992528343734846e-05, 'epoch': 0.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 1090/9322 [05:55<9:03:51,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1125, 'grad_norm': 0.20725186169147491, 'learning_rate': 9.991470078388911e-05, 'epoch': 0.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 1100/9322 [06:35<9:03:50,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1337, 'grad_norm': 0.21601931750774384, 'learning_rate': 9.990341811547029e-05, 'epoch': 0.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 1110/9322 [07:15<9:03:27,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.116, 'grad_norm': 0.2185433954000473, 'learning_rate': 9.989143559032261e-05, 'epoch': 0.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 1120/9322 [07:55<9:02:51,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1531, 'grad_norm': 0.20616883039474487, 'learning_rate': 9.987875337649175e-05, 'epoch': 0.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 1130/9322 [08:34<9:02:11,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.135, 'grad_norm': 0.22126032412052155, 'learning_rate': 9.986537165183587e-05, 'epoch': 0.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 1140/9322 [09:14<9:01:46,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1824, 'grad_norm': 0.20090465247631073, 'learning_rate': 9.985129060402331e-05, 'epoch': 0.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 1150/9322 [09:54<9:00:55,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1327, 'grad_norm': 0.21300947666168213, 'learning_rate': 9.983651043052984e-05, 'epoch': 0.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 1160/9322 [10:33<8:59:44,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1439, 'grad_norm': 0.20876313745975494, 'learning_rate': 9.982103133863592e-05, 'epoch': 0.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 1170/9322 [11:13<8:59:20,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1538, 'grad_norm': 0.20748764276504517, 'learning_rate': 9.980485354542382e-05, 'epoch': 0.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 1180/9322 [11:53<8:59:15,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1777, 'grad_norm': 0.19640496373176575, 'learning_rate': 9.978797727777452e-05, 'epoch': 0.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 1190/9322 [12:33<8:58:18,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.128, 'grad_norm': 0.20234961807727814, 'learning_rate': 9.977040277236459e-05, 'epoch': 0.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 1200/9322 [13:12<8:57:29,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1288, 'grad_norm': 0.20219942927360535, 'learning_rate': 9.975213027566285e-05, 'epoch': 0.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 1210/9322 [13:52<8:56:55,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1254, 'grad_norm': 0.20355166494846344, 'learning_rate': 9.973316004392687e-05, 'epoch': 0.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 1220/9322 [14:32<8:56:15,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1475, 'grad_norm': 0.20215332508087158, 'learning_rate': 9.971349234319945e-05, 'epoch': 0.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 1230/9322 [15:11<8:55:49,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1585, 'grad_norm': 0.21253542602062225, 'learning_rate': 9.969312744930484e-05, 'epoch': 0.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 1240/9322 [15:51<8:55:30,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1281, 'grad_norm': 0.2083738148212433, 'learning_rate': 9.967206564784487e-05, 'epoch': 0.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 1250/9322 [16:31<8:54:45,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1527, 'grad_norm': 0.19757871329784393, 'learning_rate': 9.965030723419498e-05, 'epoch': 0.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 1260/9322 [17:11<8:53:54,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1011, 'grad_norm': 0.1993149220943451, 'learning_rate': 9.96278525135e-05, 'epoch': 0.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 1270/9322 [17:51<8:53:39,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1269, 'grad_norm': 0.22373835742473602, 'learning_rate': 9.960470180067003e-05, 'epoch': 0.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 1280/9322 [18:30<8:52:52,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1431, 'grad_norm': 0.2095639705657959, 'learning_rate': 9.958085542037583e-05, 'epoch': 0.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 1290/9322 [19:10<8:52:16,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.126, 'grad_norm': 0.20428705215454102, 'learning_rate': 9.955631370704438e-05, 'epoch': 0.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 1300/9322 [19:50<8:51:30,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.136, 'grad_norm': 0.2140158861875534, 'learning_rate': 9.95310770048542e-05, 'epoch': 0.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 1310/9322 [20:30<8:51:06,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1251, 'grad_norm': 0.2211582213640213, 'learning_rate': 9.950514566773043e-05, 'epoch': 0.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 1320/9322 [21:09<8:50:25,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1456, 'grad_norm': 0.19289961457252502, 'learning_rate': 9.947852005933996e-05, 'epoch': 0.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 1330/9322 [21:49<8:49:32,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1191, 'grad_norm': 0.20599529147148132, 'learning_rate': 9.945120055308633e-05, 'epoch': 0.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 1340/9322 [22:29<8:49:18,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0969, 'grad_norm': 0.2032819241285324, 'learning_rate': 9.942318753210437e-05, 'epoch': 0.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 1350/9322 [23:09<8:48:40,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1021, 'grad_norm': 0.2022038847208023, 'learning_rate': 9.939448138925503e-05, 'epoch': 0.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 1360/9322 [23:48<8:47:35,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1804, 'grad_norm': 0.20349323749542236, 'learning_rate': 9.936508252711963e-05, 'epoch': 0.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 1370/9322 [24:28<8:47:11,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1257, 'grad_norm': 0.20033085346221924, 'learning_rate': 9.933499135799446e-05, 'epoch': 0.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 1380/9322 [25:08<8:46:39,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1153, 'grad_norm': 0.20305968821048737, 'learning_rate': 9.93042083038848e-05, 'epoch': 0.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 1390/9322 [25:48<8:46:18,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1586, 'grad_norm': 0.22951456904411316, 'learning_rate': 9.92727337964991e-05, 'epoch': 0.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 1400/9322 [26:28<8:45:55,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1265, 'grad_norm': 0.21172620356082916, 'learning_rate': 9.924056827724295e-05, 'epoch': 0.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 1410/9322 [27:07<8:45:01,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0831, 'grad_norm': 0.205246239900589, 'learning_rate': 9.920771219721277e-05, 'epoch': 0.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 1420/9322 [27:47<8:44:15,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1234, 'grad_norm': 0.21531732380390167, 'learning_rate': 9.91741660171896e-05, 'epoch': 0.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 1430/9322 [28:27<8:43:16,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0972, 'grad_norm': 0.22316139936447144, 'learning_rate': 9.913993020763259e-05, 'epoch': 0.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 1440/9322 [29:07<8:42:01,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1246, 'grad_norm': 0.2073349803686142, 'learning_rate': 9.910500524867244e-05, 'epoch': 0.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 1450/9322 [29:47<8:41:13,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1363, 'grad_norm': 0.21089215576648712, 'learning_rate': 9.906939163010456e-05, 'epoch': 0.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 1460/9322 [30:26<8:41:10,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1113, 'grad_norm': 0.20599061250686646, 'learning_rate': 9.903308985138238e-05, 'epoch': 0.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 1470/9322 [31:06<8:40:44,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1205, 'grad_norm': 0.2028377652168274, 'learning_rate': 9.899610042161014e-05, 'epoch': 0.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 1480/9322 [31:46<8:40:38,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.132, 'grad_norm': 0.20302896201610565, 'learning_rate': 9.895842385953593e-05, 'epoch': 0.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 1490/9322 [32:26<8:40:19,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1442, 'grad_norm': 0.21387000381946564, 'learning_rate': 9.892006069354429e-05, 'epoch': 0.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 1500/9322 [33:06<8:39:36,  3.99s/it][INFO|trainer.py:3993] 2025-06-24 11:54:37,690 >> Saving model checkpoint to llama3-3b_lora_pretrain/checkpoint-1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1123, 'grad_norm': 0.1992429494857788, 'learning_rate': 9.888101146164888e-05, 'epoch': 0.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:698] 2025-06-24 11:54:39,310 >> loading configuration file config.json from cache at /home/ai-research-lab/.cache/huggingface/hub/models--meta-llama--LLaMA-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95/config.json\n",
      "[INFO|configuration_utils.py:770] 2025-06-24 11:54:39,311 >> Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128008,\n",
      "    128009\n",
      "  ],\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 131072,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 24,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": {\n",
      "    \"factor\": 32.0,\n",
      "    \"high_freq_factor\": 4.0,\n",
      "    \"low_freq_factor\": 1.0,\n",
      "    \"original_max_position_embeddings\": 8192,\n",
      "    \"rope_type\": \"llama3\"\n",
      "  },\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2356] 2025-06-24 11:54:39,421 >> chat template saved in llama3-3b_lora_pretrain/checkpoint-1500/chat_template.jinja\n",
      "[INFO|tokenization_utils_base.py:2525] 2025-06-24 11:54:39,422 >> tokenizer config file saved in llama3-3b_lora_pretrain/checkpoint-1500/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2534] 2025-06-24 11:54:39,422 >> Special tokens file saved in llama3-3b_lora_pretrain/checkpoint-1500/special_tokens_map.json\n",
      " 16%|█▌        | 1510/9322 [33:47<8:42:03,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1336, 'grad_norm': 0.20826144516468048, 'learning_rate': 9.884127671148487e-05, 'epoch': 0.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 1520/9322 [34:27<8:39:39,  4.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1303, 'grad_norm': 0.2243576943874359, 'learning_rate': 9.880085700030133e-05, 'epoch': 0.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 1530/9322 [35:07<8:38:20,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.146, 'grad_norm': 0.20842689275741577, 'learning_rate': 9.875975289495334e-05, 'epoch': 0.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1540/9322 [35:47<8:38:00,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1453, 'grad_norm': 0.1943773776292801, 'learning_rate': 9.871796497189408e-05, 'epoch': 0.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1550/9322 [36:27<8:37:25,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1258, 'grad_norm': 0.2087825983762741, 'learning_rate': 9.867549381716679e-05, 'epoch': 0.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1560/9322 [37:07<8:36:55,  4.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1911, 'grad_norm': 0.19639649987220764, 'learning_rate': 9.863234002639643e-05, 'epoch': 0.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1570/9322 [37:47<8:36:04,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1227, 'grad_norm': 0.20310862362384796, 'learning_rate': 9.858850420478148e-05, 'epoch': 0.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1580/9322 [38:27<8:35:10,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.104, 'grad_norm': 0.20491114258766174, 'learning_rate': 9.854398696708531e-05, 'epoch': 0.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1590/9322 [39:07<8:34:46,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1474, 'grad_norm': 0.20036739110946655, 'learning_rate': 9.849878893762766e-05, 'epoch': 0.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1600/9322 [39:47<8:34:02,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1596, 'grad_norm': 0.20228801667690277, 'learning_rate': 9.845291075027583e-05, 'epoch': 0.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1610/9322 [40:27<8:33:43,  4.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0974, 'grad_norm': 0.20095230638980865, 'learning_rate': 9.84063530484358e-05, 'epoch': 0.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1620/9322 [41:07<8:32:54,  4.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0767, 'grad_norm': 0.20152126252651215, 'learning_rate': 9.835911648504322e-05, 'epoch': 0.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1630/9322 [41:47<8:32:14,  4.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1392, 'grad_norm': 0.20326638221740723, 'learning_rate': 9.831120172255428e-05, 'epoch': 0.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 1640/9322 [42:27<8:31:18,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1262, 'grad_norm': 0.21244436502456665, 'learning_rate': 9.826260943293633e-05, 'epoch': 0.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 1650/9322 [43:07<8:29:44,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1453, 'grad_norm': 0.2047700136899948, 'learning_rate': 9.821334029765853e-05, 'epoch': 0.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 1660/9322 [43:47<8:28:58,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1174, 'grad_norm': 0.2010001391172409, 'learning_rate': 9.81633950076823e-05, 'epoch': 0.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 1670/9322 [44:26<8:28:06,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0548, 'grad_norm': 0.21268321573734283, 'learning_rate': 9.81127742634516e-05, 'epoch': 0.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 1680/9322 [45:06<8:26:49,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1429, 'grad_norm': 0.20367950201034546, 'learning_rate': 9.806147877488308e-05, 'epoch': 0.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 1690/9322 [45:46<8:26:19,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1588, 'grad_norm': 0.21632951498031616, 'learning_rate': 9.800950926135619e-05, 'epoch': 0.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 1700/9322 [46:26<8:25:45,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1173, 'grad_norm': 0.21138904988765717, 'learning_rate': 9.795686645170305e-05, 'epoch': 0.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 1710/9322 [47:06<8:25:33,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1204, 'grad_norm': 0.19646690785884857, 'learning_rate': 9.790355108419821e-05, 'epoch': 0.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 1720/9322 [47:46<8:25:23,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0813, 'grad_norm': 0.20483215153217316, 'learning_rate': 9.784956390654836e-05, 'epoch': 0.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 1730/9322 [48:25<8:24:43,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0767, 'grad_norm': 0.20553722977638245, 'learning_rate': 9.779490567588176e-05, 'epoch': 0.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 1740/9322 [49:05<8:24:41,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0846, 'grad_norm': 0.2058163285255432, 'learning_rate': 9.773957715873773e-05, 'epoch': 0.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 1750/9322 [49:45<8:24:12,  4.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1445, 'grad_norm': 0.21178796887397766, 'learning_rate': 9.768357913105581e-05, 'epoch': 0.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 1760/9322 [50:25<8:23:52,  4.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1261, 'grad_norm': 0.21011562645435333, 'learning_rate': 9.762691237816487e-05, 'epoch': 0.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 1770/9322 [51:05<8:23:04,  4.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0626, 'grad_norm': 0.20450136065483093, 'learning_rate': 9.756957769477217e-05, 'epoch': 0.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 1780/9322 [51:45<8:22:45,  4.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1213, 'grad_norm': 0.2062024027109146, 'learning_rate': 9.751157588495219e-05, 'epoch': 0.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 1790/9322 [52:25<8:22:12,  4.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1301, 'grad_norm': 0.20291979610919952, 'learning_rate': 9.745290776213529e-05, 'epoch': 0.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 1800/9322 [53:05<8:23:53,  4.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0864, 'grad_norm': 0.2107326239347458, 'learning_rate': 9.73935741490964e-05, 'epoch': 0.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 1810/9322 [53:45<8:20:14,  4.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0885, 'grad_norm': 0.1970675140619278, 'learning_rate': 9.733357587794343e-05, 'epoch': 0.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 1820/9322 [54:25<8:19:34,  4.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0951, 'grad_norm': 0.21784624457359314, 'learning_rate': 9.727291379010557e-05, 'epoch': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 1830/9322 [55:05<8:18:47,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1351, 'grad_norm': 0.21080154180526733, 'learning_rate': 9.721158873632156e-05, 'epoch': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 1840/9322 [55:45<8:17:57,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0802, 'grad_norm': 0.20815879106521606, 'learning_rate': 9.714960157662769e-05, 'epoch': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 1850/9322 [56:25<8:17:49,  4.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1422, 'grad_norm': 0.19148249924182892, 'learning_rate': 9.708695318034582e-05, 'epoch': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 1860/9322 [57:05<8:16:40,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1634, 'grad_norm': 0.22578062117099762, 'learning_rate': 9.702364442607111e-05, 'epoch': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1870/9322 [57:45<8:16:16,  4.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1018, 'grad_norm': 0.19429577887058258, 'learning_rate': 9.69596762016597e-05, 'epoch': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1880/9322 [58:25<8:15:52,  4.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1627, 'grad_norm': 0.22328805923461914, 'learning_rate': 9.689504940421633e-05, 'epoch': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1890/9322 [59:05<8:15:29,  4.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1734, 'grad_norm': 0.2048436403274536, 'learning_rate': 9.68297649400817e-05, 'epoch': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1900/9322 [59:45<8:15:06,  4.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1273, 'grad_norm': 0.20166464149951935, 'learning_rate': 9.676382372481981e-05, 'epoch': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1910/9322 [1:00:25<8:14:42,  4.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1398, 'grad_norm': 0.20310698449611664, 'learning_rate': 9.6697226683205e-05, 'epoch': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 1920/9322 [1:01:05<8:13:57,  4.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1493, 'grad_norm': 0.2061321884393692, 'learning_rate': 9.662997474920916e-05, 'epoch': 0.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 1930/9322 [1:01:45<8:13:30,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1057, 'grad_norm': 0.20308750867843628, 'learning_rate': 9.656206886598849e-05, 'epoch': 0.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 1940/9322 [1:02:25<8:13:12,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1107, 'grad_norm': 0.2022319883108139, 'learning_rate': 9.64935099858703e-05, 'epoch': 0.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 1950/9322 [1:03:05<8:12:46,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.138, 'grad_norm': 0.20723241567611694, 'learning_rate': 9.642429907033975e-05, 'epoch': 0.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 1960/9322 [1:03:46<8:11:39,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0917, 'grad_norm': 0.20592957735061646, 'learning_rate': 9.635443709002621e-05, 'epoch': 0.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 1970/9322 [1:04:26<8:11:13,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.127, 'grad_norm': 0.20995770394802094, 'learning_rate': 9.628392502468977e-05, 'epoch': 0.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 1980/9322 [1:05:06<8:11:04,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1343, 'grad_norm': 0.21645569801330566, 'learning_rate': 9.621276386320743e-05, 'epoch': 0.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 1990/9322 [1:05:46<8:09:54,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0616, 'grad_norm': 0.21519196033477783, 'learning_rate': 9.614095460355932e-05, 'epoch': 0.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 2000/9322 [1:06:26<8:09:22,  4.01s/it][INFO|trainer.py:3993] 2025-06-24 12:27:57,961 >> Saving model checkpoint to llama3-3b_lora_pretrain/checkpoint-2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0777, 'grad_norm': 0.20910689234733582, 'learning_rate': 9.606849825281457e-05, 'epoch': 0.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:698] 2025-06-24 12:27:59,499 >> loading configuration file config.json from cache at /home/ai-research-lab/.cache/huggingface/hub/models--meta-llama--LLaMA-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95/config.json\n",
      "[INFO|configuration_utils.py:770] 2025-06-24 12:27:59,500 >> Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128008,\n",
      "    128009\n",
      "  ],\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 131072,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 24,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": {\n",
      "    \"factor\": 32.0,\n",
      "    \"high_freq_factor\": 4.0,\n",
      "    \"low_freq_factor\": 1.0,\n",
      "    \"original_max_position_embeddings\": 8192,\n",
      "    \"rope_type\": \"llama3\"\n",
      "  },\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2356] 2025-06-24 12:27:59,602 >> chat template saved in llama3-3b_lora_pretrain/checkpoint-2000/chat_template.jinja\n",
      "[INFO|tokenization_utils_base.py:2525] 2025-06-24 12:27:59,603 >> tokenizer config file saved in llama3-3b_lora_pretrain/checkpoint-2000/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2534] 2025-06-24 12:27:59,603 >> Special tokens file saved in llama3-3b_lora_pretrain/checkpoint-2000/special_tokens_map.json\n",
      " 22%|██▏       | 2010/9322 [1:07:08<8:10:57,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1385, 'grad_norm': 0.20742477476596832, 'learning_rate': 9.59953958271173e-05, 'epoch': 0.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2020/9322 [1:07:48<8:07:54,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1369, 'grad_norm': 0.21037814021110535, 'learning_rate': 9.592164835167235e-05, 'epoch': 0.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2030/9322 [1:08:28<8:07:12,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1355, 'grad_norm': 0.20300818979740143, 'learning_rate': 9.584725686073082e-05, 'epoch': 0.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2040/9322 [1:09:08<8:07:15,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1378, 'grad_norm': 0.20173057913780212, 'learning_rate': 9.57722223975757e-05, 'epoch': 0.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2050/9322 [1:09:48<8:07:53,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1302, 'grad_norm': 0.20538118481636047, 'learning_rate': 9.56965460145071e-05, 'epoch': 0.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2060/9322 [1:10:29<8:06:09,  4.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1555, 'grad_norm': 0.20095160603523254, 'learning_rate': 9.562022877282762e-05, 'epoch': 0.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2070/9322 [1:11:09<8:05:42,  4.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1251, 'grad_norm': 0.2040059119462967, 'learning_rate': 9.554327174282735e-05, 'epoch': 0.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2080/9322 [1:11:49<8:05:20,  4.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1087, 'grad_norm': 0.20358791947364807, 'learning_rate': 9.546567600376896e-05, 'epoch': 0.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2090/9322 [1:12:29<8:04:45,  4.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1627, 'grad_norm': 0.2105618119239807, 'learning_rate': 9.538744264387247e-05, 'epoch': 0.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 2100/9322 [1:13:09<8:03:59,  4.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1528, 'grad_norm': 0.2054038792848587, 'learning_rate': 9.53085727603001e-05, 'epoch': 0.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 2110/9322 [1:13:50<8:03:41,  4.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1257, 'grad_norm': 0.20386232435703278, 'learning_rate': 9.522906745914076e-05, 'epoch': 0.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 2120/9322 [1:14:30<8:03:09,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1004, 'grad_norm': 0.19438336789608002, 'learning_rate': 9.514892785539464e-05, 'epoch': 0.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 2130/9322 [1:15:10<8:02:58,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0854, 'grad_norm': 0.21047505736351013, 'learning_rate': 9.506815507295752e-05, 'epoch': 0.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 2140/9322 [1:15:51<8:02:30,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.104, 'grad_norm': 0.21308964490890503, 'learning_rate': 9.498675024460502e-05, 'epoch': 0.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 2150/9322 [1:16:31<8:01:56,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1039, 'grad_norm': 0.21588543057441711, 'learning_rate': 9.490471451197671e-05, 'epoch': 0.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 2160/9322 [1:17:11<8:01:27,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1336, 'grad_norm': 0.21184086799621582, 'learning_rate': 9.48220490255601e-05, 'epoch': 0.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 2170/9322 [1:17:51<8:01:04,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1386, 'grad_norm': 0.242310032248497, 'learning_rate': 9.47387549446745e-05, 'epoch': 0.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 2180/9322 [1:18:32<8:00:16,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1691, 'grad_norm': 0.20432022213935852, 'learning_rate': 9.46548334374548e-05, 'epoch': 0.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 2190/9322 [1:19:12<7:59:28,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1507, 'grad_norm': 0.2106589376926422, 'learning_rate': 9.457028568083505e-05, 'epoch': 0.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 2200/9322 [1:19:53<7:58:42,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0729, 'grad_norm': 0.20977161824703217, 'learning_rate': 9.448511286053193e-05, 'epoch': 0.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 2210/9322 [1:20:33<7:57:58,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0818, 'grad_norm': 0.21531087160110474, 'learning_rate': 9.439931617102819e-05, 'epoch': 0.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 2220/9322 [1:21:13<7:57:27,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1146, 'grad_norm': 0.21038757264614105, 'learning_rate': 9.431289681555585e-05, 'epoch': 0.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 2230/9322 [1:21:54<7:56:55,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1207, 'grad_norm': 0.21195344626903534, 'learning_rate': 9.422585600607932e-05, 'epoch': 0.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 2240/9322 [1:22:34<7:56:29,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1133, 'grad_norm': 0.214646115899086, 'learning_rate': 9.413819496327844e-05, 'epoch': 0.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 2250/9322 [1:23:14<7:55:39,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0797, 'grad_norm': 0.20643214881420135, 'learning_rate': 9.404991491653135e-05, 'epoch': 0.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 2260/9322 [1:23:55<7:55:12,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1194, 'grad_norm': 0.20845437049865723, 'learning_rate': 9.396101710389721e-05, 'epoch': 0.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 2270/9322 [1:24:35<7:54:20,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1117, 'grad_norm': 0.21513961255550385, 'learning_rate': 9.387150277209889e-05, 'epoch': 0.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 2280/9322 [1:25:15<7:53:08,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1149, 'grad_norm': 0.20016314089298248, 'learning_rate': 9.378137317650546e-05, 'epoch': 0.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 2290/9322 [1:25:56<7:52:56,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1456, 'grad_norm': 0.20318305492401123, 'learning_rate': 9.369062958111458e-05, 'epoch': 0.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 2300/9322 [1:26:36<7:52:24,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1068, 'grad_norm': 0.21219505369663239, 'learning_rate': 9.359927325853479e-05, 'epoch': 0.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 2310/9322 [1:27:16<7:51:53,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.136, 'grad_norm': 0.20689994096755981, 'learning_rate': 9.350730548996764e-05, 'epoch': 0.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 2320/9322 [1:27:57<7:51:01,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0975, 'grad_norm': 0.21178562939167023, 'learning_rate': 9.341472756518976e-05, 'epoch': 0.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 2330/9322 [1:28:37<7:50:19,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1807, 'grad_norm': 0.2067711353302002, 'learning_rate': 9.332154078253472e-05, 'epoch': 0.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2340/9322 [1:29:18<7:49:42,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0495, 'grad_norm': 0.20996759831905365, 'learning_rate': 9.322774644887486e-05, 'epoch': 0.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2350/9322 [1:29:58<7:49:04,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0938, 'grad_norm': 0.21475611627101898, 'learning_rate': 9.313334587960296e-05, 'epoch': 0.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2360/9322 [1:30:38<7:48:10,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1106, 'grad_norm': 0.21105262637138367, 'learning_rate': 9.303834039861377e-05, 'epoch': 0.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2370/9322 [1:31:19<7:47:36,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1045, 'grad_norm': 0.20601175725460052, 'learning_rate': 9.294273133828547e-05, 'epoch': 0.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 2380/9322 [1:31:59<7:46:29,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0833, 'grad_norm': 0.20800864696502686, 'learning_rate': 9.284652003946097e-05, 'epoch': 0.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 2390/9322 [1:32:39<7:46:17,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1015, 'grad_norm': 0.20935238897800446, 'learning_rate': 9.274970785142909e-05, 'epoch': 0.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 2400/9322 [1:33:20<7:45:33,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0949, 'grad_norm': 0.21414871513843536, 'learning_rate': 9.265229613190569e-05, 'epoch': 0.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 2410/9322 [1:34:00<7:44:56,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1116, 'grad_norm': 0.2180669754743576, 'learning_rate': 9.255428624701456e-05, 'epoch': 0.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 2420/9322 [1:34:41<7:44:44,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0944, 'grad_norm': 0.22129100561141968, 'learning_rate': 9.24556795712683e-05, 'epoch': 0.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 2430/9322 [1:35:21<7:43:42,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0636, 'grad_norm': 0.2071383148431778, 'learning_rate': 9.235647748754907e-05, 'epoch': 0.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 2440/9322 [1:36:01<7:42:55,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.078, 'grad_norm': 0.2017052322626114, 'learning_rate': 9.225668138708913e-05, 'epoch': 0.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 2450/9322 [1:36:42<7:42:38,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0902, 'grad_norm': 0.20850872993469238, 'learning_rate': 9.21562926694514e-05, 'epoch': 0.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 2460/9322 [1:37:22<7:41:41,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1041, 'grad_norm': 0.21597442030906677, 'learning_rate': 9.205531274250973e-05, 'epoch': 0.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 2470/9322 [1:38:02<7:41:02,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1001, 'grad_norm': 0.21026432514190674, 'learning_rate': 9.19537430224293e-05, 'epoch': 0.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 2480/9322 [1:38:43<7:40:12,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1016, 'grad_norm': 0.2236497700214386, 'learning_rate': 9.185158493364663e-05, 'epoch': 0.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 2490/9322 [1:39:23<7:39:33,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.114, 'grad_norm': 0.21563391387462616, 'learning_rate': 9.174883990884967e-05, 'epoch': 0.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 2500/9322 [1:40:04<7:38:48,  4.04s/it][INFO|trainer.py:3993] 2025-06-24 13:01:35,580 >> Saving model checkpoint to llama3-3b_lora_pretrain/checkpoint-2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1204, 'grad_norm': 0.1990136057138443, 'learning_rate': 9.164550938895771e-05, 'epoch': 0.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:698] 2025-06-24 13:01:37,093 >> loading configuration file config.json from cache at /home/ai-research-lab/.cache/huggingface/hub/models--meta-llama--LLaMA-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95/config.json\n",
      "[INFO|configuration_utils.py:770] 2025-06-24 13:01:37,093 >> Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128008,\n",
      "    128009\n",
      "  ],\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 131072,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 24,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": {\n",
      "    \"factor\": 32.0,\n",
      "    \"high_freq_factor\": 4.0,\n",
      "    \"low_freq_factor\": 1.0,\n",
      "    \"original_max_position_embeddings\": 8192,\n",
      "    \"rope_type\": \"llama3\"\n",
      "  },\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2356] 2025-06-24 13:01:37,180 >> chat template saved in llama3-3b_lora_pretrain/checkpoint-2500/chat_template.jinja\n",
      "[INFO|tokenization_utils_base.py:2525] 2025-06-24 13:01:37,181 >> tokenizer config file saved in llama3-3b_lora_pretrain/checkpoint-2500/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2534] 2025-06-24 13:01:37,181 >> Special tokens file saved in llama3-3b_lora_pretrain/checkpoint-2500/special_tokens_map.json\n",
      " 27%|██▋       | 2510/9322 [1:40:46<7:40:22,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.075, 'grad_norm': 0.21227647364139557, 'learning_rate': 9.15415948231011e-05, 'epoch': 0.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 2520/9322 [1:41:26<7:37:15,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1528, 'grad_norm': 0.2112644910812378, 'learning_rate': 9.143709766860107e-05, 'epoch': 0.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 2530/9322 [1:42:06<7:36:43,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0494, 'grad_norm': 0.21994301676750183, 'learning_rate': 9.133201939094912e-05, 'epoch': 0.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 2540/9322 [1:42:47<7:36:08,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0493, 'grad_norm': 0.21732422709465027, 'learning_rate': 9.122636146378659e-05, 'epoch': 0.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 2550/9322 [1:43:27<7:35:27,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1027, 'grad_norm': 0.2138318121433258, 'learning_rate': 9.112012536888396e-05, 'epoch': 0.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 2560/9322 [1:44:07<7:34:39,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0666, 'grad_norm': 0.208596870303154, 'learning_rate': 9.101331259612003e-05, 'epoch': 0.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 2570/9322 [1:44:48<7:34:11,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1225, 'grad_norm': 0.21333085000514984, 'learning_rate': 9.09059246434611e-05, 'epoch': 0.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 2580/9322 [1:45:28<7:33:30,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1041, 'grad_norm': 0.20708836615085602, 'learning_rate': 9.079796301693992e-05, 'epoch': 0.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 2590/9322 [1:46:09<7:32:58,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1195, 'grad_norm': 0.21792319416999817, 'learning_rate': 9.068942923063453e-05, 'epoch': 0.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 2600/9322 [1:46:49<7:32:09,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.16, 'grad_norm': 0.21307246387004852, 'learning_rate': 9.05803248066471e-05, 'epoch': 0.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 2610/9322 [1:47:29<7:31:38,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1083, 'grad_norm': 0.21510809659957886, 'learning_rate': 9.047065127508254e-05, 'epoch': 0.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 2620/9322 [1:48:10<7:31:14,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1237, 'grad_norm': 0.21291109919548035, 'learning_rate': 9.036041017402708e-05, 'epoch': 0.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 2630/9322 [1:48:50<7:31:24,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1113, 'grad_norm': 0.21038110554218292, 'learning_rate': 9.024960304952661e-05, 'epoch': 0.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 2640/9322 [1:49:31<7:30:31,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1128, 'grad_norm': 0.20763744413852692, 'learning_rate': 9.013823145556512e-05, 'epoch': 0.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 2650/9322 [1:50:11<7:29:51,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0769, 'grad_norm': 0.20969325304031372, 'learning_rate': 9.002629695404284e-05, 'epoch': 0.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 2660/9322 [1:50:52<7:28:48,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.099, 'grad_norm': 0.2058858573436737, 'learning_rate': 8.991380111475428e-05, 'epoch': 0.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 2670/9322 [1:51:32<7:27:56,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0731, 'grad_norm': 0.20272298157215118, 'learning_rate': 8.980074551536637e-05, 'epoch': 0.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 2680/9322 [1:52:12<7:27:05,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1143, 'grad_norm': 0.20676298439502716, 'learning_rate': 8.968713174139616e-05, 'epoch': 0.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 2690/9322 [1:52:53<7:26:30,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1374, 'grad_norm': 0.22058920562267303, 'learning_rate': 8.957296138618872e-05, 'epoch': 0.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 2700/9322 [1:53:33<7:25:55,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1114, 'grad_norm': 0.22358298301696777, 'learning_rate': 8.94582360508947e-05, 'epoch': 0.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 2710/9322 [1:54:14<7:24:58,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1135, 'grad_norm': 0.2020980417728424, 'learning_rate': 8.934295734444795e-05, 'epoch': 0.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 2720/9322 [1:54:54<7:23:41,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.138, 'grad_norm': 0.22480952739715576, 'learning_rate': 8.922712688354292e-05, 'epoch': 0.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 2730/9322 [1:55:34<7:23:17,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.091, 'grad_norm': 0.21504604816436768, 'learning_rate': 8.911074629261194e-05, 'epoch': 0.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 2740/9322 [1:56:15<7:22:41,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0867, 'grad_norm': 0.21193447709083557, 'learning_rate': 8.899381720380256e-05, 'epoch': 0.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 2750/9322 [1:56:55<7:22:12,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0996, 'grad_norm': 0.2091544270515442, 'learning_rate': 8.887634125695449e-05, 'epoch': 0.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 2760/9322 [1:57:35<7:21:06,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.083, 'grad_norm': 0.21788938343524933, 'learning_rate': 8.875832009957683e-05, 'epoch': 0.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 2770/9322 [1:58:16<7:20:44,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0893, 'grad_norm': 0.21521514654159546, 'learning_rate': 8.863975538682471e-05, 'epoch': 0.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 2780/9322 [1:58:56<7:20:12,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.157, 'grad_norm': 0.20956870913505554, 'learning_rate': 8.852064878147628e-05, 'epoch': 0.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 2790/9322 [1:59:36<7:19:31,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1378, 'grad_norm': 0.20695118606090546, 'learning_rate': 8.840100195390927e-05, 'epoch': 0.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 2800/9322 [2:00:17<7:18:44,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1395, 'grad_norm': 0.20421932637691498, 'learning_rate': 8.828081658207765e-05, 'epoch': 0.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 2810/9322 [2:00:57<7:17:54,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0837, 'grad_norm': 0.21268418431282043, 'learning_rate': 8.8160094351488e-05, 'epoch': 0.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 2820/9322 [2:01:37<7:17:07,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1425, 'grad_norm': 0.2061370462179184, 'learning_rate': 8.803883695517598e-05, 'epoch': 0.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 2830/9322 [2:02:18<7:16:38,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0731, 'grad_norm': 0.2166556566953659, 'learning_rate': 8.791704609368255e-05, 'epoch': 0.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 2840/9322 [2:02:58<7:15:47,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1339, 'grad_norm': 0.21017511188983917, 'learning_rate': 8.779472347503e-05, 'epoch': 0.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 2850/9322 [2:03:38<7:15:13,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0629, 'grad_norm': 0.2262854129076004, 'learning_rate': 8.767187081469819e-05, 'epoch': 0.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 2860/9322 [2:04:19<7:14:43,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0964, 'grad_norm': 0.21746709942817688, 'learning_rate': 8.754848983560042e-05, 'epoch': 0.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 2870/9322 [2:04:59<7:14:30,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0887, 'grad_norm': 0.2098059356212616, 'learning_rate': 8.742458226805918e-05, 'epoch': 0.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 2880/9322 [2:05:40<7:13:27,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.161, 'grad_norm': 0.21198850870132446, 'learning_rate': 8.730014984978199e-05, 'epoch': 0.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 2890/9322 [2:06:20<7:12:38,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0744, 'grad_norm': 0.22509276866912842, 'learning_rate': 8.717519432583702e-05, 'epoch': 0.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 2900/9322 [2:07:00<7:12:05,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0609, 'grad_norm': 0.21776601672172546, 'learning_rate': 8.704971744862853e-05, 'epoch': 0.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 2910/9322 [2:07:41<7:13:06,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.096, 'grad_norm': 0.20797139406204224, 'learning_rate': 8.692372097787242e-05, 'epoch': 0.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 2920/9322 [2:08:21<7:10:46,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0923, 'grad_norm': 0.2180987447500229, 'learning_rate': 8.679720668057145e-05, 'epoch': 0.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 2930/9322 [2:09:02<7:10:10,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1521, 'grad_norm': 0.2128494530916214, 'learning_rate': 8.667017633099048e-05, 'epoch': 0.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 2940/9322 [2:09:42<7:09:23,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1643, 'grad_norm': 0.21049518883228302, 'learning_rate': 8.654263171063167e-05, 'epoch': 0.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 2950/9322 [2:10:22<7:09:13,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1111, 'grad_norm': 0.21477076411247253, 'learning_rate': 8.641457460820934e-05, 'epoch': 0.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 2960/9322 [2:11:03<7:07:59,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1269, 'grad_norm': 0.20942436158657074, 'learning_rate': 8.628600681962502e-05, 'epoch': 0.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 2970/9322 [2:11:43<7:07:20,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1152, 'grad_norm': 0.22002211213111877, 'learning_rate': 8.615693014794224e-05, 'epoch': 0.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 2980/9322 [2:12:24<7:06:38,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1059, 'grad_norm': 0.20976217091083527, 'learning_rate': 8.602734640336116e-05, 'epoch': 0.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 2990/9322 [2:13:04<7:06:18,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0938, 'grad_norm': 0.2072802186012268, 'learning_rate': 8.589725740319333e-05, 'epoch': 0.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 3000/9322 [2:13:44<7:05:20,  4.04s/it][INFO|trainer.py:3993] 2025-06-24 13:35:16,366 >> Saving model checkpoint to llama3-3b_lora_pretrain/checkpoint-3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1343, 'grad_norm': 0.215326189994812, 'learning_rate': 8.576666497183604e-05, 'epoch': 0.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:698] 2025-06-24 13:35:17,904 >> loading configuration file config.json from cache at /home/ai-research-lab/.cache/huggingface/hub/models--meta-llama--LLaMA-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95/config.json\n",
      "[INFO|configuration_utils.py:770] 2025-06-24 13:35:17,905 >> Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128008,\n",
      "    128009\n",
      "  ],\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 131072,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 24,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": {\n",
      "    \"factor\": 32.0,\n",
      "    \"high_freq_factor\": 4.0,\n",
      "    \"low_freq_factor\": 1.0,\n",
      "    \"original_max_position_embeddings\": 8192,\n",
      "    \"rope_type\": \"llama3\"\n",
      "  },\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2356] 2025-06-24 13:35:18,006 >> chat template saved in llama3-3b_lora_pretrain/checkpoint-3000/chat_template.jinja\n",
      "[INFO|tokenization_utils_base.py:2525] 2025-06-24 13:35:18,008 >> tokenizer config file saved in llama3-3b_lora_pretrain/checkpoint-3000/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2534] 2025-06-24 13:35:18,008 >> Special tokens file saved in llama3-3b_lora_pretrain/checkpoint-3000/special_tokens_map.json\n",
      " 32%|███▏      | 3010/9322 [2:14:27<7:06:45,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1074, 'grad_norm': 0.21916688978672028, 'learning_rate': 8.563557094074682e-05, 'epoch': 0.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 3020/9322 [2:15:07<7:03:52,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1101, 'grad_norm': 0.20814725756645203, 'learning_rate': 8.550397714841779e-05, 'epoch': 0.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 3030/9322 [2:15:47<7:03:31,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1187, 'grad_norm': 0.21406500041484833, 'learning_rate': 8.537188544034979e-05, 'epoch': 0.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 3040/9322 [2:16:28<7:02:58,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1244, 'grad_norm': 0.22321361303329468, 'learning_rate': 8.52392976690266e-05, 'epoch': 0.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 3050/9322 [2:17:08<7:02:01,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1, 'grad_norm': 0.21633079648017883, 'learning_rate': 8.510621569388882e-05, 'epoch': 0.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 3060/9322 [2:17:48<7:01:39,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.123, 'grad_norm': 0.21518371999263763, 'learning_rate': 8.497264138130795e-05, 'epoch': 0.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 3070/9322 [2:18:29<7:00:51,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0385, 'grad_norm': 0.20726904273033142, 'learning_rate': 8.48385766045601e-05, 'epoch': 0.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 3080/9322 [2:19:09<7:00:08,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1161, 'grad_norm': 0.2155458927154541, 'learning_rate': 8.470402324379974e-05, 'epoch': 0.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 3090/9322 [2:19:50<6:59:17,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1075, 'grad_norm': 0.20518727600574493, 'learning_rate': 8.456898318603344e-05, 'epoch': 0.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 3100/9322 [2:20:30<6:58:34,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1229, 'grad_norm': 0.22438141703605652, 'learning_rate': 8.443345832509319e-05, 'epoch': 0.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 3110/9322 [2:21:10<6:58:14,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0984, 'grad_norm': 0.210627943277359, 'learning_rate': 8.429745056161011e-05, 'epoch': 0.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 3120/9322 [2:21:51<6:57:50,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1038, 'grad_norm': 0.207561194896698, 'learning_rate': 8.416096180298753e-05, 'epoch': 0.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 3130/9322 [2:22:31<6:57:01,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0877, 'grad_norm': 0.21599896252155304, 'learning_rate': 8.402399396337444e-05, 'epoch': 0.34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 3140/9322 [2:23:12<6:56:09,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0793, 'grad_norm': 0.2116883248090744, 'learning_rate': 8.388654896363853e-05, 'epoch': 0.34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 3150/9322 [2:23:52<6:55:25,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1256, 'grad_norm': 0.22215954959392548, 'learning_rate': 8.374862873133932e-05, 'epoch': 0.34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 3160/9322 [2:24:32<6:54:41,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0782, 'grad_norm': 0.22175684571266174, 'learning_rate': 8.361023520070106e-05, 'epoch': 0.34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 3170/9322 [2:25:13<6:54:26,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1305, 'grad_norm': 0.21172349154949188, 'learning_rate': 8.347137031258568e-05, 'epoch': 0.34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 3180/9322 [2:25:53<6:53:37,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0751, 'grad_norm': 0.22422508895397186, 'learning_rate': 8.333203601446552e-05, 'epoch': 0.34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 3190/9322 [2:26:34<6:53:14,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1326, 'grad_norm': 0.21666352450847626, 'learning_rate': 8.319223426039602e-05, 'epoch': 0.34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 3200/9322 [2:27:14<6:52:12,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1323, 'grad_norm': 0.21331313252449036, 'learning_rate': 8.305196701098833e-05, 'epoch': 0.34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 3210/9322 [2:27:55<6:51:54,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0987, 'grad_norm': 0.21486015617847443, 'learning_rate': 8.291123623338186e-05, 'epoch': 0.34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 3220/9322 [2:28:35<6:51:07,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1298, 'grad_norm': 0.2128881961107254, 'learning_rate': 8.277004390121655e-05, 'epoch': 0.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 3230/9322 [2:29:15<6:50:29,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0727, 'grad_norm': 0.2138930708169937, 'learning_rate': 8.262839199460536e-05, 'epoch': 0.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 3240/9322 [2:29:56<6:49:40,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1071, 'grad_norm': 0.2075796276330948, 'learning_rate': 8.248628250010637e-05, 'epoch': 0.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 3250/9322 [2:30:36<6:49:14,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1362, 'grad_norm': 0.2185944765806198, 'learning_rate': 8.234371741069507e-05, 'epoch': 0.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 3260/9322 [2:31:17<6:48:17,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0718, 'grad_norm': 0.2106158584356308, 'learning_rate': 8.220069872573618e-05, 'epoch': 0.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 3270/9322 [2:31:57<6:47:48,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0933, 'grad_norm': 0.21488942205905914, 'learning_rate': 8.205722845095584e-05, 'epoch': 0.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 3280/9322 [2:32:38<6:47:05,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0767, 'grad_norm': 0.21025501191616058, 'learning_rate': 8.191330859841341e-05, 'epoch': 0.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 3290/9322 [2:33:18<6:46:30,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0668, 'grad_norm': 0.20986618101596832, 'learning_rate': 8.176894118647311e-05, 'epoch': 0.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 3300/9322 [2:33:58<6:45:55,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1033, 'grad_norm': 0.21192307770252228, 'learning_rate': 8.162412823977595e-05, 'epoch': 0.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 3310/9322 [2:34:39<6:45:07,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1372, 'grad_norm': 0.22224178910255432, 'learning_rate': 8.147887178921117e-05, 'epoch': 0.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 3320/9322 [2:35:19<6:44:04,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0579, 'grad_norm': 0.22220775485038757, 'learning_rate': 8.133317387188781e-05, 'epoch': 0.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 3330/9322 [2:36:00<6:43:41,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1216, 'grad_norm': 0.21087828278541565, 'learning_rate': 8.118703653110614e-05, 'epoch': 0.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 3340/9322 [2:36:40<6:42:57,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1399, 'grad_norm': 0.20975051820278168, 'learning_rate': 8.104046181632899e-05, 'epoch': 0.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 3350/9322 [2:37:21<6:42:31,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1116, 'grad_norm': 0.20764334499835968, 'learning_rate': 8.089345178315306e-05, 'epoch': 0.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 3360/9322 [2:38:01<6:41:54,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1247, 'grad_norm': 0.21715788543224335, 'learning_rate': 8.074600849328003e-05, 'epoch': 0.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 3370/9322 [2:38:41<6:40:55,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1473, 'grad_norm': 0.21759885549545288, 'learning_rate': 8.059813401448766e-05, 'epoch': 0.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 3380/9322 [2:39:22<6:40:17,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1116, 'grad_norm': 0.21788236498832703, 'learning_rate': 8.044983042060079e-05, 'epoch': 0.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 3390/9322 [2:40:02<6:39:43,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1084, 'grad_norm': 0.22156964242458344, 'learning_rate': 8.030109979146231e-05, 'epoch': 0.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 3400/9322 [2:40:43<6:40:34,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1088, 'grad_norm': 0.20930635929107666, 'learning_rate': 8.015194421290393e-05, 'epoch': 0.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 3410/9322 [2:41:23<6:38:44,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1163, 'grad_norm': 0.21979545056819916, 'learning_rate': 8.000236577671691e-05, 'epoch': 0.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 3420/9322 [2:42:04<6:38:12,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.009, 'grad_norm': 0.2131783366203308, 'learning_rate': 7.985236658062281e-05, 'epoch': 0.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 3430/9322 [2:42:44<6:37:22,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1307, 'grad_norm': 0.22088800370693207, 'learning_rate': 7.9701948728244e-05, 'epoch': 0.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 3440/9322 [2:43:25<6:36:41,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0676, 'grad_norm': 0.2182118445634842, 'learning_rate': 7.955111432907416e-05, 'epoch': 0.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 3450/9322 [2:44:05<6:35:58,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1347, 'grad_norm': 0.22235389053821564, 'learning_rate': 7.939986549844874e-05, 'epoch': 0.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 3460/9322 [2:44:46<6:35:03,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0681, 'grad_norm': 0.21221069991588593, 'learning_rate': 7.92482043575153e-05, 'epoch': 0.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 3470/9322 [2:45:26<6:34:33,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0846, 'grad_norm': 0.2076101005077362, 'learning_rate': 7.909613303320365e-05, 'epoch': 0.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 3480/9322 [2:46:07<6:33:48,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1122, 'grad_norm': 0.21508623659610748, 'learning_rate': 7.894365365819618e-05, 'epoch': 0.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 3490/9322 [2:46:47<6:33:14,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1101, 'grad_norm': 0.2103666365146637, 'learning_rate': 7.879076837089786e-05, 'epoch': 0.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3500/9322 [2:47:28<6:32:31,  4.05s/it][INFO|trainer.py:3993] 2025-06-24 14:08:59,620 >> Saving model checkpoint to llama3-3b_lora_pretrain/checkpoint-3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1241, 'grad_norm': 0.2107885777950287, 'learning_rate': 7.863747931540621e-05, 'epoch': 0.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:698] 2025-06-24 14:09:01,111 >> loading configuration file config.json from cache at /home/ai-research-lab/.cache/huggingface/hub/models--meta-llama--LLaMA-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95/config.json\n",
      "[INFO|configuration_utils.py:770] 2025-06-24 14:09:01,111 >> Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128008,\n",
      "    128009\n",
      "  ],\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 131072,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 24,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": {\n",
      "    \"factor\": 32.0,\n",
      "    \"high_freq_factor\": 4.0,\n",
      "    \"low_freq_factor\": 1.0,\n",
      "    \"original_max_position_embeddings\": 8192,\n",
      "    \"rope_type\": \"llama3\"\n",
      "  },\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2356] 2025-06-24 14:09:01,199 >> chat template saved in llama3-3b_lora_pretrain/checkpoint-3500/chat_template.jinja\n",
      "[INFO|tokenization_utils_base.py:2525] 2025-06-24 14:09:01,200 >> tokenizer config file saved in llama3-3b_lora_pretrain/checkpoint-3500/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2534] 2025-06-24 14:09:01,200 >> Special tokens file saved in llama3-3b_lora_pretrain/checkpoint-3500/special_tokens_map.json\n",
      " 38%|███▊      | 3510/9322 [2:48:10<6:33:33,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1277, 'grad_norm': 0.21342821419239044, 'learning_rate': 7.848378864148134e-05, 'epoch': 0.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3520/9322 [2:48:50<6:31:16,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1356, 'grad_norm': 0.21099333465099335, 'learning_rate': 7.832969850451575e-05, 'epoch': 0.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3530/9322 [2:49:31<6:30:32,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1409, 'grad_norm': 0.20860973000526428, 'learning_rate': 7.817521106550407e-05, 'epoch': 0.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3540/9322 [2:50:11<6:29:47,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1659, 'grad_norm': 0.20666171610355377, 'learning_rate': 7.802032849101281e-05, 'epoch': 0.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3550/9322 [2:50:52<6:29:22,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0771, 'grad_norm': 0.2153516262769699, 'learning_rate': 7.786505295314991e-05, 'epoch': 0.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3560/9322 [2:51:32<6:28:22,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1192, 'grad_norm': 0.21056921780109406, 'learning_rate': 7.770938662953435e-05, 'epoch': 0.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3570/9322 [2:52:13<6:27:54,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0906, 'grad_norm': 0.21488559246063232, 'learning_rate': 7.755333170326557e-05, 'epoch': 0.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3580/9322 [2:52:53<6:27:01,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1078, 'grad_norm': 0.226096972823143, 'learning_rate': 7.739689036289289e-05, 'epoch': 0.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 3590/9322 [2:53:33<6:26:37,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0795, 'grad_norm': 0.20031924545764923, 'learning_rate': 7.724006480238469e-05, 'epoch': 0.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 3600/9322 [2:54:14<6:25:42,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0812, 'grad_norm': 0.2115015834569931, 'learning_rate': 7.708285722109785e-05, 'epoch': 0.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 3610/9322 [2:54:54<6:24:58,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1275, 'grad_norm': 0.2127465158700943, 'learning_rate': 7.692526982374675e-05, 'epoch': 0.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 3620/9322 [2:55:35<6:24:47,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0608, 'grad_norm': 0.21303297579288483, 'learning_rate': 7.676730482037239e-05, 'epoch': 0.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 3630/9322 [2:56:15<6:24:13,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1319, 'grad_norm': 0.21277643740177155, 'learning_rate': 7.660896442631142e-05, 'epoch': 0.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 3640/9322 [2:56:56<6:23:20,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1089, 'grad_norm': 0.2135479748249054, 'learning_rate': 7.645025086216501e-05, 'epoch': 0.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 3650/9322 [2:57:36<6:22:47,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.094, 'grad_norm': 0.21004930138587952, 'learning_rate': 7.62911663537678e-05, 'epoch': 0.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 3660/9322 [2:58:17<6:22:00,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0825, 'grad_norm': 0.2121649980545044, 'learning_rate': 7.613171313215663e-05, 'epoch': 0.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 3670/9322 [2:58:57<6:21:24,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1017, 'grad_norm': 0.2091565579175949, 'learning_rate': 7.597189343353925e-05, 'epoch': 0.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 3680/9322 [2:59:38<6:20:41,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0784, 'grad_norm': 0.22989092767238617, 'learning_rate': 7.581170949926294e-05, 'epoch': 0.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 3690/9322 [3:00:18<6:20:01,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0667, 'grad_norm': 0.21297793090343475, 'learning_rate': 7.565116357578312e-05, 'epoch': 0.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 3700/9322 [3:00:59<6:19:28,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0949, 'grad_norm': 0.21458294987678528, 'learning_rate': 7.549025791463184e-05, 'epoch': 0.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 3710/9322 [3:01:39<6:19:00,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0921, 'grad_norm': 0.21467186510562897, 'learning_rate': 7.532899477238619e-05, 'epoch': 0.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 3720/9322 [3:02:20<6:18:14,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0771, 'grad_norm': 0.2139175832271576, 'learning_rate': 7.516737641063664e-05, 'epoch': 0.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 3730/9322 [3:03:00<6:17:29,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1017, 'grad_norm': 0.21757735311985016, 'learning_rate': 7.500540509595533e-05, 'epoch': 0.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 3740/9322 [3:03:41<6:16:55,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0717, 'grad_norm': 0.21472586691379547, 'learning_rate': 7.484308309986434e-05, 'epoch': 0.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 3750/9322 [3:04:21<6:16:06,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1288, 'grad_norm': 0.2125895470380783, 'learning_rate': 7.468041269880373e-05, 'epoch': 0.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 3760/9322 [3:05:02<6:15:34,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0579, 'grad_norm': 0.21723124384880066, 'learning_rate': 7.45173961740997e-05, 'epoch': 0.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 3770/9322 [3:05:42<6:14:41,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0692, 'grad_norm': 0.21090471744537354, 'learning_rate': 7.435403581193253e-05, 'epoch': 0.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 3780/9322 [3:06:23<6:14:11,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1155, 'grad_norm': 0.21652741730213165, 'learning_rate': 7.419033390330462e-05, 'epoch': 0.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 3790/9322 [3:07:03<6:13:08,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1196, 'grad_norm': 0.2270786464214325, 'learning_rate': 7.402629274400823e-05, 'epoch': 0.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 3800/9322 [3:07:44<6:12:49,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1078, 'grad_norm': 0.22536838054656982, 'learning_rate': 7.386191463459338e-05, 'epoch': 0.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 3810/9322 [3:08:25<6:12:52,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1142, 'grad_norm': 0.21817126870155334, 'learning_rate': 7.369720188033554e-05, 'epoch': 0.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 3820/9322 [3:09:05<6:11:18,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1039, 'grad_norm': 0.2156520038843155, 'learning_rate': 7.353215679120334e-05, 'epoch': 0.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 3830/9322 [3:09:45<6:10:21,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0869, 'grad_norm': 0.22054070234298706, 'learning_rate': 7.33667816818261e-05, 'epoch': 0.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 3840/9322 [3:10:26<6:09:42,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1168, 'grad_norm': 0.21852818131446838, 'learning_rate': 7.320107887146146e-05, 'epoch': 0.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 3850/9322 [3:11:06<6:09:00,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1045, 'grad_norm': 0.21142391860485077, 'learning_rate': 7.30350506839628e-05, 'epoch': 0.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 3860/9322 [3:11:47<6:08:21,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0737, 'grad_norm': 0.21774514019489288, 'learning_rate': 7.286869944774665e-05, 'epoch': 0.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 3870/9322 [3:12:27<6:07:45,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1488, 'grad_norm': 0.21426312625408173, 'learning_rate': 7.270202749576009e-05, 'epoch': 0.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 3880/9322 [3:13:08<6:06:52,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0444, 'grad_norm': 0.29737401008605957, 'learning_rate': 7.253503716544792e-05, 'epoch': 0.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 3890/9322 [3:13:48<6:06:15,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.11, 'grad_norm': 0.21760419011116028, 'learning_rate': 7.236773079872001e-05, 'epoch': 0.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 3900/9322 [3:14:29<6:05:30,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.099, 'grad_norm': 0.20957598090171814, 'learning_rate': 7.220011074191838e-05, 'epoch': 0.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 3910/9322 [3:15:09<6:05:06,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0636, 'grad_norm': 0.22092171013355255, 'learning_rate': 7.203217934578428e-05, 'epoch': 0.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 3920/9322 [3:15:50<6:04:11,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1025, 'grad_norm': 0.22010518610477448, 'learning_rate': 7.18639389654253e-05, 'epoch': 0.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 3930/9322 [3:16:30<6:03:36,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1221, 'grad_norm': 0.21430206298828125, 'learning_rate': 7.169539196028223e-05, 'epoch': 0.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 3940/9322 [3:17:12<6:04:55,  4.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1137, 'grad_norm': 0.21616841852664948, 'learning_rate': 7.152654069409614e-05, 'epoch': 0.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 3950/9322 [3:17:52<6:02:25,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0983, 'grad_norm': 0.21508342027664185, 'learning_rate': 7.1357387534875e-05, 'epoch': 0.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 3960/9322 [3:18:34<6:02:16,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0621, 'grad_norm': 0.2055150419473648, 'learning_rate': 7.118793485486067e-05, 'epoch': 0.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 3970/9322 [3:19:14<6:01:06,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.092, 'grad_norm': 0.20392821729183197, 'learning_rate': 7.101818503049558e-05, 'epoch': 0.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 3980/9322 [3:19:55<6:00:07,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0724, 'grad_norm': 0.21939602494239807, 'learning_rate': 7.084814044238928e-05, 'epoch': 0.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 3990/9322 [3:20:35<5:59:48,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1478, 'grad_norm': 0.21036633849143982, 'learning_rate': 7.067780347528525e-05, 'epoch': 0.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 4000/9322 [3:21:16<5:59:00,  4.05s/it][INFO|trainer.py:3993] 2025-06-24 14:42:47,653 >> Saving model checkpoint to llama3-3b_lora_pretrain/checkpoint-4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0943, 'grad_norm': 0.2245354950428009, 'learning_rate': 7.050717651802733e-05, 'epoch': 0.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:698] 2025-06-24 14:42:49,184 >> loading configuration file config.json from cache at /home/ai-research-lab/.cache/huggingface/hub/models--meta-llama--LLaMA-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95/config.json\n",
      "[INFO|configuration_utils.py:770] 2025-06-24 14:42:49,185 >> Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128008,\n",
      "    128009\n",
      "  ],\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 131072,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 24,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": {\n",
      "    \"factor\": 32.0,\n",
      "    \"high_freq_factor\": 4.0,\n",
      "    \"low_freq_factor\": 1.0,\n",
      "    \"original_max_position_embeddings\": 8192,\n",
      "    \"rope_type\": \"llama3\"\n",
      "  },\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2356] 2025-06-24 14:42:49,382 >> chat template saved in llama3-3b_lora_pretrain/checkpoint-4000/chat_template.jinja\n",
      "[INFO|tokenization_utils_base.py:2525] 2025-06-24 14:42:49,386 >> tokenizer config file saved in llama3-3b_lora_pretrain/checkpoint-4000/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2534] 2025-06-24 14:42:49,386 >> Special tokens file saved in llama3-3b_lora_pretrain/checkpoint-4000/special_tokens_map.json\n",
      " 43%|████▎     | 4010/9322 [3:21:58<6:00:09,  4.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1375, 'grad_norm': 0.22083680331707, 'learning_rate': 7.033626196352623e-05, 'epoch': 0.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 4020/9322 [3:22:39<5:57:33,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0829, 'grad_norm': 0.21467413008213043, 'learning_rate': 7.016506220872598e-05, 'epoch': 0.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 4030/9322 [3:23:19<5:56:55,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.104, 'grad_norm': 0.21921873092651367, 'learning_rate': 6.999357965457037e-05, 'epoch': 0.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 4040/9322 [3:24:00<5:56:03,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0981, 'grad_norm': 0.21628712117671967, 'learning_rate': 6.982181670596918e-05, 'epoch': 0.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 4050/9322 [3:24:40<5:55:35,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.139, 'grad_norm': 0.20697136223316193, 'learning_rate': 6.964977577176453e-05, 'epoch': 0.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 4060/9322 [3:25:21<5:54:52,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0883, 'grad_norm': 0.22277292609214783, 'learning_rate': 6.94774592646971e-05, 'epoch': 0.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 4070/9322 [3:26:01<5:54:32,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1147, 'grad_norm': 0.21815940737724304, 'learning_rate': 6.930486960137219e-05, 'epoch': 0.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 4080/9322 [3:26:42<5:53:44,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1123, 'grad_norm': 0.2187817394733429, 'learning_rate': 6.913200920222598e-05, 'epoch': 0.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 4090/9322 [3:27:22<5:53:09,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1206, 'grad_norm': 0.24525684118270874, 'learning_rate': 6.895888049149147e-05, 'epoch': 0.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 4100/9322 [3:28:03<5:52:23,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0713, 'grad_norm': 0.2117684930562973, 'learning_rate': 6.878548589716452e-05, 'epoch': 0.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 4110/9322 [3:28:43<5:51:54,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1274, 'grad_norm': 0.21350809931755066, 'learning_rate': 6.861182785096983e-05, 'epoch': 0.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 4120/9322 [3:29:24<5:51:01,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0718, 'grad_norm': 0.21470297873020172, 'learning_rate': 6.843790878832679e-05, 'epoch': 0.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 4130/9322 [3:30:04<5:50:26,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1329, 'grad_norm': 0.21192997694015503, 'learning_rate': 6.826373114831532e-05, 'epoch': 0.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 4140/9322 [3:30:45<5:49:32,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0812, 'grad_norm': 0.2228626012802124, 'learning_rate': 6.808929737364176e-05, 'epoch': 0.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 4150/9322 [3:31:25<5:49:15,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1556, 'grad_norm': 0.22132468223571777, 'learning_rate': 6.791460991060443e-05, 'epoch': 0.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 4160/9322 [3:32:06<5:48:42,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0999, 'grad_norm': 0.22028958797454834, 'learning_rate': 6.773967120905955e-05, 'epoch': 0.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 4170/9322 [3:32:46<5:48:00,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1297, 'grad_norm': 0.2125990092754364, 'learning_rate': 6.756448372238667e-05, 'epoch': 0.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 4180/9322 [3:33:27<5:47:32,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0712, 'grad_norm': 0.21925120055675507, 'learning_rate': 6.738904990745442e-05, 'epoch': 0.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 4190/9322 [3:34:07<5:46:43,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1632, 'grad_norm': 0.22140327095985413, 'learning_rate': 6.721337222458595e-05, 'epoch': 0.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 4200/9322 [3:34:48<5:46:04,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0888, 'grad_norm': 0.21138668060302734, 'learning_rate': 6.70374531375245e-05, 'epoch': 0.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 4210/9322 [3:35:28<5:45:20,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1375, 'grad_norm': 0.2144152820110321, 'learning_rate': 6.68612951133988e-05, 'epoch': 0.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 4220/9322 [3:36:09<5:44:58,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1044, 'grad_norm': 0.21495142579078674, 'learning_rate': 6.66849006226885e-05, 'epoch': 0.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 4230/9322 [3:36:50<5:44:12,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0842, 'grad_norm': 0.21679846942424774, 'learning_rate': 6.650827213918951e-05, 'epoch': 0.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 4240/9322 [3:37:30<5:43:52,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.063, 'grad_norm': 0.21757115423679352, 'learning_rate': 6.633141213997926e-05, 'epoch': 0.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 4250/9322 [3:38:11<5:43:03,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.094, 'grad_norm': 0.21358110010623932, 'learning_rate': 6.61543231053821e-05, 'epoch': 0.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 4260/9322 [3:38:51<5:42:20,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0854, 'grad_norm': 0.21844017505645752, 'learning_rate': 6.597700751893434e-05, 'epoch': 0.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 4270/9322 [3:39:32<5:41:42,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0347, 'grad_norm': 0.229159414768219, 'learning_rate': 6.579946786734956e-05, 'epoch': 0.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 4280/9322 [3:40:12<5:40:53,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0485, 'grad_norm': 0.21479980647563934, 'learning_rate': 6.562170664048361e-05, 'epoch': 0.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 4290/9322 [3:40:53<5:40:04,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9706, 'grad_norm': 0.22223852574825287, 'learning_rate': 6.544372633129985e-05, 'epoch': 0.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 4300/9322 [3:41:34<5:39:12,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1091, 'grad_norm': 0.21675258874893188, 'learning_rate': 6.526552943583403e-05, 'epoch': 0.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 4310/9322 [3:42:14<5:38:39,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1251, 'grad_norm': 0.21915467083454132, 'learning_rate': 6.50871184531594e-05, 'epoch': 0.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 4320/9322 [3:42:55<5:37:52,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0784, 'grad_norm': 0.21016083657741547, 'learning_rate': 6.490849588535159e-05, 'epoch': 0.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 4330/9322 [3:43:35<5:37:10,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1144, 'grad_norm': 0.22063444554805756, 'learning_rate': 6.472966423745356e-05, 'epoch': 0.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 4340/9322 [3:44:16<5:36:33,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.147, 'grad_norm': 0.20937427878379822, 'learning_rate': 6.455062601744045e-05, 'epoch': 0.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 4350/9322 [3:44:56<5:35:57,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0761, 'grad_norm': 0.22368250787258148, 'learning_rate': 6.437138373618441e-05, 'epoch': 0.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 4360/9322 [3:45:37<5:34:55,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1043, 'grad_norm': 0.21602651476860046, 'learning_rate': 6.41919399074194e-05, 'epoch': 0.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 4370/9322 [3:46:17<5:34:10,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0814, 'grad_norm': 0.22154554724693298, 'learning_rate': 6.40122970477059e-05, 'epoch': 0.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 4380/9322 [3:46:58<5:33:36,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0472, 'grad_norm': 0.21779772639274597, 'learning_rate': 6.383245767639573e-05, 'epoch': 0.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 4390/9322 [3:47:38<5:33:00,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.114, 'grad_norm': 0.20765787363052368, 'learning_rate': 6.36524243155965e-05, 'epoch': 0.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 4400/9322 [3:48:19<5:32:17,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.095, 'grad_norm': 0.2225305587053299, 'learning_rate': 6.347219949013649e-05, 'epoch': 0.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 4410/9322 [3:48:59<5:31:37,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1194, 'grad_norm': 0.2099052220582962, 'learning_rate': 6.329178572752905e-05, 'epoch': 0.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 4420/9322 [3:49:40<5:30:55,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1019, 'grad_norm': 0.217523992061615, 'learning_rate': 6.311118555793725e-05, 'epoch': 0.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 4430/9322 [3:50:20<5:30:26,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1216, 'grad_norm': 0.21279391646385193, 'learning_rate': 6.293040151413842e-05, 'epoch': 0.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 4440/9322 [3:51:01<5:29:26,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0761, 'grad_norm': 0.21028874814510345, 'learning_rate': 6.274943613148849e-05, 'epoch': 0.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 4450/9322 [3:51:41<5:29:03,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1076, 'grad_norm': 0.21118119359016418, 'learning_rate': 6.256829194788658e-05, 'epoch': 0.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 4460/9322 [3:52:22<5:28:10,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0894, 'grad_norm': 0.21097636222839355, 'learning_rate': 6.23869715037394e-05, 'epoch': 0.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 4470/9322 [3:53:02<5:27:33,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1585, 'grad_norm': 0.22094987332820892, 'learning_rate': 6.220547734192547e-05, 'epoch': 0.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 4480/9322 [3:53:43<5:28:09,  4.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0786, 'grad_norm': 0.2159237563610077, 'learning_rate': 6.202381200775966e-05, 'epoch': 0.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 4490/9322 [3:54:23<5:26:14,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0559, 'grad_norm': 0.27351534366607666, 'learning_rate': 6.184197804895733e-05, 'epoch': 0.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 4500/9322 [3:55:04<5:25:31,  4.05s/it][INFO|trainer.py:3993] 2025-06-24 15:16:35,970 >> Saving model checkpoint to llama3-3b_lora_pretrain/checkpoint-4500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0989, 'grad_norm': 0.2207118719816208, 'learning_rate': 6.165997801559874e-05, 'epoch': 0.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:698] 2025-06-24 15:16:37,480 >> loading configuration file config.json from cache at /home/ai-research-lab/.cache/huggingface/hub/models--meta-llama--LLaMA-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95/config.json\n",
      "[INFO|configuration_utils.py:770] 2025-06-24 15:16:37,481 >> Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128008,\n",
      "    128009\n",
      "  ],\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 131072,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 24,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": {\n",
      "    \"factor\": 32.0,\n",
      "    \"high_freq_factor\": 4.0,\n",
      "    \"low_freq_factor\": 1.0,\n",
      "    \"original_max_position_embeddings\": 8192,\n",
      "    \"rope_type\": \"llama3\"\n",
      "  },\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2356] 2025-06-24 15:16:37,646 >> chat template saved in llama3-3b_lora_pretrain/checkpoint-4500/chat_template.jinja\n",
      "[INFO|tokenization_utils_base.py:2525] 2025-06-24 15:16:37,647 >> tokenizer config file saved in llama3-3b_lora_pretrain/checkpoint-4500/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2534] 2025-06-24 15:16:37,647 >> Special tokens file saved in llama3-3b_lora_pretrain/checkpoint-4500/special_tokens_map.json\n",
      " 48%|████▊     | 4510/9322 [3:55:46<5:26:32,  4.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.11, 'grad_norm': 0.21041785180568695, 'learning_rate': 6.147781446009317e-05, 'epoch': 0.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 4520/9322 [3:56:27<5:24:09,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0881, 'grad_norm': 0.2253263294696808, 'learning_rate': 6.129548993714316e-05, 'epoch': 0.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 4530/9322 [3:57:07<5:23:42,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0608, 'grad_norm': 0.21625612676143646, 'learning_rate': 6.111300700370874e-05, 'epoch': 0.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 4540/9322 [3:57:48<5:22:55,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1051, 'grad_norm': 0.2119084596633911, 'learning_rate': 6.093036821897147e-05, 'epoch': 0.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 4550/9322 [3:58:28<5:22:25,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0619, 'grad_norm': 0.217506542801857, 'learning_rate': 6.0747576144298665e-05, 'epoch': 0.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 4560/9322 [3:59:09<5:21:39,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1107, 'grad_norm': 0.2211492508649826, 'learning_rate': 6.056463334320738e-05, 'epoch': 0.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 4570/9322 [3:59:49<5:20:54,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0984, 'grad_norm': 0.23020733892917633, 'learning_rate': 6.0381542381328445e-05, 'epoch': 0.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 4580/9322 [4:00:30<5:20:06,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.072, 'grad_norm': 0.2182679921388626, 'learning_rate': 6.019830582637064e-05, 'epoch': 0.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 4590/9322 [4:01:11<5:19:40,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1031, 'grad_norm': 0.21241196990013123, 'learning_rate': 6.0014926248084456e-05, 'epoch': 0.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 4600/9322 [4:01:51<5:18:54,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0392, 'grad_norm': 0.22233951091766357, 'learning_rate': 5.983140621822626e-05, 'epoch': 0.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 4610/9322 [4:02:32<5:18:19,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0957, 'grad_norm': 0.21927037835121155, 'learning_rate': 5.964774831052211e-05, 'epoch': 0.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 4620/9322 [4:03:12<5:17:38,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0785, 'grad_norm': 0.22201254963874817, 'learning_rate': 5.9463955100631684e-05, 'epoch': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 4630/9322 [4:03:53<5:16:54,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0922, 'grad_norm': 0.2227252721786499, 'learning_rate': 5.928002916611221e-05, 'epoch': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 4640/9322 [4:04:33<5:16:09,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0513, 'grad_norm': 0.2162170261144638, 'learning_rate': 5.909597308638222e-05, 'epoch': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 4650/9322 [4:05:14<5:15:29,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0704, 'grad_norm': 0.24567916989326477, 'learning_rate': 5.891178944268546e-05, 'epoch': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 4660/9322 [4:05:54<5:14:56,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1246, 'grad_norm': 0.22338761389255524, 'learning_rate': 5.872748081805468e-05, 'epoch': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 4670/9322 [4:06:35<5:14:21,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1101, 'grad_norm': 0.22143368422985077, 'learning_rate': 5.8543049797275365e-05, 'epoch': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 4680/9322 [4:07:15<5:13:32,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0835, 'grad_norm': 0.2120606154203415, 'learning_rate': 5.8358498966849507e-05, 'epoch': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 4690/9322 [4:07:56<5:12:53,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.034, 'grad_norm': 0.22450685501098633, 'learning_rate': 5.817383091495935e-05, 'epoch': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 4700/9322 [4:08:36<5:12:10,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0953, 'grad_norm': 0.2178938388824463, 'learning_rate': 5.79890482314311e-05, 'epoch': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 4710/9322 [4:09:17<5:11:28,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0931, 'grad_norm': 0.2293740212917328, 'learning_rate': 5.7804153507698514e-05, 'epoch': 0.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 4720/9322 [4:09:57<5:10:53,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0328, 'grad_norm': 0.21465496718883514, 'learning_rate': 5.7619149336766686e-05, 'epoch': 0.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 4730/9322 [4:10:38<5:10:13,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1134, 'grad_norm': 0.21971246600151062, 'learning_rate': 5.743403831317562e-05, 'epoch': 0.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 4740/9322 [4:11:18<5:09:25,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1017, 'grad_norm': 0.21638734638690948, 'learning_rate': 5.724882303296381e-05, 'epoch': 0.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 4750/9322 [4:11:59<5:08:57,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0438, 'grad_norm': 0.22714155912399292, 'learning_rate': 5.706350609363191e-05, 'epoch': 0.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 4760/9322 [4:12:40<5:08:48,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1048, 'grad_norm': 0.21904043853282928, 'learning_rate': 5.687809009410623e-05, 'epoch': 0.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 4770/9322 [4:13:20<5:07:47,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0772, 'grad_norm': 0.22117850184440613, 'learning_rate': 5.669257763470232e-05, 'epoch': 0.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 4780/9322 [4:14:01<5:07:27,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0437, 'grad_norm': 0.2277885526418686, 'learning_rate': 5.6506971317088566e-05, 'epoch': 0.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 4790/9322 [4:14:41<5:06:40,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0868, 'grad_norm': 0.22021432220935822, 'learning_rate': 5.6321273744249536e-05, 'epoch': 0.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 4800/9322 [4:15:22<5:05:40,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0844, 'grad_norm': 0.2247849553823471, 'learning_rate': 5.6135487520449693e-05, 'epoch': 0.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 4810/9322 [4:16:03<5:05:12,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0628, 'grad_norm': 0.22323891520500183, 'learning_rate': 5.5949615251196685e-05, 'epoch': 0.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 4820/9322 [4:16:43<5:04:32,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0567, 'grad_norm': 0.21908116340637207, 'learning_rate': 5.576365954320494e-05, 'epoch': 0.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 4830/9322 [4:17:24<5:03:56,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0552, 'grad_norm': 0.22809839248657227, 'learning_rate': 5.557762300435896e-05, 'epoch': 0.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 4840/9322 [4:18:04<5:03:14,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1003, 'grad_norm': 0.22438809275627136, 'learning_rate': 5.539150824367694e-05, 'epoch': 0.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 4850/9322 [4:18:45<5:02:40,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.132, 'grad_norm': 0.22664420306682587, 'learning_rate': 5.520531787127401e-05, 'epoch': 0.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 4860/9322 [4:19:26<5:02:05,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0273, 'grad_norm': 0.22282083332538605, 'learning_rate': 5.501905449832571e-05, 'epoch': 0.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 4870/9322 [4:20:06<5:01:24,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1, 'grad_norm': 0.22125035524368286, 'learning_rate': 5.4832720737031376e-05, 'epoch': 0.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 4880/9322 [4:20:47<5:00:23,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0461, 'grad_norm': 0.2267526239156723, 'learning_rate': 5.4646319200577454e-05, 'epoch': 0.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 4890/9322 [4:21:27<4:59:47,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1109, 'grad_norm': 0.22568485140800476, 'learning_rate': 5.445985250310092e-05, 'epoch': 0.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 4900/9322 [4:22:08<4:59:04,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1075, 'grad_norm': 0.2171049565076828, 'learning_rate': 5.427332325965255e-05, 'epoch': 0.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 4910/9322 [4:22:49<4:58:32,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0876, 'grad_norm': 0.2274179905653, 'learning_rate': 5.4086734086160284e-05, 'epoch': 0.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 4920/9322 [4:23:29<4:57:42,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0876, 'grad_norm': 0.22816281020641327, 'learning_rate': 5.390008759939256e-05, 'epoch': 0.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 4930/9322 [4:24:10<4:56:55,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1473, 'grad_norm': 0.2191290408372879, 'learning_rate': 5.3713386416921565e-05, 'epoch': 0.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 4940/9322 [4:24:50<4:55:56,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0823, 'grad_norm': 0.21860606968402863, 'learning_rate': 5.3526633157086557e-05, 'epoch': 0.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 4950/9322 [4:25:31<4:55:34,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0523, 'grad_norm': 0.21718519926071167, 'learning_rate': 5.333983043895714e-05, 'epoch': 0.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 4960/9322 [4:26:11<4:54:54,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0995, 'grad_norm': 0.2282615602016449, 'learning_rate': 5.315298088229653e-05, 'epoch': 0.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 4970/9322 [4:26:52<4:54:23,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0737, 'grad_norm': 0.2207747995853424, 'learning_rate': 5.296608710752484e-05, 'epoch': 0.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 4980/9322 [4:27:33<4:53:41,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0957, 'grad_norm': 0.23023834824562073, 'learning_rate': 5.277915173568225e-05, 'epoch': 0.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 4990/9322 [4:28:13<4:53:02,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1375, 'grad_norm': 0.21272194385528564, 'learning_rate': 5.2592177388392374e-05, 'epoch': 0.54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 5000/9322 [4:28:54<4:52:20,  4.06s/it][INFO|trainer.py:3993] 2025-06-24 15:50:25,741 >> Saving model checkpoint to llama3-3b_lora_pretrain/checkpoint-5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0931, 'grad_norm': 0.2172388732433319, 'learning_rate': 5.240516668782539e-05, 'epoch': 0.54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:698] 2025-06-24 15:50:26,924 >> loading configuration file config.json from cache at /home/ai-research-lab/.cache/huggingface/hub/models--meta-llama--LLaMA-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95/config.json\n",
      "[INFO|configuration_utils.py:770] 2025-06-24 15:50:26,925 >> Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128008,\n",
      "    128009\n",
      "  ],\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 131072,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 24,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": {\n",
      "    \"factor\": 32.0,\n",
      "    \"high_freq_factor\": 4.0,\n",
      "    \"low_freq_factor\": 1.0,\n",
      "    \"original_max_position_embeddings\": 8192,\n",
      "    \"rope_type\": \"llama3\"\n",
      "  },\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2356] 2025-06-24 15:50:27,092 >> chat template saved in llama3-3b_lora_pretrain/checkpoint-5000/chat_template.jinja\n",
      "[INFO|tokenization_utils_base.py:2525] 2025-06-24 15:50:27,093 >> tokenizer config file saved in llama3-3b_lora_pretrain/checkpoint-5000/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2534] 2025-06-24 15:50:27,093 >> Special tokens file saved in llama3-3b_lora_pretrain/checkpoint-5000/special_tokens_map.json\n",
      " 54%|█████▎    | 5010/9322 [4:29:36<4:52:45,  4.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1281, 'grad_norm': 0.22019168734550476, 'learning_rate': 5.22181222566613e-05, 'epoch': 0.54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 5020/9322 [4:30:16<4:50:38,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1087, 'grad_norm': 0.21833665668964386, 'learning_rate': 5.203104671805317e-05, 'epoch': 0.54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 5030/9322 [4:30:57<4:50:00,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0862, 'grad_norm': 0.21775943040847778, 'learning_rate': 5.1843942695590295e-05, 'epoch': 0.54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 5040/9322 [4:31:38<4:50:12,  4.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0942, 'grad_norm': 0.23345521092414856, 'learning_rate': 5.165681281326147e-05, 'epoch': 0.54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 5050/9322 [4:32:18<4:48:44,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1416, 'grad_norm': 0.21882374584674835, 'learning_rate': 5.146965969541815e-05, 'epoch': 0.54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 5060/9322 [4:32:59<4:48:00,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1164, 'grad_norm': 0.2222488820552826, 'learning_rate': 5.12824859667376e-05, 'epoch': 0.54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 5070/9322 [4:33:39<4:47:02,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0784, 'grad_norm': 0.2230827659368515, 'learning_rate': 5.109529425218621e-05, 'epoch': 0.54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 5080/9322 [4:34:20<4:46:16,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0637, 'grad_norm': 0.2227364331483841, 'learning_rate': 5.0908087176982546e-05, 'epoch': 0.54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 5090/9322 [4:35:00<4:45:32,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0916, 'grad_norm': 0.22796371579170227, 'learning_rate': 5.0720867366560644e-05, 'epoch': 0.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 5100/9322 [4:35:41<4:44:53,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1167, 'grad_norm': 0.24076691269874573, 'learning_rate': 5.05336374465331e-05, 'epoch': 0.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 5110/9322 [4:36:21<4:44:22,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1639, 'grad_norm': 0.21645992994308472, 'learning_rate': 5.0346400042654305e-05, 'epoch': 0.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 5120/9322 [4:37:02<4:43:35,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1073, 'grad_norm': 0.2260187417268753, 'learning_rate': 5.0159157780783615e-05, 'epoch': 0.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 5130/9322 [4:37:42<4:42:53,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0803, 'grad_norm': 0.2157033383846283, 'learning_rate': 4.997191328684852e-05, 'epoch': 0.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 5140/9322 [4:38:23<4:42:15,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1156, 'grad_norm': 0.22664204239845276, 'learning_rate': 4.978466918680779e-05, 'epoch': 0.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 5150/9322 [4:39:03<4:41:35,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0867, 'grad_norm': 0.23248271644115448, 'learning_rate': 4.959742810661467e-05, 'epoch': 0.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 5160/9322 [4:39:44<4:40:29,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1019, 'grad_norm': 0.22635267674922943, 'learning_rate': 4.94101926721801e-05, 'epoch': 0.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 5170/9322 [4:40:24<4:39:42,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1141, 'grad_norm': 0.21468688547611237, 'learning_rate': 4.9222965509335755e-05, 'epoch': 0.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 5180/9322 [4:41:04<4:38:48,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0946, 'grad_norm': 0.23065818846225739, 'learning_rate': 4.903574924379741e-05, 'epoch': 0.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 5190/9322 [4:41:45<4:37:50,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1081, 'grad_norm': 0.20995557308197021, 'learning_rate': 4.884854650112796e-05, 'epoch': 0.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 5200/9322 [4:42:25<4:37:06,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0879, 'grad_norm': 0.21750013530254364, 'learning_rate': 4.8661359906700634e-05, 'epoch': 0.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 5210/9322 [4:43:05<4:36:22,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0959, 'grad_norm': 0.22037313878536224, 'learning_rate': 4.847419208566223e-05, 'epoch': 0.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 5220/9322 [4:43:46<4:35:39,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0591, 'grad_norm': 0.22795182466506958, 'learning_rate': 4.8287045662896255e-05, 'epoch': 0.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 5230/9322 [4:44:26<4:35:16,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0698, 'grad_norm': 0.22527381777763367, 'learning_rate': 4.809992326298609e-05, 'epoch': 0.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 5240/9322 [4:45:07<4:34:38,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1187, 'grad_norm': 0.22317606210708618, 'learning_rate': 4.791282751017829e-05, 'epoch': 0.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 5250/9322 [4:45:47<4:34:04,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1297, 'grad_norm': 0.2125529646873474, 'learning_rate': 4.7725761028345635e-05, 'epoch': 0.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 5260/9322 [4:46:27<4:33:17,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1437, 'grad_norm': 0.2282009720802307, 'learning_rate': 4.753872644095042e-05, 'epoch': 0.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 5270/9322 [4:47:08<4:32:44,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.064, 'grad_norm': 0.2431432604789734, 'learning_rate': 4.735172637100765e-05, 'epoch': 0.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 5280/9322 [4:47:48<4:32:06,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0687, 'grad_norm': 0.22072014212608337, 'learning_rate': 4.716476344104826e-05, 'epoch': 0.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 5290/9322 [4:48:28<4:31:30,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0818, 'grad_norm': 0.23072926700115204, 'learning_rate': 4.697784027308228e-05, 'epoch': 0.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 5300/9322 [4:49:09<4:30:47,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1225, 'grad_norm': 0.21344980597496033, 'learning_rate': 4.6790959488562195e-05, 'epoch': 0.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 5310/9322 [4:49:49<4:29:56,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1119, 'grad_norm': 0.22390006482601166, 'learning_rate': 4.660412370834601e-05, 'epoch': 0.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 5320/9322 [4:50:30<4:29:15,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.109, 'grad_norm': 0.22780923545360565, 'learning_rate': 4.641733555266065e-05, 'epoch': 0.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 5330/9322 [4:51:10<4:27:59,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0917, 'grad_norm': 0.21567372977733612, 'learning_rate': 4.623059764106505e-05, 'epoch': 0.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 5340/9322 [4:51:50<4:27:26,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.085, 'grad_norm': 0.22187171876430511, 'learning_rate': 4.6043912592413604e-05, 'epoch': 0.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 5350/9322 [4:52:31<4:26:56,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0924, 'grad_norm': 0.2255663275718689, 'learning_rate': 4.585728302481929e-05, 'epoch': 0.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 5360/9322 [4:53:11<4:26:09,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1024, 'grad_norm': 0.21689966320991516, 'learning_rate': 4.567071155561704e-05, 'epoch': 0.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 5370/9322 [4:53:51<4:25:26,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0661, 'grad_norm': 0.22484897077083588, 'learning_rate': 4.5484200801326996e-05, 'epoch': 0.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 5380/9322 [4:54:32<4:24:40,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0555, 'grad_norm': 0.23389987647533417, 'learning_rate': 4.5297753377617774e-05, 'epoch': 0.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 5390/9322 [4:55:12<4:23:44,  4.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1559, 'grad_norm': 0.22459019720554352, 'learning_rate': 4.51113718992699e-05, 'epoch': 0.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 5400/9322 [4:55:52<4:23:09,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0897, 'grad_norm': 0.23061172664165497, 'learning_rate': 4.492505898013899e-05, 'epoch': 0.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 5410/9322 [4:56:32<4:22:20,  4.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0919, 'grad_norm': 0.2251240611076355, 'learning_rate': 4.473881723311925e-05, 'epoch': 0.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 5420/9322 [4:57:13<4:21:34,  4.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0955, 'grad_norm': 0.22934748232364655, 'learning_rate': 4.45526492701067e-05, 'epoch': 0.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 5430/9322 [4:57:53<4:20:53,  4.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1505, 'grad_norm': 0.2185167521238327, 'learning_rate': 4.436655770196261e-05, 'epoch': 0.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 5440/9322 [4:58:33<4:20:08,  4.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1077, 'grad_norm': 0.23245510458946228, 'learning_rate': 4.4180545138476874e-05, 'epoch': 0.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 5450/9322 [4:59:13<4:19:28,  4.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1199, 'grad_norm': 0.2204321026802063, 'learning_rate': 4.39946141883314e-05, 'epoch': 0.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 5460/9322 [4:59:53<4:18:39,  4.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0625, 'grad_norm': 0.22904516756534576, 'learning_rate': 4.380876745906351e-05, 'epoch': 0.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 5470/9322 [5:00:33<4:17:43,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0627, 'grad_norm': 0.22388677299022675, 'learning_rate': 4.3623007557029484e-05, 'epoch': 0.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 5480/9322 [5:01:14<4:16:47,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0945, 'grad_norm': 0.22436219453811646, 'learning_rate': 4.3437337087367796e-05, 'epoch': 0.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 5490/9322 [5:01:54<4:16:19,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0866, 'grad_norm': 0.22899532318115234, 'learning_rate': 4.3251758653962795e-05, 'epoch': 0.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 5500/9322 [5:02:34<4:15:38,  4.01s/it][INFO|trainer.py:3993] 2025-06-24 16:24:05,881 >> Saving model checkpoint to llama3-3b_lora_pretrain/checkpoint-5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0608, 'grad_norm': 0.21766091883182526, 'learning_rate': 4.306627485940803e-05, 'epoch': 0.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:698] 2025-06-24 16:24:07,042 >> loading configuration file config.json from cache at /home/ai-research-lab/.cache/huggingface/hub/models--meta-llama--LLaMA-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95/config.json\n",
      "[INFO|configuration_utils.py:770] 2025-06-24 16:24:07,043 >> Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128008,\n",
      "    128009\n",
      "  ],\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 131072,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 24,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": {\n",
      "    \"factor\": 32.0,\n",
      "    \"high_freq_factor\": 4.0,\n",
      "    \"low_freq_factor\": 1.0,\n",
      "    \"original_max_position_embeddings\": 8192,\n",
      "    \"rope_type\": \"llama3\"\n",
      "  },\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2356] 2025-06-24 16:24:07,166 >> chat template saved in llama3-3b_lora_pretrain/checkpoint-5500/chat_template.jinja\n",
      "[INFO|tokenization_utils_base.py:2525] 2025-06-24 16:24:07,168 >> tokenizer config file saved in llama3-3b_lora_pretrain/checkpoint-5500/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2534] 2025-06-24 16:24:07,168 >> Special tokens file saved in llama3-3b_lora_pretrain/checkpoint-5500/special_tokens_map.json\n",
      " 59%|█████▉    | 5510/9322 [5:03:16<4:16:07,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0975, 'grad_norm': 0.22665368020534515, 'learning_rate': 4.2880888304969854e-05, 'epoch': 0.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 5520/9322 [5:03:56<4:14:25,  4.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.063, 'grad_norm': 0.22915925085544586, 'learning_rate': 4.269560159055087e-05, 'epoch': 0.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 5530/9322 [5:04:36<4:13:46,  4.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1235, 'grad_norm': 0.21841667592525482, 'learning_rate': 4.251041731465354e-05, 'epoch': 0.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 5540/9322 [5:05:16<4:13:19,  4.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0773, 'grad_norm': 0.21995222568511963, 'learning_rate': 4.2325338074343685e-05, 'epoch': 0.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 5550/9322 [5:05:56<4:12:42,  4.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0823, 'grad_norm': 0.23788917064666748, 'learning_rate': 4.214036646521407e-05, 'epoch': 0.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 5560/9322 [5:06:36<4:11:39,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0377, 'grad_norm': 0.23288002610206604, 'learning_rate': 4.195550508134805e-05, 'epoch': 0.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 5570/9322 [5:07:16<4:10:38,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1068, 'grad_norm': 0.22049742937088013, 'learning_rate': 4.177075651528311e-05, 'epoch': 0.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 5580/9322 [5:07:57<4:10:09,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0863, 'grad_norm': 0.23186591267585754, 'learning_rate': 4.158612335797458e-05, 'epoch': 0.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 5590/9322 [5:08:37<4:09:16,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1008, 'grad_norm': 0.21943706274032593, 'learning_rate': 4.140160819875931e-05, 'epoch': 0.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 5600/9322 [5:09:17<4:08:05,  4.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0828, 'grad_norm': 0.21909666061401367, 'learning_rate': 4.121721362531924e-05, 'epoch': 0.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 5610/9322 [5:09:57<4:06:48,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0712, 'grad_norm': 0.22720180451869965, 'learning_rate': 4.1032942223645246e-05, 'epoch': 0.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 5620/9322 [5:10:36<4:05:47,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0871, 'grad_norm': 0.2212880253791809, 'learning_rate': 4.0848796578000785e-05, 'epoch': 0.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 5630/9322 [5:11:16<4:04:55,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1008, 'grad_norm': 0.22082564234733582, 'learning_rate': 4.0664779270885704e-05, 'epoch': 0.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 5640/9322 [5:11:56<4:03:50,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1058, 'grad_norm': 0.2296365648508072, 'learning_rate': 4.048089288299997e-05, 'epoch': 0.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 5650/9322 [5:12:36<4:03:02,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0887, 'grad_norm': 0.22795626521110535, 'learning_rate': 4.029713999320756e-05, 'epoch': 0.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 5660/9322 [5:13:15<4:02:12,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.109, 'grad_norm': 0.21969036757946014, 'learning_rate': 4.0113523178500224e-05, 'epoch': 0.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 5670/9322 [5:13:55<4:01:27,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0965, 'grad_norm': 0.2237507849931717, 'learning_rate': 3.9930045013961314e-05, 'epoch': 0.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 5680/9322 [5:14:35<4:00:26,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.141, 'grad_norm': 0.22061604261398315, 'learning_rate': 3.9746708072729805e-05, 'epoch': 0.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 5690/9322 [5:15:14<3:59:57,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0785, 'grad_norm': 0.23069685697555542, 'learning_rate': 3.956351492596405e-05, 'epoch': 0.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 5700/9322 [5:15:54<3:59:01,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0886, 'grad_norm': 0.21415941417217255, 'learning_rate': 3.938046814280584e-05, 'epoch': 0.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 5710/9322 [5:16:34<3:58:29,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0898, 'grad_norm': 0.2155791074037552, 'learning_rate': 3.919757029034433e-05, 'epoch': 0.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 5720/9322 [5:17:13<3:57:30,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1388, 'grad_norm': 0.22581610083580017, 'learning_rate': 3.901482393358002e-05, 'epoch': 0.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 5730/9322 [5:17:53<3:57:00,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0442, 'grad_norm': 0.21883973479270935, 'learning_rate': 3.883223163538881e-05, 'epoch': 0.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 5740/9322 [5:18:32<3:56:20,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1151, 'grad_norm': 0.2255222350358963, 'learning_rate': 3.8649795956486026e-05, 'epoch': 0.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 5750/9322 [5:19:12<3:55:36,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1152, 'grad_norm': 0.21125197410583496, 'learning_rate': 3.8467519455390584e-05, 'epoch': 0.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 5760/9322 [5:19:51<3:54:51,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0864, 'grad_norm': 0.22210699319839478, 'learning_rate': 3.828540468838897e-05, 'epoch': 0.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 5770/9322 [5:20:31<3:54:05,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0797, 'grad_norm': 0.22790934145450592, 'learning_rate': 3.810345420949956e-05, 'epoch': 0.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 5780/9322 [5:21:11<3:53:31,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0494, 'grad_norm': 0.22878742218017578, 'learning_rate': 3.792167057043669e-05, 'epoch': 0.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 5790/9322 [5:21:50<3:52:52,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0551, 'grad_norm': 0.22736035287380219, 'learning_rate': 3.774005632057485e-05, 'epoch': 0.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 5800/9322 [5:22:30<3:52:04,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0749, 'grad_norm': 0.21216095983982086, 'learning_rate': 3.755861400691306e-05, 'epoch': 0.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 5810/9322 [5:23:09<3:51:19,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0922, 'grad_norm': 0.22321368753910065, 'learning_rate': 3.737734617403898e-05, 'epoch': 0.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 5820/9322 [5:23:49<3:50:48,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0949, 'grad_norm': 0.21984755992889404, 'learning_rate': 3.719625536409337e-05, 'epoch': 0.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 5830/9322 [5:24:28<3:50:04,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0877, 'grad_norm': 0.22756311297416687, 'learning_rate': 3.7015344116734386e-05, 'epoch': 0.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 5840/9322 [5:25:08<3:49:15,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0804, 'grad_norm': 0.22830292582511902, 'learning_rate': 3.683461496910192e-05, 'epoch': 0.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 5850/9322 [5:25:47<3:48:36,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1667, 'grad_norm': 0.21959078311920166, 'learning_rate': 3.6654070455782096e-05, 'epoch': 0.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 5860/9322 [5:26:27<3:48:00,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1153, 'grad_norm': 0.22366000711917877, 'learning_rate': 3.647371310877163e-05, 'epoch': 0.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 5870/9322 [5:27:06<3:47:46,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0506, 'grad_norm': 0.234337717294693, 'learning_rate': 3.6293545457442424e-05, 'epoch': 0.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 5880/9322 [5:27:46<3:46:37,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0952, 'grad_norm': 0.2210848331451416, 'learning_rate': 3.611357002850606e-05, 'epoch': 0.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 5890/9322 [5:28:26<3:45:57,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1007, 'grad_norm': 0.22360067069530487, 'learning_rate': 3.593378934597828e-05, 'epoch': 0.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 5900/9322 [5:29:05<3:45:10,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1127, 'grad_norm': 0.21090510487556458, 'learning_rate': 3.575420593114374e-05, 'epoch': 0.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 5910/9322 [5:29:44<3:44:29,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1275, 'grad_norm': 0.22360704839229584, 'learning_rate': 3.5574822302520484e-05, 'epoch': 0.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 5920/9322 [5:30:24<3:43:45,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1085, 'grad_norm': 0.2326691746711731, 'learning_rate': 3.5395640975824795e-05, 'epoch': 0.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 5930/9322 [5:31:03<3:43:08,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0518, 'grad_norm': 0.23389780521392822, 'learning_rate': 3.521666446393575e-05, 'epoch': 0.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 5940/9322 [5:31:43<3:42:32,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0805, 'grad_norm': 0.22148765623569489, 'learning_rate': 3.5037895276860124e-05, 'epoch': 0.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 5950/9322 [5:32:22<3:41:49,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0667, 'grad_norm': 0.23879683017730713, 'learning_rate': 3.48593359216971e-05, 'epoch': 0.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 5960/9322 [5:33:02<3:41:09,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0898, 'grad_norm': 0.22237034142017365, 'learning_rate': 3.468098890260311e-05, 'epoch': 0.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 5970/9322 [5:33:41<3:40:33,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0239, 'grad_norm': 0.22252586483955383, 'learning_rate': 3.450285672075675e-05, 'epoch': 0.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 5980/9322 [5:34:21<3:39:47,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0751, 'grad_norm': 0.22011658549308777, 'learning_rate': 3.43249418743237e-05, 'epoch': 0.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 5990/9322 [5:35:00<3:39:05,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0368, 'grad_norm': 0.2246798574924469, 'learning_rate': 3.414724685842165e-05, 'epoch': 0.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 6000/9322 [5:35:40<3:38:20,  3.94s/it][INFO|trainer.py:3993] 2025-06-24 16:57:11,719 >> Saving model checkpoint to llama3-3b_lora_pretrain/checkpoint-6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0976, 'grad_norm': 0.22972439229488373, 'learning_rate': 3.39697741650854e-05, 'epoch': 0.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:698] 2025-06-24 16:57:12,879 >> loading configuration file config.json from cache at /home/ai-research-lab/.cache/huggingface/hub/models--meta-llama--LLaMA-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95/config.json\n",
      "[INFO|configuration_utils.py:770] 2025-06-24 16:57:12,880 >> Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128008,\n",
      "    128009\n",
      "  ],\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 131072,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 24,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": {\n",
      "    \"factor\": 32.0,\n",
      "    \"high_freq_factor\": 4.0,\n",
      "    \"low_freq_factor\": 1.0,\n",
      "    \"original_max_position_embeddings\": 8192,\n",
      "    \"rope_type\": \"llama3\"\n",
      "  },\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2356] 2025-06-24 16:57:13,033 >> chat template saved in llama3-3b_lora_pretrain/checkpoint-6000/chat_template.jinja\n",
      "[INFO|tokenization_utils_base.py:2525] 2025-06-24 16:57:13,034 >> tokenizer config file saved in llama3-3b_lora_pretrain/checkpoint-6000/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2534] 2025-06-24 16:57:13,034 >> Special tokens file saved in llama3-3b_lora_pretrain/checkpoint-6000/special_tokens_map.json\n",
      " 64%|██████▍   | 6010/9322 [5:36:21<3:38:30,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.125, 'grad_norm': 0.24271711707115173, 'learning_rate': 3.379252628323178e-05, 'epoch': 0.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 6020/9322 [5:37:00<3:36:54,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0852, 'grad_norm': 0.21812410652637482, 'learning_rate': 3.361550569862486e-05, 'epoch': 0.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 6030/9322 [5:37:39<3:36:15,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1049, 'grad_norm': 0.2253229022026062, 'learning_rate': 3.343871489384102e-05, 'epoch': 0.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 6040/9322 [5:38:19<3:35:30,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0917, 'grad_norm': 0.22646065056324005, 'learning_rate': 3.3262156348234124e-05, 'epoch': 0.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 6050/9322 [5:38:58<3:34:45,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.106, 'grad_norm': 0.22668300569057465, 'learning_rate': 3.308583253790084e-05, 'epoch': 0.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 6060/9322 [5:39:38<3:34:06,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0713, 'grad_norm': 0.23074935376644135, 'learning_rate': 3.290974593564585e-05, 'epoch': 0.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 6070/9322 [5:40:17<3:33:35,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1051, 'grad_norm': 0.23036359250545502, 'learning_rate': 3.273389901094717e-05, 'epoch': 0.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 6080/9322 [5:40:56<3:32:46,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0954, 'grad_norm': 0.22052264213562012, 'learning_rate': 3.255829422992147e-05, 'epoch': 0.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 6090/9322 [5:41:36<3:32:00,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0725, 'grad_norm': 0.22960646450519562, 'learning_rate': 3.238293405528961e-05, 'epoch': 0.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 6100/9322 [5:42:15<3:31:20,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0934, 'grad_norm': 0.22029909491539001, 'learning_rate': 3.220782094634201e-05, 'epoch': 0.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 6110/9322 [5:42:55<3:30:50,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0813, 'grad_norm': 0.21976037323474884, 'learning_rate': 3.203295735890418e-05, 'epoch': 0.66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 6120/9322 [5:43:34<3:30:04,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0898, 'grad_norm': 0.224455326795578, 'learning_rate': 3.18583457453023e-05, 'epoch': 0.66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 6130/9322 [5:44:13<3:29:22,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0931, 'grad_norm': 0.2227695733308792, 'learning_rate': 3.168398855432882e-05, 'epoch': 0.66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 6140/9322 [5:44:53<3:28:57,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0539, 'grad_norm': 0.23479712009429932, 'learning_rate': 3.150988823120806e-05, 'epoch': 0.66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 6150/9322 [5:45:32<3:28:05,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0814, 'grad_norm': 0.22192586958408356, 'learning_rate': 3.1336047217562033e-05, 'epoch': 0.66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 6160/9322 [5:46:12<3:27:26,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0869, 'grad_norm': 0.23228123784065247, 'learning_rate': 3.116246795137608e-05, 'epoch': 0.66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 6170/9322 [5:46:51<3:26:36,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0305, 'grad_norm': 0.2241409569978714, 'learning_rate': 3.098915286696476e-05, 'epoch': 0.66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 6180/9322 [5:47:30<3:26:07,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1071, 'grad_norm': 0.22499136626720428, 'learning_rate': 3.0816104394937727e-05, 'epoch': 0.66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 6190/9322 [5:48:10<3:25:23,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0499, 'grad_norm': 0.2206088751554489, 'learning_rate': 3.0643324962165546e-05, 'epoch': 0.66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 6200/9322 [5:48:49<3:24:41,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0442, 'grad_norm': 0.2214038372039795, 'learning_rate': 3.047081699174573e-05, 'epoch': 0.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 6210/9322 [5:49:28<3:23:50,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0912, 'grad_norm': 0.22835758328437805, 'learning_rate': 3.0298582902968752e-05, 'epoch': 0.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 6220/9322 [5:50:08<3:23:10,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0964, 'grad_norm': 0.2285616546869278, 'learning_rate': 3.0126625111284112e-05, 'epoch': 0.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 6230/9322 [5:50:47<3:22:48,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1095, 'grad_norm': 0.22741520404815674, 'learning_rate': 2.9954946028266427e-05, 'epoch': 0.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 6240/9322 [5:51:26<3:22:04,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0575, 'grad_norm': 0.22600190341472626, 'learning_rate': 2.9783548061581703e-05, 'epoch': 0.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 6250/9322 [5:52:06<3:21:26,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0886, 'grad_norm': 0.2409949004650116, 'learning_rate': 2.961243361495345e-05, 'epoch': 0.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 6260/9322 [5:52:45<3:21:07,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0306, 'grad_norm': 0.22492648661136627, 'learning_rate': 2.944160508812903e-05, 'epoch': 0.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 6270/9322 [5:53:24<3:20:21,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.092, 'grad_norm': 0.2266170084476471, 'learning_rate': 2.9271064876846054e-05, 'epoch': 0.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 6280/9322 [5:54:04<3:19:42,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.077, 'grad_norm': 0.22108577191829681, 'learning_rate': 2.9100815372798684e-05, 'epoch': 0.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 6290/9322 [5:54:43<3:19:04,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1051, 'grad_norm': 0.22119072079658508, 'learning_rate': 2.8930858963604118e-05, 'epoch': 0.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 6300/9322 [5:55:23<3:18:28,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0544, 'grad_norm': 0.23190408945083618, 'learning_rate': 2.8761198032769187e-05, 'epoch': 0.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 6310/9322 [5:56:02<3:17:56,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0842, 'grad_norm': 0.22377179563045502, 'learning_rate': 2.859183495965686e-05, 'epoch': 0.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 6320/9322 [5:56:41<3:17:08,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1107, 'grad_norm': 0.21851126849651337, 'learning_rate': 2.8422772119452843e-05, 'epoch': 0.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 6330/9322 [5:57:21<3:16:21,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0708, 'grad_norm': 0.23467016220092773, 'learning_rate': 2.8254011883132327e-05, 'epoch': 0.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 6340/9322 [5:58:00<3:15:45,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0718, 'grad_norm': 0.22179436683654785, 'learning_rate': 2.808555661742669e-05, 'epoch': 0.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 6350/9322 [5:58:40<3:15:10,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0791, 'grad_norm': 0.2238251119852066, 'learning_rate': 2.7917408684790393e-05, 'epoch': 0.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 6360/9322 [5:59:19<3:14:29,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0982, 'grad_norm': 0.23037168383598328, 'learning_rate': 2.774957044336778e-05, 'epoch': 0.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 6370/9322 [5:59:58<3:13:45,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0426, 'grad_norm': 0.23085090517997742, 'learning_rate': 2.758204424695996e-05, 'epoch': 0.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 6380/9322 [6:00:38<3:13:00,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1162, 'grad_norm': 0.2177487015724182, 'learning_rate': 2.74148324449919e-05, 'epoch': 0.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▊   | 6390/9322 [6:01:17<3:12:31,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0491, 'grad_norm': 0.2261824756860733, 'learning_rate': 2.7247937382479393e-05, 'epoch': 0.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▊   | 6400/9322 [6:01:56<3:11:26,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0891, 'grad_norm': 0.2310759574174881, 'learning_rate': 2.7081361399996247e-05, 'epoch': 0.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 6410/9322 [6:02:36<3:12:51,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0841, 'grad_norm': 0.22845475375652313, 'learning_rate': 2.6915106833641423e-05, 'epoch': 0.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 6420/9322 [6:03:15<3:10:13,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0676, 'grad_norm': 0.22110745310783386, 'learning_rate': 2.6749176015006238e-05, 'epoch': 0.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 6430/9322 [6:03:55<3:09:29,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1047, 'grad_norm': 0.233759343624115, 'learning_rate': 2.6583571271141695e-05, 'epoch': 0.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 6440/9322 [6:04:34<3:08:53,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0726, 'grad_norm': 0.23996233940124512, 'learning_rate': 2.6418294924525855e-05, 'epoch': 0.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 6450/9322 [6:05:13<3:08:08,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0615, 'grad_norm': 0.21994809806346893, 'learning_rate': 2.625334929303132e-05, 'epoch': 0.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 6460/9322 [6:05:53<3:07:35,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0819, 'grad_norm': 0.22947177290916443, 'learning_rate': 2.608873668989258e-05, 'epoch': 0.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 6470/9322 [6:06:32<3:07:06,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0216, 'grad_norm': 0.2245234251022339, 'learning_rate': 2.592445942367373e-05, 'epoch': 0.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 6480/9322 [6:07:11<3:06:30,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0827, 'grad_norm': 0.22390243411064148, 'learning_rate': 2.5760519798235993e-05, 'epoch': 0.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 6490/9322 [6:07:51<3:05:54,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0349, 'grad_norm': 0.22651980817317963, 'learning_rate': 2.5596920112705425e-05, 'epoch': 0.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 6500/9322 [6:08:30<3:05:16,  3.94s/it][INFO|trainer.py:3993] 2025-06-24 17:30:02,153 >> Saving model checkpoint to llama3-3b_lora_pretrain/checkpoint-6500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0621, 'grad_norm': 0.2297147661447525, 'learning_rate': 2.543366266144075e-05, 'epoch': 0.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:698] 2025-06-24 17:30:03,275 >> loading configuration file config.json from cache at /home/ai-research-lab/.cache/huggingface/hub/models--meta-llama--LLaMA-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95/config.json\n",
      "[INFO|configuration_utils.py:770] 2025-06-24 17:30:03,276 >> Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128008,\n",
      "    128009\n",
      "  ],\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 131072,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 24,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": {\n",
      "    \"factor\": 32.0,\n",
      "    \"high_freq_factor\": 4.0,\n",
      "    \"low_freq_factor\": 1.0,\n",
      "    \"original_max_position_embeddings\": 8192,\n",
      "    \"rope_type\": \"llama3\"\n",
      "  },\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2356] 2025-06-24 17:30:03,396 >> chat template saved in llama3-3b_lora_pretrain/checkpoint-6500/chat_template.jinja\n",
      "[INFO|tokenization_utils_base.py:2525] 2025-06-24 17:30:03,398 >> tokenizer config file saved in llama3-3b_lora_pretrain/checkpoint-6500/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2534] 2025-06-24 17:30:03,398 >> Special tokens file saved in llama3-3b_lora_pretrain/checkpoint-6500/special_tokens_map.json\n",
      " 70%|██████▉   | 6510/9322 [6:09:11<3:05:24,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0583, 'grad_norm': 0.22763222455978394, 'learning_rate': 2.5270749734001055e-05, 'epoch': 0.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 6520/9322 [6:09:51<3:03:48,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0569, 'grad_norm': 0.22809310257434845, 'learning_rate': 2.5108183615113766e-05, 'epoch': 0.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 6530/9322 [6:10:30<3:03:01,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0272, 'grad_norm': 0.2623980641365051, 'learning_rate': 2.4945966584642627e-05, 'epoch': 0.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 6540/9322 [6:11:09<3:02:30,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0742, 'grad_norm': 0.2177499234676361, 'learning_rate': 2.4784100917555632e-05, 'epoch': 0.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 6550/9322 [6:11:49<3:01:56,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1129, 'grad_norm': 0.22666026651859283, 'learning_rate': 2.4622588883893227e-05, 'epoch': 0.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 6560/9322 [6:12:28<3:01:16,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0464, 'grad_norm': 0.22506004571914673, 'learning_rate': 2.446143274873639e-05, 'epoch': 0.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 6570/9322 [6:13:07<3:00:29,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0357, 'grad_norm': 0.21177233755588531, 'learning_rate': 2.430063477217491e-05, 'epoch': 0.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 6580/9322 [6:13:47<2:59:58,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0585, 'grad_norm': 0.2325003743171692, 'learning_rate': 2.414019720927564e-05, 'epoch': 0.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 6590/9322 [6:14:26<2:59:15,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1143, 'grad_norm': 0.22627507150173187, 'learning_rate': 2.3980122310050977e-05, 'epoch': 0.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 6600/9322 [6:15:05<2:58:28,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1134, 'grad_norm': 0.22359225153923035, 'learning_rate': 2.3820412319427237e-05, 'epoch': 0.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 6610/9322 [6:15:45<2:57:50,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0654, 'grad_norm': 0.2257590889930725, 'learning_rate': 2.3661069477213126e-05, 'epoch': 0.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 6620/9322 [6:16:24<2:57:16,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1051, 'grad_norm': 0.21749135851860046, 'learning_rate': 2.3502096018068404e-05, 'epoch': 0.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 6630/9322 [6:17:04<2:56:34,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0967, 'grad_norm': 0.22202661633491516, 'learning_rate': 2.3343494171472497e-05, 'epoch': 0.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 6640/9322 [6:17:43<2:55:52,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1101, 'grad_norm': 0.2207728624343872, 'learning_rate': 2.3185266161693304e-05, 'epoch': 0.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 6650/9322 [6:18:22<2:55:15,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0967, 'grad_norm': 0.2333543300628662, 'learning_rate': 2.3027414207755932e-05, 'epoch': 0.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 6660/9322 [6:19:02<2:54:31,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.079, 'grad_norm': 0.219285786151886, 'learning_rate': 2.286994052341157e-05, 'epoch': 0.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 6670/9322 [6:19:41<2:53:52,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0964, 'grad_norm': 0.2303195744752884, 'learning_rate': 2.2712847317106502e-05, 'epoch': 0.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 6680/9322 [6:20:20<2:54:51,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1033, 'grad_norm': 0.22901761531829834, 'learning_rate': 2.2556136791951056e-05, 'epoch': 0.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 6690/9322 [6:21:00<2:52:40,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.07, 'grad_norm': 0.22270645201206207, 'learning_rate': 2.2399811145688825e-05, 'epoch': 0.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 6700/9322 [6:21:39<2:52:02,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0463, 'grad_norm': 0.2332088202238083, 'learning_rate': 2.224387257066571e-05, 'epoch': 0.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 6710/9322 [6:22:18<2:51:18,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1217, 'grad_norm': 0.23092126846313477, 'learning_rate': 2.2088323253799287e-05, 'epoch': 0.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 6720/9322 [6:22:58<2:50:35,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0138, 'grad_norm': 0.23105043172836304, 'learning_rate': 2.1933165376548052e-05, 'epoch': 0.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 6730/9322 [6:23:37<2:49:51,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0533, 'grad_norm': 0.227755606174469, 'learning_rate': 2.1778401114880864e-05, 'epoch': 0.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 6740/9322 [6:24:16<2:49:13,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1231, 'grad_norm': 0.22826485335826874, 'learning_rate': 2.1624032639246467e-05, 'epoch': 0.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 6750/9322 [6:24:56<2:48:35,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0902, 'grad_norm': 0.22627419233322144, 'learning_rate': 2.1470062114542977e-05, 'epoch': 0.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 6760/9322 [6:25:35<2:47:48,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0432, 'grad_norm': 0.23040474951267242, 'learning_rate': 2.1316491700087548e-05, 'epoch': 0.73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 6770/9322 [6:26:14<2:47:10,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1368, 'grad_norm': 0.22948689758777618, 'learning_rate': 2.1163323549586154e-05, 'epoch': 0.73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 6780/9322 [6:26:54<2:46:35,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0718, 'grad_norm': 0.23395171761512756, 'learning_rate': 2.1010559811103276e-05, 'epoch': 0.73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 6790/9322 [6:27:33<2:45:54,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1057, 'grad_norm': 0.24287281930446625, 'learning_rate': 2.0858202627031825e-05, 'epoch': 0.73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 6800/9322 [6:28:12<2:45:10,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.098, 'grad_norm': 0.22643312811851501, 'learning_rate': 2.0706254134063157e-05, 'epoch': 0.73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 6810/9322 [6:28:52<2:44:27,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0825, 'grad_norm': 0.23029156029224396, 'learning_rate': 2.0554716463157015e-05, 'epoch': 0.73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 6820/9322 [6:29:31<2:43:48,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0933, 'grad_norm': 0.22607527673244476, 'learning_rate': 2.0403591739511653e-05, 'epoch': 0.73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 6830/9322 [6:30:10<2:43:13,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1032, 'grad_norm': 0.2581336200237274, 'learning_rate': 2.025288208253413e-05, 'epoch': 0.73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 6840/9322 [6:30:49<2:42:27,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0697, 'grad_norm': 0.22887973487377167, 'learning_rate': 2.0102589605810452e-05, 'epoch': 0.73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 6850/9322 [6:31:29<2:42:01,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0848, 'grad_norm': 0.21998704969882965, 'learning_rate': 1.9952716417076052e-05, 'epoch': 0.73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 6860/9322 [6:32:08<2:41:13,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0609, 'grad_norm': 0.22685866057872772, 'learning_rate': 1.9803264618186124e-05, 'epoch': 0.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 6870/9322 [6:32:47<2:40:31,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0709, 'grad_norm': 0.2274046093225479, 'learning_rate': 1.965423630508621e-05, 'epoch': 0.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 6880/9322 [6:33:27<2:39:50,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0686, 'grad_norm': 0.27425962686538696, 'learning_rate': 1.9505633567782822e-05, 'epoch': 0.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 6890/9322 [6:34:06<2:39:09,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0189, 'grad_norm': 0.22564803063869476, 'learning_rate': 1.935745849031405e-05, 'epoch': 0.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 6900/9322 [6:34:45<2:38:31,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.111, 'grad_norm': 0.22788091003894806, 'learning_rate': 1.9209713150720455e-05, 'epoch': 0.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 6910/9322 [6:35:24<2:38:00,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0682, 'grad_norm': 0.2265453338623047, 'learning_rate': 1.9062399621015798e-05, 'epoch': 0.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 6920/9322 [6:36:04<2:37:12,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0829, 'grad_norm': 0.2189902663230896, 'learning_rate': 1.8915519967158056e-05, 'epoch': 0.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 6930/9322 [6:36:43<2:36:32,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0995, 'grad_norm': 0.22688157856464386, 'learning_rate': 1.876907624902043e-05, 'epoch': 0.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 6940/9322 [6:37:22<2:35:53,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0492, 'grad_norm': 0.22945931553840637, 'learning_rate': 1.8623070520362473e-05, 'epoch': 0.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 6950/9322 [6:38:02<2:35:18,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1037, 'grad_norm': 0.23607748746871948, 'learning_rate': 1.8477504828801313e-05, 'epoch': 0.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 6960/9322 [6:38:41<2:34:55,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0929, 'grad_norm': 0.23633494973182678, 'learning_rate': 1.8332381215782818e-05, 'epoch': 0.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 6970/9322 [6:39:20<2:33:53,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0488, 'grad_norm': 0.22111256420612335, 'learning_rate': 1.81877017165531e-05, 'epoch': 0.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 6980/9322 [6:39:59<2:33:15,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0729, 'grad_norm': 0.22666868567466736, 'learning_rate': 1.8043468360129895e-05, 'epoch': 0.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 6990/9322 [6:40:39<2:32:36,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1158, 'grad_norm': 0.23344169557094574, 'learning_rate': 1.789968316927415e-05, 'epoch': 0.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 7000/9322 [6:41:18<2:31:55,  3.93s/it][INFO|trainer.py:3993] 2025-06-24 18:02:50,040 >> Saving model checkpoint to llama3-3b_lora_pretrain/checkpoint-7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0823, 'grad_norm': 0.22067752480506897, 'learning_rate': 1.775634816046165e-05, 'epoch': 0.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:698] 2025-06-24 18:02:51,282 >> loading configuration file config.json from cache at /home/ai-research-lab/.cache/huggingface/hub/models--meta-llama--LLaMA-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95/config.json\n",
      "[INFO|configuration_utils.py:770] 2025-06-24 18:02:51,282 >> Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128008,\n",
      "    128009\n",
      "  ],\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 131072,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 24,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": {\n",
      "    \"factor\": 32.0,\n",
      "    \"high_freq_factor\": 4.0,\n",
      "    \"low_freq_factor\": 1.0,\n",
      "    \"original_max_position_embeddings\": 8192,\n",
      "    \"rope_type\": \"llama3\"\n",
      "  },\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2356] 2025-06-24 18:02:51,402 >> chat template saved in llama3-3b_lora_pretrain/checkpoint-7000/chat_template.jinja\n",
      "[INFO|tokenization_utils_base.py:2525] 2025-06-24 18:02:51,403 >> tokenizer config file saved in llama3-3b_lora_pretrain/checkpoint-7000/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2534] 2025-06-24 18:02:51,404 >> Special tokens file saved in llama3-3b_lora_pretrain/checkpoint-7000/special_tokens_map.json\n",
      " 75%|███████▌  | 7010/9322 [6:41:59<2:31:50,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0419, 'grad_norm': 0.2250414788722992, 'learning_rate': 1.7613465343854703e-05, 'epoch': 0.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 7020/9322 [6:42:38<2:30:26,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0954, 'grad_norm': 0.2288021743297577, 'learning_rate': 1.747103672327396e-05, 'epoch': 0.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 7030/9322 [6:43:17<2:29:54,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0752, 'grad_norm': 0.22551825642585754, 'learning_rate': 1.732906429617034e-05, 'epoch': 0.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 7040/9322 [6:43:57<2:29:13,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0569, 'grad_norm': 0.22789596021175385, 'learning_rate': 1.7187550053597034e-05, 'epoch': 0.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 7050/9322 [6:44:36<2:28:43,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.089, 'grad_norm': 0.22090566158294678, 'learning_rate': 1.7046495980181488e-05, 'epoch': 0.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 7060/9322 [6:45:15<2:27:56,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0043, 'grad_norm': 0.22471584379673004, 'learning_rate': 1.690590405409769e-05, 'epoch': 0.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 7070/9322 [6:45:54<2:27:20,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1069, 'grad_norm': 0.23336325585842133, 'learning_rate': 1.676577624703834e-05, 'epoch': 0.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 7080/9322 [6:46:34<2:26:36,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0903, 'grad_norm': 0.24146327376365662, 'learning_rate': 1.662611452418722e-05, 'epoch': 0.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 7090/9322 [6:47:13<2:25:55,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0686, 'grad_norm': 0.2323898822069168, 'learning_rate': 1.6486920844191678e-05, 'epoch': 0.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 7100/9322 [6:47:52<2:25:07,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0862, 'grad_norm': 0.23192347586154938, 'learning_rate': 1.634819715913509e-05, 'epoch': 0.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 7110/9322 [6:48:31<2:24:29,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1299, 'grad_norm': 0.22592271864414215, 'learning_rate': 1.6209945414509527e-05, 'epoch': 0.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 7120/9322 [6:49:11<2:23:49,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0913, 'grad_norm': 0.22421333193778992, 'learning_rate': 1.6072167549188477e-05, 'epoch': 0.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 7130/9322 [6:49:50<2:23:10,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0909, 'grad_norm': 0.22988860309123993, 'learning_rate': 1.593486549539961e-05, 'epoch': 0.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 7140/9322 [6:50:29<2:22:30,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0834, 'grad_norm': 0.22511114180088043, 'learning_rate': 1.5798041178697754e-05, 'epoch': 0.77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 7150/9322 [6:51:08<2:21:46,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0766, 'grad_norm': 0.23287421464920044, 'learning_rate': 1.566169651793779e-05, 'epoch': 0.77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 7160/9322 [6:51:47<2:21:10,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0826, 'grad_norm': 0.2262069284915924, 'learning_rate': 1.5525833425247836e-05, 'epoch': 0.77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 7170/9322 [6:52:26<2:20:36,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1062, 'grad_norm': 0.23213514685630798, 'learning_rate': 1.5390453806002352e-05, 'epoch': 0.77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 7180/9322 [6:53:06<2:19:54,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0559, 'grad_norm': 0.23264756798744202, 'learning_rate': 1.5255559558795507e-05, 'epoch': 0.77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 7190/9322 [6:53:45<2:19:24,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0807, 'grad_norm': 0.22777803242206573, 'learning_rate': 1.5121152575414488e-05, 'epoch': 0.77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 7200/9322 [6:54:24<2:18:46,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1002, 'grad_norm': 0.22777101397514343, 'learning_rate': 1.4987234740812962e-05, 'epoch': 0.77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 7210/9322 [6:55:03<2:18:21,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0897, 'grad_norm': 0.22559019923210144, 'learning_rate': 1.4853807933084685e-05, 'epoch': 0.77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 7220/9322 [6:55:43<2:17:37,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0527, 'grad_norm': 0.228082075715065, 'learning_rate': 1.4720874023437114e-05, 'epoch': 0.77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 7230/9322 [6:56:22<2:17:07,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0644, 'grad_norm': 0.23534953594207764, 'learning_rate': 1.458843487616523e-05, 'epoch': 0.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 7240/9322 [6:57:01<2:16:31,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1487, 'grad_norm': 0.2287881225347519, 'learning_rate': 1.445649234862536e-05, 'epoch': 0.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 7250/9322 [6:57:41<2:15:47,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1237, 'grad_norm': 0.2287089079618454, 'learning_rate': 1.4325048291209093e-05, 'epoch': 0.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 7260/9322 [6:58:20<2:15:13,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1205, 'grad_norm': 0.267396479845047, 'learning_rate': 1.419410454731736e-05, 'epoch': 0.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 7270/9322 [6:58:59<2:14:36,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1341, 'grad_norm': 0.22437947988510132, 'learning_rate': 1.4063662953334594e-05, 'epoch': 0.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 7272/9322 [6:59:07<2:14:27,  3.94s/it][rank0]: Traceback (most recent call last):\n",
      "[rank0]:   File \"/home/ai-research-lab/MCSProjectbyWajahatalibasharat5Percent/LLaMA-Factory/src/llamafactory/launcher.py\", line 23, in <module>\n",
      "[rank0]:     launch()\n",
      "[rank0]:   File \"/home/ai-research-lab/MCSProjectbyWajahatalibasharat5Percent/LLaMA-Factory/src/llamafactory/launcher.py\", line 19, in launch\n",
      "[rank0]:     run_exp()\n",
      "[rank0]:   File \"/home/ai-research-lab/MCSProjectbyWajahatalibasharat5Percent/LLaMA-Factory/src/llamafactory/train/tuner.py\", line 110, in run_exp\n",
      "[rank0]:     _training_function(config={\"args\": args, \"callbacks\": callbacks})\n",
      "[rank0]:   File \"/home/ai-research-lab/MCSProjectbyWajahatalibasharat5Percent/LLaMA-Factory/src/llamafactory/train/tuner.py\", line 70, in _training_function\n",
      "[rank0]:     run_pt(model_args, data_args, training_args, finetuning_args, callbacks)\n",
      "[rank0]:   File \"/home/ai-research-lab/MCSProjectbyWajahatalibasharat5Percent/LLaMA-Factory/src/llamafactory/train/pt/workflow.py\", line 63, in run_pt\n",
      "[rank0]:     train_result = trainer.train(resume_from_checkpoint=training_args.resume_from_checkpoint)\n",
      "[rank0]:   File \"/home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages/transformers/trainer.py\", line 2240, in train\n",
      "[rank0]:     return inner_training_loop(\n",
      "[rank0]:   File \"/home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages/transformers/trainer.py\", line 2555, in _inner_training_loop\n",
      "[rank0]:     tr_loss_step = self.training_step(model, inputs, num_items_in_batch)\n",
      "[rank0]:   File \"/home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages/transformers/trainer.py\", line 3791, in training_step\n",
      "[rank0]:     self.accelerator.backward(loss, **kwargs)\n",
      "[rank0]:   File \"/home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages/accelerate/accelerator.py\", line 2473, in backward\n",
      "[rank0]:     loss.backward(**kwargs)\n",
      "[rank0]:   File \"/home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/_tensor.py\", line 648, in backward\n",
      "[rank0]:     torch.autograd.backward(\n",
      "[rank0]:   File \"/home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/autograd/__init__.py\", line 353, in backward\n",
      "[rank0]:     _engine_run_backward(\n",
      "[rank0]:   File \"/home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/autograd/graph.py\", line 824, in _engine_run_backward\n",
      "[rank0]:     return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "[rank0]: KeyboardInterrupt\n",
      "W0624 18:20:42.044000 19301 site-packages/torch/distributed/elastic/agent/server/api.py:719] Received Signals.SIGINT death signal, shutting down workers\n",
      "W0624 18:20:42.078000 19301 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 19334 closing signal SIGINT\n",
      "W0624 18:20:42.080000 19301 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 19335 closing signal SIGINT\n",
      "[rank1]: Traceback (most recent call last):\n",
      "[rank1]:   File \"/home/ai-research-lab/MCSProjectbyWajahatalibasharat5Percent/LLaMA-Factory/src/llamafactory/launcher.py\", line 23, in <module>\n",
      "[rank1]:     launch()\n",
      "[rank1]:   File \"/home/ai-research-lab/MCSProjectbyWajahatalibasharat5Percent/LLaMA-Factory/src/llamafactory/launcher.py\", line 19, in launch\n",
      "[rank1]:     run_exp()\n",
      "[rank1]:   File \"/home/ai-research-lab/MCSProjectbyWajahatalibasharat5Percent/LLaMA-Factory/src/llamafactory/train/tuner.py\", line 110, in run_exp\n",
      "[rank1]:     _training_function(config={\"args\": args, \"callbacks\": callbacks})\n",
      "[rank1]:   File \"/home/ai-research-lab/MCSProjectbyWajahatalibasharat5Percent/LLaMA-Factory/src/llamafactory/train/tuner.py\", line 70, in _training_function\n",
      "[rank1]:     run_pt(model_args, data_args, training_args, finetuning_args, callbacks)\n",
      "[rank1]:   File \"/home/ai-research-lab/MCSProjectbyWajahatalibasharat5Percent/LLaMA-Factory/src/llamafactory/train/pt/workflow.py\", line 63, in run_pt\n",
      "[rank1]:     train_result = trainer.train(resume_from_checkpoint=training_args.resume_from_checkpoint)\n",
      "[rank1]:   File \"/home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages/transformers/trainer.py\", line 2240, in train\n",
      "[rank1]:     return inner_training_loop(\n",
      "[rank1]:   File \"/home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages/transformers/trainer.py\", line 2555, in _inner_training_loop\n",
      "[rank1]:     tr_loss_step = self.training_step(model, inputs, num_items_in_batch)\n",
      "[rank1]:   File \"/home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages/transformers/trainer.py\", line 3791, in training_step\n",
      "[rank1]:     self.accelerator.backward(loss, **kwargs)\n",
      "[rank1]:   File \"/home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages/accelerate/accelerator.py\", line 2473, in backward\n",
      "[rank1]:     loss.backward(**kwargs)\n",
      "[rank1]:   File \"/home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/_tensor.py\", line 648, in backward\n",
      "[rank1]:     torch.autograd.backward(\n",
      "[rank1]:   File \"/home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/autograd/__init__.py\", line 353, in backward\n",
      "[rank1]:     _engine_run_backward(\n",
      "[rank1]:   File \"/home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/autograd/graph.py\", line 824, in _engine_run_backward\n",
      "[rank1]:     return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "[rank1]: KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ai-research-lab/miniconda3/envs/myenv/bin/llamafactory-cli\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/home/ai-research-lab/MCSProjectbyWajahatalibasharat5Percent/LLaMA-Factory/src/llamafactory/cli.py\", line 130, in main\n",
      "    process = subprocess.run(\n",
      "  File \"/home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/subprocess.py\", line 505, in run\n",
      "    stdout, stderr = process.communicate(input, timeout=timeout)\n",
      "  File \"/home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/subprocess.py\", line 1146, in communicate\n",
      "    self.wait()\n",
      "  File \"/home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/subprocess.py\", line 1209, in wait\n",
      "    return self._wait(timeout=timeout)\n",
      "  File \"/home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/subprocess.py\", line 1959, in _wait\n",
      "    (pid, sts) = self._try_wait(0)\n",
      "  File \"/home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/subprocess.py\", line 1917, in _try_wait\n",
      "    (pid, sts) = os.waitpid(self.pid, wait_flags)\n",
      "KeyboardInterrupt\n",
      "[rank1]:[W624 18:20:43.185097724 TCPStore.cpp:125] [c10d] recvValue failed on SocketImpl(fd=30, addr=[localhost]:60904, remote=[localhost]:58459): failed to recv, got 0 bytes\n",
      "Exception raised from recvBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:678 (most recent call first):\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7de133f785e8 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/lib/libc10.so)\n",
      "frame #1: <unknown function> + 0x5ba8bfe (0x7de1247a8bfe in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #2: <unknown function> + 0x5baaf40 (0x7de1247aaf40 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #3: <unknown function> + 0x5bab84a (0x7de1247ab84a in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x2a9 (0x7de1247a52a9 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7de0d5cf3ad9 in /home/ai-research-lab/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #6: <unknown function> + 0xdbbf4 (0x7de0c5cdbbf4 in /home/ai-research-lab/miniconda3/envs/myenv/bin/../lib/libstdc++.so.6)\n",
      "frame #7: <unknown function> + 0xa2ef1 (0x7de1420a2ef1 in /lib/x86_64-linux-gnu/libc.so.6)\n",
      "frame #8: <unknown function> + 0x13445c (0x7de14213445c in /lib/x86_64-linux-gnu/libc.so.6)\n",
      "\n",
      "[rank1]:[W624 18:20:43.193484375 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 1] Failed to check the \"should dump\" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: failed to recv, got 0 bytes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Command to run the training using llamafactory-cli\n",
    "# This line will execute the training command.\n",
    "# Make sure you have `llamafactory-cli` installed and available in your system's PATH.\n",
    "print(f\"\\nRunning training with: llamafactory-cli train {config_file_name}\")\n",
    "# Execute the shell command\n",
    "os.system(f\"llamafactory-cli train {config_file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf83b47",
   "metadata": {},
   "source": [
    "## LoRA Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62c3a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Inference arguments for LLaMA Factory\n",
    "args = dict(\n",
    "    # Model settings\n",
    "    model_name_or_path=\"meta-llama/LLaMA-3.2-3B-Instruct\",\n",
    "    adapter_name_or_path=\"llama3-3b_lora_pretrain\", # Path to your LoRA adapter directory\n",
    "    template=\"llama3\",\n",
    "    infer_backend=\"huggingface\",  # Choices: [\"huggingface\", \"vllm\", \"sglang\"]\n",
    "    trust_remote_code=True,\n",
    "    # You might want to add other inference-related arguments here if needed,\n",
    "    # such as `max_new_tokens`, `temperature`, `top_p`, etc., depending on\n",
    "    # what llamafactory-cli infer supports.\n",
    "    # For example:\n",
    "    # max_new_tokens=1024,\n",
    "    # temperature=0.7,\n",
    "    # top_p=0.9,\n",
    "    # do_sample=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6eaa51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the filename for the inference configuration\n",
    "inference_config_file = \"inference_config.json\"\n",
    "\n",
    "# Save the arguments to a JSON file\n",
    "with open(inference_config_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(args, f, indent=2)\n",
    "\n",
    "print(f\"Inference configuration saved to {inference_config_file}:\")\n",
    "print(json.dumps(args, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc5e11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run inference using llamafactory-cli:\n",
    "# For interactive chat:\n",
    "print(f\"\\nTo start an interactive chat session, run:\")\n",
    "print(f\"llamafactory-cli chat {inference_config_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a910e5",
   "metadata": {},
   "source": [
    "## Merging the lora adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58be1470",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Define the arguments for merging LoRA adapters\n",
    "args = dict(\n",
    "    # Model settings\n",
    "    # The base model that the LoRA adapters were trained on.\n",
    "    model_name_or_path=\"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "    # Path to your LoRA adapter directory.\n",
    "    # This should be the same 'output_dir' from your training script.\n",
    "    adapter_name_or_path=\"llama3-3b_lora_pretrain\",\n",
    "    # The template used during training and inference for prompt formatting.\n",
    "    template=\"llama3\",\n",
    "    # Whether to trust remote code when loading models/components.\n",
    "    trust_remote_code=True,\n",
    "    # Specify the finetuning type, crucial for LLaMA Factory to know how to merge.\n",
    "    # Since you used LoRA for training, it should be \"lora\".\n",
    "    finetuning_type=\"lora\",\n",
    "\n",
    "    # Export settings for the merged model\n",
    "    # The directory where the merged full model will be saved.\n",
    "    export_dir=\"output/llama3_lora_sft_merged\",\n",
    "    # The maximum size (in GB) of each shard of the exported model.\n",
    "    # This helps in splitting large models into smaller files.\n",
    "    export_size=5,\n",
    "    # The device to use for the merging process ('cpu' or 'auto').\n",
    "    # 'auto' will attempt to use GPU if available, otherwise fallback to CPU.\n",
    "    export_device=\"auto\",\n",
    "    # Whether to export in a legacy format. Set to False for modern usage.\n",
    "    export_legacy_format=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe37307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the filename for the merging configuration JSON file\n",
    "merge_config_file_name = \"merge_config.json\"\n",
    "\n",
    "# Save the arguments dictionary to the JSON file\n",
    "with open(merge_config_file_name, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(args, f, indent=2)\n",
    "\n",
    "print(f\"Merging configuration saved to {merge_config_file_name}:\")\n",
    "print(json.dumps(args, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2b58e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Command to run the merging process using llamafactory-cli\n",
    "# You would typically execute this command from your terminal after\n",
    "# this Python script generates the configuration file.\n",
    "print(f\"\\nTo merge the LoRA adapters with the base model, run:\")\n",
    "print(f\"llamafactory-cli export {merge_config_file_name}\")\n",
    "\n",
    "# Optional: You can uncomment the following lines to execute the command directly\n",
    "# from this Python script (useful in environments like Jupyter notebooks).\n",
    "# import subprocess\n",
    "# try:\n",
    "#     subprocess.run([\"llamafactory-cli\", \"export\", merge_config_file_name], check=True)\n",
    "# except subprocess.CalledProcessError as e:\n",
    "#     print(f\"Error running llamafactory-cli export: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce42e4c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
